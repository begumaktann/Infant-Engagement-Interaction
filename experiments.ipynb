{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5PA3sgrLy5D"
      },
      "outputs": [],
      "source": [
        "# prompt: load /content/drive/MyDrive/merged_all_keypoints_b_label_only.csv and /content/drive/MyDrive/engagement_cleaned.csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the first CSV file\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/merged_all_keypoints_b_label_only.csv')\n",
        "\n",
        "# Load the second CSV file\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/engagement_cleaned.csv')\n",
        "\n",
        "# Now you have two pandas DataFrames: df1 and df2\n",
        "# You can work with them, for example, print the first few rows:\n",
        "# print(df1.head())\n",
        "# print(df2.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GazyME7eMJw2",
        "outputId": "48e9fab6-4cfe-4b93-f07a-0ac5b50b2af8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 181,\n  \"fields\": [\n    {\n      \"column\": \"video_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"Fp21\",\n          \"Fp31\",\n          \"Fp13\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 150,\n        \"samples\": [\n          \"00:03:24\",\n          \"00:00:26\",\n          \"00:05:43\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"watching\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"playing_engaged\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"playfully_engaged\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"angrily_engaged\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seconds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 140,\n        \"min\": 18,\n        \"max\": 563,\n        \"num_unique_values\": 150,\n        \"samples\": [\n          204\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df2"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-282a5d8a-73b4-421d-9b5d-35c0818a41df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_id</th>\n",
              "      <th>time</th>\n",
              "      <th>watching</th>\n",
              "      <th>playing_engaged</th>\n",
              "      <th>playfully_engaged</th>\n",
              "      <th>angrily_engaged</th>\n",
              "      <th>seconds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fp13</td>\n",
              "      <td>00:00:37</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fp13</td>\n",
              "      <td>00:01:07</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fp13</td>\n",
              "      <td>00:01:37</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fp13</td>\n",
              "      <td>00:02:07</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fp14</td>\n",
              "      <td>00:00:55</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>Fp38</td>\n",
              "      <td>00:07:14</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>Fp39</td>\n",
              "      <td>00:05:04</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>Fp39</td>\n",
              "      <td>00:06:13</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>Fp40</td>\n",
              "      <td>00:08:17</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>Fp40</td>\n",
              "      <td>00:09:23</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>563</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>181 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-282a5d8a-73b4-421d-9b5d-35c0818a41df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-282a5d8a-73b4-421d-9b5d-35c0818a41df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-282a5d8a-73b4-421d-9b5d-35c0818a41df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f45c929f-d214-4c47-be33-be868516d7ce\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f45c929f-d214-4c47-be33-be868516d7ce')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f45c929f-d214-4c47-be33-be868516d7ce button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a5e9377d-11a9-4776-a4ce-97d0112e2f49\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a5e9377d-11a9-4776-a4ce-97d0112e2f49 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    video_id      time  watching  playing_engaged  playfully_engaged  \\\n",
              "0       Fp13  00:00:37         1                0                  0   \n",
              "1       Fp13  00:01:07         1                2                  1   \n",
              "2       Fp13  00:01:37         1                0                  0   \n",
              "3       Fp13  00:02:07         1                0                  0   \n",
              "4       Fp14  00:00:55         1                0                  0   \n",
              "..       ...       ...       ...              ...                ...   \n",
              "176     Fp38  00:07:14         1                0                  0   \n",
              "177     Fp39  00:05:04         1                2                  1   \n",
              "178     Fp39  00:06:13         1                2                  1   \n",
              "179     Fp40  00:08:17         1                2                  1   \n",
              "180     Fp40  00:09:23         1                2                  1   \n",
              "\n",
              "     angrily_engaged  seconds  \n",
              "0                  0       37  \n",
              "1                  0       67  \n",
              "2                  0       97  \n",
              "3                  0      127  \n",
              "4                  0       55  \n",
              "..               ...      ...  \n",
              "176                0      434  \n",
              "177                0      304  \n",
              "178                0      373  \n",
              "179                0      497  \n",
              "180                0      563  \n",
              "\n",
              "[181 rows x 7 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "haZVpiiZMM_L",
        "outputId": "be154b33-c982-4871-8dd4-f1f9b06cf133"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bc110262-cd2c-4657-88bd-f850da76f761\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frame</th>\n",
              "      <th>sec</th>\n",
              "      <th>tracking_id</th>\n",
              "      <th>kp0_x</th>\n",
              "      <th>kp0_y</th>\n",
              "      <th>kp1_x</th>\n",
              "      <th>kp1_y</th>\n",
              "      <th>kp2_x</th>\n",
              "      <th>kp2_y</th>\n",
              "      <th>kp3_x</th>\n",
              "      <th>...</th>\n",
              "      <th>kp12_y</th>\n",
              "      <th>kp13_x</th>\n",
              "      <th>kp13_y</th>\n",
              "      <th>kp14_x</th>\n",
              "      <th>kp14_y</th>\n",
              "      <th>kp15_x</th>\n",
              "      <th>kp15_y</th>\n",
              "      <th>kp16_x</th>\n",
              "      <th>kp16_y</th>\n",
              "      <th>source_video</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.04</td>\n",
              "      <td>68</td>\n",
              "      <td>396</td>\n",
              "      <td>702</td>\n",
              "      <td>392</td>\n",
              "      <td>689</td>\n",
              "      <td>392</td>\n",
              "      <td>702</td>\n",
              "      <td>341</td>\n",
              "      <td>...</td>\n",
              "      <td>955</td>\n",
              "      <td>392</td>\n",
              "      <td>935</td>\n",
              "      <td>374</td>\n",
              "      <td>869</td>\n",
              "      <td>296</td>\n",
              "      <td>756</td>\n",
              "      <td>422</td>\n",
              "      <td>855</td>\n",
              "      <td>P16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.08</td>\n",
              "      <td>68</td>\n",
              "      <td>396</td>\n",
              "      <td>690</td>\n",
              "      <td>396</td>\n",
              "      <td>690</td>\n",
              "      <td>393</td>\n",
              "      <td>690</td>\n",
              "      <td>319</td>\n",
              "      <td>...</td>\n",
              "      <td>955</td>\n",
              "      <td>378</td>\n",
              "      <td>869</td>\n",
              "      <td>396</td>\n",
              "      <td>869</td>\n",
              "      <td>293</td>\n",
              "      <td>756</td>\n",
              "      <td>419</td>\n",
              "      <td>856</td>\n",
              "      <td>P16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.12</td>\n",
              "      <td>68</td>\n",
              "      <td>368</td>\n",
              "      <td>693</td>\n",
              "      <td>368</td>\n",
              "      <td>693</td>\n",
              "      <td>368</td>\n",
              "      <td>693</td>\n",
              "      <td>324</td>\n",
              "      <td>...</td>\n",
              "      <td>956</td>\n",
              "      <td>379</td>\n",
              "      <td>871</td>\n",
              "      <td>397</td>\n",
              "      <td>858</td>\n",
              "      <td>401</td>\n",
              "      <td>858</td>\n",
              "      <td>419</td>\n",
              "      <td>858</td>\n",
              "      <td>P16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.16</td>\n",
              "      <td>68</td>\n",
              "      <td>371</td>\n",
              "      <td>714</td>\n",
              "      <td>371</td>\n",
              "      <td>694</td>\n",
              "      <td>368</td>\n",
              "      <td>694</td>\n",
              "      <td>313</td>\n",
              "      <td>...</td>\n",
              "      <td>956</td>\n",
              "      <td>404</td>\n",
              "      <td>943</td>\n",
              "      <td>400</td>\n",
              "      <td>858</td>\n",
              "      <td>397</td>\n",
              "      <td>858</td>\n",
              "      <td>422</td>\n",
              "      <td>858</td>\n",
              "      <td>P16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.20</td>\n",
              "      <td>68</td>\n",
              "      <td>369</td>\n",
              "      <td>714</td>\n",
              "      <td>362</td>\n",
              "      <td>714</td>\n",
              "      <td>373</td>\n",
              "      <td>707</td>\n",
              "      <td>326</td>\n",
              "      <td>...</td>\n",
              "      <td>955</td>\n",
              "      <td>402</td>\n",
              "      <td>942</td>\n",
              "      <td>373</td>\n",
              "      <td>870</td>\n",
              "      <td>402</td>\n",
              "      <td>857</td>\n",
              "      <td>420</td>\n",
              "      <td>857</td>\n",
              "      <td>P16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520982</th>\n",
              "      <td>17493</td>\n",
              "      <td>699.72</td>\n",
              "      <td>24</td>\n",
              "      <td>523</td>\n",
              "      <td>768</td>\n",
              "      <td>518</td>\n",
              "      <td>744</td>\n",
              "      <td>518</td>\n",
              "      <td>744</td>\n",
              "      <td>435</td>\n",
              "      <td>...</td>\n",
              "      <td>978</td>\n",
              "      <td>417</td>\n",
              "      <td>948</td>\n",
              "      <td>558</td>\n",
              "      <td>912</td>\n",
              "      <td>562</td>\n",
              "      <td>888</td>\n",
              "      <td>575</td>\n",
              "      <td>840</td>\n",
              "      <td>Fp29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520983</th>\n",
              "      <td>17494</td>\n",
              "      <td>699.76</td>\n",
              "      <td>24</td>\n",
              "      <td>523</td>\n",
              "      <td>769</td>\n",
              "      <td>518</td>\n",
              "      <td>745</td>\n",
              "      <td>518</td>\n",
              "      <td>745</td>\n",
              "      <td>435</td>\n",
              "      <td>...</td>\n",
              "      <td>980</td>\n",
              "      <td>558</td>\n",
              "      <td>902</td>\n",
              "      <td>610</td>\n",
              "      <td>889</td>\n",
              "      <td>562</td>\n",
              "      <td>889</td>\n",
              "      <td>575</td>\n",
              "      <td>841</td>\n",
              "      <td>Fp29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520984</th>\n",
              "      <td>17495</td>\n",
              "      <td>699.80</td>\n",
              "      <td>24</td>\n",
              "      <td>518</td>\n",
              "      <td>769</td>\n",
              "      <td>518</td>\n",
              "      <td>745</td>\n",
              "      <td>518</td>\n",
              "      <td>745</td>\n",
              "      <td>435</td>\n",
              "      <td>...</td>\n",
              "      <td>980</td>\n",
              "      <td>557</td>\n",
              "      <td>902</td>\n",
              "      <td>610</td>\n",
              "      <td>889</td>\n",
              "      <td>562</td>\n",
              "      <td>889</td>\n",
              "      <td>575</td>\n",
              "      <td>841</td>\n",
              "      <td>Fp29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520985</th>\n",
              "      <td>17496</td>\n",
              "      <td>699.84</td>\n",
              "      <td>24</td>\n",
              "      <td>519</td>\n",
              "      <td>768</td>\n",
              "      <td>519</td>\n",
              "      <td>750</td>\n",
              "      <td>519</td>\n",
              "      <td>750</td>\n",
              "      <td>436</td>\n",
              "      <td>...</td>\n",
              "      <td>979</td>\n",
              "      <td>523</td>\n",
              "      <td>888</td>\n",
              "      <td>562</td>\n",
              "      <td>907</td>\n",
              "      <td>540</td>\n",
              "      <td>840</td>\n",
              "      <td>579</td>\n",
              "      <td>840</td>\n",
              "      <td>Fp29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520986</th>\n",
              "      <td>17497</td>\n",
              "      <td>699.88</td>\n",
              "      <td>24</td>\n",
              "      <td>519</td>\n",
              "      <td>762</td>\n",
              "      <td>524</td>\n",
              "      <td>744</td>\n",
              "      <td>519</td>\n",
              "      <td>744</td>\n",
              "      <td>433</td>\n",
              "      <td>...</td>\n",
              "      <td>980</td>\n",
              "      <td>381</td>\n",
              "      <td>938</td>\n",
              "      <td>558</td>\n",
              "      <td>841</td>\n",
              "      <td>515</td>\n",
              "      <td>774</td>\n",
              "      <td>575</td>\n",
              "      <td>841</td>\n",
              "      <td>Fp29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>520987 rows × 38 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc110262-cd2c-4657-88bd-f850da76f761')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc110262-cd2c-4657-88bd-f850da76f761 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc110262-cd2c-4657-88bd-f850da76f761');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c5c5bd70-0ca5-4675-afbf-c536daa03958\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c5c5bd70-0ca5-4675-afbf-c536daa03958')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c5c5bd70-0ca5-4675-afbf-c536daa03958 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d7334b09-af37-4b62-9f8e-1731ee0edf65\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df1')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d7334b09-af37-4b62-9f8e-1731ee0edf65 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df1');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        frame     sec  tracking_id  kp0_x  kp0_y  kp1_x  kp1_y  kp2_x  kp2_y  \\\n",
              "0           1    0.04           68    396    702    392    689    392    702   \n",
              "1           2    0.08           68    396    690    396    690    393    690   \n",
              "2           3    0.12           68    368    693    368    693    368    693   \n",
              "3           4    0.16           68    371    714    371    694    368    694   \n",
              "4           5    0.20           68    369    714    362    714    373    707   \n",
              "...       ...     ...          ...    ...    ...    ...    ...    ...    ...   \n",
              "520982  17493  699.72           24    523    768    518    744    518    744   \n",
              "520983  17494  699.76           24    523    769    518    745    518    745   \n",
              "520984  17495  699.80           24    518    769    518    745    518    745   \n",
              "520985  17496  699.84           24    519    768    519    750    519    750   \n",
              "520986  17497  699.88           24    519    762    524    744    519    744   \n",
              "\n",
              "        kp3_x  ...  kp12_y  kp13_x  kp13_y  kp14_x  kp14_y  kp15_x  kp15_y  \\\n",
              "0         341  ...     955     392     935     374     869     296     756   \n",
              "1         319  ...     955     378     869     396     869     293     756   \n",
              "2         324  ...     956     379     871     397     858     401     858   \n",
              "3         313  ...     956     404     943     400     858     397     858   \n",
              "4         326  ...     955     402     942     373     870     402     857   \n",
              "...       ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "520982    435  ...     978     417     948     558     912     562     888   \n",
              "520983    435  ...     980     558     902     610     889     562     889   \n",
              "520984    435  ...     980     557     902     610     889     562     889   \n",
              "520985    436  ...     979     523     888     562     907     540     840   \n",
              "520986    433  ...     980     381     938     558     841     515     774   \n",
              "\n",
              "        kp16_x  kp16_y  source_video  \n",
              "0          422     855           P16  \n",
              "1          419     856           P16  \n",
              "2          419     858           P16  \n",
              "3          422     858           P16  \n",
              "4          420     857           P16  \n",
              "...        ...     ...           ...  \n",
              "520982     575     840          Fp29  \n",
              "520983     575     841          Fp29  \n",
              "520984     575     841          Fp29  \n",
              "520985     579     840          Fp29  \n",
              "520986     575     841          Fp29  \n",
              "\n",
              "[520987 rows x 38 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "HcqzhYAZMYLF",
        "outputId": "16672fe8-dedc-4bd2-debe-8da1fc81c6e7"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'angrily_engaged'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-cd51a4b1545e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mengagement_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_engagement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"video_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds_rounded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"merge_key\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mengagement_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdf_keypoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_keypoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"merge_key\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mengagement_lookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengagement_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Drop helper columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4698\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4699\u001b[0m         \"\"\"\n\u001b[0;32m-> 4700\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4701\u001b[0m         return self._constructor(new_values, index=self.index, copy=False).__finalize__(\n\u001b[1;32m   4702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         return lib.map_infer_mask(\n",
            "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-cd51a4b1545e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mengagement_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_engagement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"video_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds_rounded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"merge_key\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mengagement_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdf_keypoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_keypoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"merge_key\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mengagement_lookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengagement_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Drop helper columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'angrily_engaged'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "df_keypoints = pd.read_csv(\"/content/drive/MyDrive/merged_all_keypoints_b_label_only.csv\")\n",
        "df_engagement = pd.read_csv(\"/content/drive/MyDrive/engagement_cleaned.csv\")\n",
        "\n",
        "# Round seconds in both dataframes\n",
        "df_keypoints[\"sec_rounded\"] = df_keypoints[\"sec\"].round().astype(int)\n",
        "df_engagement[\"seconds_rounded\"] = df_engagement[\"seconds\"].round().astype(int)\n",
        "\n",
        "# Create a helper column for matching\n",
        "df_keypoints[\"merge_key\"] = list(zip(df_keypoints[\"source_video\"], df_keypoints[\"sec_rounded\"]))\n",
        "df_engagement[\"merge_key\"] = list(zip(df_engagement[\"video_id\"], df_engagement[\"seconds_rounded\"]))\n",
        "\n",
        "# Create a dictionary mapping (video_id, second) to the engagement labels\n",
        "engagement_lookup = {}\n",
        "\n",
        "for _, row in df_engagement.iterrows():\n",
        "    video = row[\"video_id\"]\n",
        "    second = int(row[\"seconds_rounded\"])\n",
        "    labels = row.drop([\"video_id\", \"seconds\", \"seconds_rounded\", \"merge_key\"])\n",
        "\n",
        "    for offset in range(-15, 16):  # Tolerance of ±15 seconds\n",
        "        engagement_lookup[(video, second + offset)] = labels\n",
        "\n",
        "# Apply engagement labels to keypoints data\n",
        "engagement_columns = df_engagement.columns.difference([\"video_id\", \"seconds\", \"seconds_rounded\", \"merge_key\"])\n",
        "for col in engagement_columns:\n",
        "    df_keypoints[col] = df_keypoints[\"merge_key\"].map(lambda key: engagement_lookup.get(key, pd.Series([np.nan]*len(engagement_columns)))[col])\n",
        "\n",
        "# Drop helper columns\n",
        "df_keypoints.drop(columns=[\"sec_rounded\", \"merge_key\"], inplace=True)\n",
        "\n",
        "# Save the merged dataframe\n",
        "df_keypoints.to_csv(\"merged_with_engagement_labels.csv\", index=False)\n",
        "\n",
        "print(\"✅ Merged file saved as: merged_with_engagement_labels.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSideMHK2VCV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq1BS-AtO1Wz",
        "outputId": "a87011bb-8380-463b-8199-3a5c2ff023de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Merged file saved as: merged_with_engagement_labels.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "df_keypoints = pd.read_csv(\"/content/drive/MyDrive/merged_all_keypoints_b_label_only.csv\")\n",
        "df_engagement = pd.read_csv(\"/content/drive/MyDrive/engagement_cleaned.csv\")\n",
        "\n",
        "# Round seconds in both dataframes\n",
        "df_keypoints[\"sec_rounded\"] = df_keypoints[\"sec\"].round().astype(int)\n",
        "df_engagement[\"seconds_rounded\"] = df_engagement[\"seconds\"].round().astype(int)\n",
        "\n",
        "# Create a helper column for matching\n",
        "df_keypoints[\"merge_key\"] = list(zip(df_keypoints[\"source_video\"], df_keypoints[\"sec_rounded\"]))\n",
        "df_engagement[\"merge_key\"] = list(zip(df_engagement[\"video_id\"], df_engagement[\"seconds_rounded\"]))\n",
        "\n",
        "# Create a dictionary mapping (video_id, second) to the engagement labels\n",
        "engagement_lookup = {}\n",
        "\n",
        "for _, row in df_engagement.iterrows():\n",
        "    video = row[\"video_id\"]\n",
        "    second = int(row[\"seconds_rounded\"])\n",
        "    labels = row.drop([\"video_id\", \"seconds\", \"seconds_rounded\", \"merge_key\"])\n",
        "\n",
        "    for offset in range(-15, 16):  # Tolerance of ±15 seconds\n",
        "        engagement_lookup[(video, second + offset)] = labels.to_dict() # Convert labels to a dictionary\n",
        "\n",
        "# Apply engagement labels to keypoints data\n",
        "engagement_columns = df_engagement.columns.difference([\"video_id\", \"seconds\", \"seconds_rounded\", \"merge_key\"])\n",
        "for col in engagement_columns:\n",
        "    df_keypoints[col] = df_keypoints[\"merge_key\"].map(lambda key: engagement_lookup.get(key, {}).get(col, np.nan)) # Access using column name and handle missing values\n",
        "\n",
        "# Drop helper columns\n",
        "df_keypoints.drop(columns=[\"sec_rounded\", \"merge_key\"], inplace=True)\n",
        "\n",
        "# Save the merged dataframe\n",
        "df_keypoints.to_csv(\"merged_with_engagement_labels.csv\", index=False)\n",
        "\n",
        "print(\"✅ Merged file saved as: merged_with_engagement_labels.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24cI9WwCfm-6",
        "outputId": "d6e1361a-3975-4297-d795-c008d0839e22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Merged with forward matching saved to: merged_with_forward_labels_with_tasks.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "df_keypoints = pd.read_csv(\"/content/drive/MyDrive/merged_all_keypoints_b_label_only.csv\")\n",
        "df_engagement = pd.read_csv(\"engagement_cleaned.csv\",sep=';')\n",
        "\n",
        "# Round seconds\n",
        "df_keypoints[\"sec_rounded\"] = df_keypoints[\"sec\"].round().astype(int)\n",
        "df_engagement[\"seconds_rounded\"] = df_engagement[\"seconds\"].round().astype(int)\n",
        "\n",
        "# Sort for forward search\n",
        "df_keypoints.sort_values(by=[\"source_video\", \"sec_rounded\"], inplace=True)\n",
        "df_engagement.sort_values(by=[\"video_id\", \"seconds_rounded\"], inplace=True)\n",
        "\n",
        "# Create a list to store matches\n",
        "matched_rows = []\n",
        "\n",
        "# Iterate over keypoints\n",
        "for idx, row in df_keypoints.iterrows():\n",
        "    video = row[\"source_video\"]\n",
        "    frame_sec = row[\"sec_rounded\"]\n",
        "\n",
        "    # Filter engagement labels for same video and future timestamps\n",
        "    future_engagements = df_engagement[\n",
        "        (df_engagement[\"video_id\"] == video) &\n",
        "        (df_engagement[\"seconds_rounded\"] >= frame_sec) &\n",
        "        (df_engagement[\"seconds_rounded\"] <= frame_sec + 30)\n",
        "    ]\n",
        "\n",
        "    if not future_engagements.empty:\n",
        "        # Take the first future label (i.e., nearest next engagement)\n",
        "        label_row = future_engagements.iloc[0]\n",
        "        label_data = label_row.drop([\"video_id\", \"seconds\", \"seconds_rounded\", \"merge_key\"], errors=\"ignore\").to_dict()\n",
        "    else:\n",
        "        label_data = {col: np.nan for col in df_engagement.columns if col not in [\"video_id\", \"seconds\", \"seconds_rounded\", \"merge_key\"]}\n",
        "\n",
        "    # Append label columns to the current keypoint row\n",
        "    new_row = row.to_dict()\n",
        "    new_row.update(label_data)\n",
        "    matched_rows.append(new_row)\n",
        "\n",
        "# Convert list to DataFrame\n",
        "merged_df = pd.DataFrame(matched_rows)\n",
        "\n",
        "# Drop helper column\n",
        "merged_df.drop(columns=[\"sec_rounded\"], inplace=True)\n",
        "\n",
        "# Save the new merged DataFrame\n",
        "merged_df.to_csv(\"merged_with_forward_labels.csv\", index=False)\n",
        "\n",
        "print(\"✅ Merged with forward matching saved to: merged_with_forward_labels_with_tasks.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "SogBdqRF3JYE",
        "outputId": "562e2c55-5859-4b11-8ff9-355f01780df5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4abcaf40-eb95-4411-b353-c3a0c8142eb2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frame</th>\n",
              "      <th>sec</th>\n",
              "      <th>tracking_id</th>\n",
              "      <th>kp0_x</th>\n",
              "      <th>kp0_y</th>\n",
              "      <th>kp1_x</th>\n",
              "      <th>kp1_y</th>\n",
              "      <th>kp2_x</th>\n",
              "      <th>kp2_y</th>\n",
              "      <th>kp3_x</th>\n",
              "      <th>...</th>\n",
              "      <th>kp15_y</th>\n",
              "      <th>kp16_x</th>\n",
              "      <th>kp16_y</th>\n",
              "      <th>source_video</th>\n",
              "      <th>time</th>\n",
              "      <th>watching</th>\n",
              "      <th>playing_engaged</th>\n",
              "      <th>playfully_engaged</th>\n",
              "      <th>angrily_engaged</th>\n",
              "      <th>task</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0.08</td>\n",
              "      <td>164</td>\n",
              "      <td>348</td>\n",
              "      <td>796</td>\n",
              "      <td>348</td>\n",
              "      <td>782</td>\n",
              "      <td>337</td>\n",
              "      <td>792</td>\n",
              "      <td>291</td>\n",
              "      <td>...</td>\n",
              "      <td>868</td>\n",
              "      <td>405</td>\n",
              "      <td>868</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0.12</td>\n",
              "      <td>164</td>\n",
              "      <td>348</td>\n",
              "      <td>797</td>\n",
              "      <td>351</td>\n",
              "      <td>779</td>\n",
              "      <td>337</td>\n",
              "      <td>793</td>\n",
              "      <td>340</td>\n",
              "      <td>...</td>\n",
              "      <td>853</td>\n",
              "      <td>407</td>\n",
              "      <td>877</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0.16</td>\n",
              "      <td>164</td>\n",
              "      <td>350</td>\n",
              "      <td>796</td>\n",
              "      <td>350</td>\n",
              "      <td>781</td>\n",
              "      <td>338</td>\n",
              "      <td>796</td>\n",
              "      <td>342</td>\n",
              "      <td>...</td>\n",
              "      <td>879</td>\n",
              "      <td>398</td>\n",
              "      <td>879</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>0.20</td>\n",
              "      <td>164</td>\n",
              "      <td>350</td>\n",
              "      <td>798</td>\n",
              "      <td>350</td>\n",
              "      <td>781</td>\n",
              "      <td>337</td>\n",
              "      <td>792</td>\n",
              "      <td>342</td>\n",
              "      <td>...</td>\n",
              "      <td>876</td>\n",
              "      <td>346</td>\n",
              "      <td>927</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>0.24</td>\n",
              "      <td>164</td>\n",
              "      <td>351</td>\n",
              "      <td>799</td>\n",
              "      <td>351</td>\n",
              "      <td>787</td>\n",
              "      <td>338</td>\n",
              "      <td>793</td>\n",
              "      <td>297</td>\n",
              "      <td>...</td>\n",
              "      <td>875</td>\n",
              "      <td>383</td>\n",
              "      <td>875</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520982</th>\n",
              "      <td>15101</td>\n",
              "      <td>604.04</td>\n",
              "      <td>68</td>\n",
              "      <td>472</td>\n",
              "      <td>737</td>\n",
              "      <td>486</td>\n",
              "      <td>716</td>\n",
              "      <td>449</td>\n",
              "      <td>723</td>\n",
              "      <td>505</td>\n",
              "      <td>...</td>\n",
              "      <td>845</td>\n",
              "      <td>528</td>\n",
              "      <td>924</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520983</th>\n",
              "      <td>15102</td>\n",
              "      <td>604.08</td>\n",
              "      <td>68</td>\n",
              "      <td>473</td>\n",
              "      <td>737</td>\n",
              "      <td>487</td>\n",
              "      <td>716</td>\n",
              "      <td>450</td>\n",
              "      <td>723</td>\n",
              "      <td>505</td>\n",
              "      <td>...</td>\n",
              "      <td>845</td>\n",
              "      <td>529</td>\n",
              "      <td>910</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520984</th>\n",
              "      <td>15103</td>\n",
              "      <td>604.12</td>\n",
              "      <td>68</td>\n",
              "      <td>473</td>\n",
              "      <td>737</td>\n",
              "      <td>487</td>\n",
              "      <td>716</td>\n",
              "      <td>450</td>\n",
              "      <td>723</td>\n",
              "      <td>505</td>\n",
              "      <td>...</td>\n",
              "      <td>844</td>\n",
              "      <td>529</td>\n",
              "      <td>923</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520985</th>\n",
              "      <td>15104</td>\n",
              "      <td>604.16</td>\n",
              "      <td>68</td>\n",
              "      <td>474</td>\n",
              "      <td>738</td>\n",
              "      <td>488</td>\n",
              "      <td>716</td>\n",
              "      <td>451</td>\n",
              "      <td>723</td>\n",
              "      <td>502</td>\n",
              "      <td>...</td>\n",
              "      <td>845</td>\n",
              "      <td>530</td>\n",
              "      <td>923</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520986</th>\n",
              "      <td>15105</td>\n",
              "      <td>604.20</td>\n",
              "      <td>68</td>\n",
              "      <td>474</td>\n",
              "      <td>738</td>\n",
              "      <td>488</td>\n",
              "      <td>709</td>\n",
              "      <td>451</td>\n",
              "      <td>723</td>\n",
              "      <td>502</td>\n",
              "      <td>...</td>\n",
              "      <td>845</td>\n",
              "      <td>530</td>\n",
              "      <td>923</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>520987 rows × 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4abcaf40-eb95-4411-b353-c3a0c8142eb2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4abcaf40-eb95-4411-b353-c3a0c8142eb2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4abcaf40-eb95-4411-b353-c3a0c8142eb2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-41fd7f74-c0b8-4d23-ab7d-219f420a3056\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41fd7f74-c0b8-4d23-ab7d-219f420a3056')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-41fd7f74-c0b8-4d23-ab7d-219f420a3056 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ae4efb8c-1ca4-4480-b6f9-fffd9dd2e608\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('merged_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ae4efb8c-1ca4-4480-b6f9-fffd9dd2e608 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('merged_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        frame     sec  tracking_id  kp0_x  kp0_y  kp1_x  kp1_y  kp2_x  kp2_y  \\\n",
              "0           2    0.08          164    348    796    348    782    337    792   \n",
              "1           3    0.12          164    348    797    351    779    337    793   \n",
              "2           4    0.16          164    350    796    350    781    338    796   \n",
              "3           5    0.20          164    350    798    350    781    337    792   \n",
              "4           6    0.24          164    351    799    351    787    338    793   \n",
              "...       ...     ...          ...    ...    ...    ...    ...    ...    ...   \n",
              "520982  15101  604.04           68    472    737    486    716    449    723   \n",
              "520983  15102  604.08           68    473    737    487    716    450    723   \n",
              "520984  15103  604.12           68    473    737    487    716    450    723   \n",
              "520985  15104  604.16           68    474    738    488    716    451    723   \n",
              "520986  15105  604.20           68    474    738    488    709    451    723   \n",
              "\n",
              "        kp3_x  ...  kp15_y  kp16_x  kp16_y  source_video      time  watching  \\\n",
              "0         291  ...     868     405     868          Fp17  00:00:22       1.0   \n",
              "1         340  ...     853     407     877          Fp17  00:00:22       1.0   \n",
              "2         342  ...     879     398     879          Fp17  00:00:22       1.0   \n",
              "3         342  ...     876     346     927          Fp17  00:00:22       1.0   \n",
              "4         297  ...     875     383     875          Fp17  00:00:22       1.0   \n",
              "...       ...  ...     ...     ...     ...           ...       ...       ...   \n",
              "520982    505  ...     845     528     924           P16       NaN       NaN   \n",
              "520983    505  ...     845     529     910           P16       NaN       NaN   \n",
              "520984    505  ...     844     529     923           P16       NaN       NaN   \n",
              "520985    502  ...     845     530     923           P16       NaN       NaN   \n",
              "520986    502  ...     845     530     923           P16       NaN       NaN   \n",
              "\n",
              "        playing_engaged  playfully_engaged  angrily_engaged  task  \n",
              "0                   2.0                0.0              0.0     p  \n",
              "1                   2.0                0.0              0.0     p  \n",
              "2                   2.0                0.0              0.0     p  \n",
              "3                   2.0                0.0              0.0     p  \n",
              "4                   2.0                0.0              0.0     p  \n",
              "...                 ...                ...              ...   ...  \n",
              "520982              NaN                NaN              NaN   NaN  \n",
              "520983              NaN                NaN              NaN   NaN  \n",
              "520984              NaN                NaN              NaN   NaN  \n",
              "520985              NaN                NaN              NaN   NaN  \n",
              "520986              NaN                NaN              NaN   NaN  \n",
              "\n",
              "[520987 rows x 44 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhNT2UrW5J9f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPqJWaZr5KAM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPVtMJuO5KC3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iSAU4rb5KFu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "so_0w8pr5KIZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gTFKnRq5KLf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG6BpqiT5KNX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMNPwT0q5KP9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUHRiO-C5KTX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_s0HqESReDr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_keypoints=pd.read_csv(\"merged_with_forward_labels.csv\",sep=',',low_memory=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_keypoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "35Gdny1kKzmv",
        "outputId": "87970f14-0c63-41af-fb2b-4ed06c55672d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        frame     sec  tracking_id  kp0_x  kp0_y  kp1_x  kp1_y  kp2_x  kp2_y  \\\n",
              "0           2    0.08          164    348    796    348    782    337    792   \n",
              "1           3    0.12          164    348    797    351    779    337    793   \n",
              "2           4    0.16          164    350    796    350    781    338    796   \n",
              "3           5    0.20          164    350    798    350    781    337    792   \n",
              "4           6    0.24          164    351    799    351    787    338    793   \n",
              "...       ...     ...          ...    ...    ...    ...    ...    ...    ...   \n",
              "520982  15101  604.04           68    472    737    486    716    449    723   \n",
              "520983  15102  604.08           68    473    737    487    716    450    723   \n",
              "520984  15103  604.12           68    473    737    487    716    450    723   \n",
              "520985  15104  604.16           68    474    738    488    716    451    723   \n",
              "520986  15105  604.20           68    474    738    488    709    451    723   \n",
              "\n",
              "        kp3_x  ...  kp15_y  kp16_x  kp16_y  source_video      time  watching  \\\n",
              "0         291  ...     868     405     868          Fp17  00:00:22       1.0   \n",
              "1         340  ...     853     407     877          Fp17  00:00:22       1.0   \n",
              "2         342  ...     879     398     879          Fp17  00:00:22       1.0   \n",
              "3         342  ...     876     346     927          Fp17  00:00:22       1.0   \n",
              "4         297  ...     875     383     875          Fp17  00:00:22       1.0   \n",
              "...       ...  ...     ...     ...     ...           ...       ...       ...   \n",
              "520982    505  ...     845     528     924           P16       NaN       NaN   \n",
              "520983    505  ...     845     529     910           P16       NaN       NaN   \n",
              "520984    505  ...     844     529     923           P16       NaN       NaN   \n",
              "520985    502  ...     845     530     923           P16       NaN       NaN   \n",
              "520986    502  ...     845     530     923           P16       NaN       NaN   \n",
              "\n",
              "        playing_engaged  playfully_engaged  angrily_engaged  task  \n",
              "0                   2.0                0.0              0.0     p  \n",
              "1                   2.0                0.0              0.0     p  \n",
              "2                   2.0                0.0              0.0     p  \n",
              "3                   2.0                0.0              0.0     p  \n",
              "4                   2.0                0.0              0.0     p  \n",
              "...                 ...                ...              ...   ...  \n",
              "520982              NaN                NaN              NaN   NaN  \n",
              "520983              NaN                NaN              NaN   NaN  \n",
              "520984              NaN                NaN              NaN   NaN  \n",
              "520985              NaN                NaN              NaN   NaN  \n",
              "520986              NaN                NaN              NaN   NaN  \n",
              "\n",
              "[520987 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0bfa7e12-454f-4aba-8b69-f0cf47568867\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frame</th>\n",
              "      <th>sec</th>\n",
              "      <th>tracking_id</th>\n",
              "      <th>kp0_x</th>\n",
              "      <th>kp0_y</th>\n",
              "      <th>kp1_x</th>\n",
              "      <th>kp1_y</th>\n",
              "      <th>kp2_x</th>\n",
              "      <th>kp2_y</th>\n",
              "      <th>kp3_x</th>\n",
              "      <th>...</th>\n",
              "      <th>kp15_y</th>\n",
              "      <th>kp16_x</th>\n",
              "      <th>kp16_y</th>\n",
              "      <th>source_video</th>\n",
              "      <th>time</th>\n",
              "      <th>watching</th>\n",
              "      <th>playing_engaged</th>\n",
              "      <th>playfully_engaged</th>\n",
              "      <th>angrily_engaged</th>\n",
              "      <th>task</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0.08</td>\n",
              "      <td>164</td>\n",
              "      <td>348</td>\n",
              "      <td>796</td>\n",
              "      <td>348</td>\n",
              "      <td>782</td>\n",
              "      <td>337</td>\n",
              "      <td>792</td>\n",
              "      <td>291</td>\n",
              "      <td>...</td>\n",
              "      <td>868</td>\n",
              "      <td>405</td>\n",
              "      <td>868</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0.12</td>\n",
              "      <td>164</td>\n",
              "      <td>348</td>\n",
              "      <td>797</td>\n",
              "      <td>351</td>\n",
              "      <td>779</td>\n",
              "      <td>337</td>\n",
              "      <td>793</td>\n",
              "      <td>340</td>\n",
              "      <td>...</td>\n",
              "      <td>853</td>\n",
              "      <td>407</td>\n",
              "      <td>877</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0.16</td>\n",
              "      <td>164</td>\n",
              "      <td>350</td>\n",
              "      <td>796</td>\n",
              "      <td>350</td>\n",
              "      <td>781</td>\n",
              "      <td>338</td>\n",
              "      <td>796</td>\n",
              "      <td>342</td>\n",
              "      <td>...</td>\n",
              "      <td>879</td>\n",
              "      <td>398</td>\n",
              "      <td>879</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>0.20</td>\n",
              "      <td>164</td>\n",
              "      <td>350</td>\n",
              "      <td>798</td>\n",
              "      <td>350</td>\n",
              "      <td>781</td>\n",
              "      <td>337</td>\n",
              "      <td>792</td>\n",
              "      <td>342</td>\n",
              "      <td>...</td>\n",
              "      <td>876</td>\n",
              "      <td>346</td>\n",
              "      <td>927</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>0.24</td>\n",
              "      <td>164</td>\n",
              "      <td>351</td>\n",
              "      <td>799</td>\n",
              "      <td>351</td>\n",
              "      <td>787</td>\n",
              "      <td>338</td>\n",
              "      <td>793</td>\n",
              "      <td>297</td>\n",
              "      <td>...</td>\n",
              "      <td>875</td>\n",
              "      <td>383</td>\n",
              "      <td>875</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520982</th>\n",
              "      <td>15101</td>\n",
              "      <td>604.04</td>\n",
              "      <td>68</td>\n",
              "      <td>472</td>\n",
              "      <td>737</td>\n",
              "      <td>486</td>\n",
              "      <td>716</td>\n",
              "      <td>449</td>\n",
              "      <td>723</td>\n",
              "      <td>505</td>\n",
              "      <td>...</td>\n",
              "      <td>845</td>\n",
              "      <td>528</td>\n",
              "      <td>924</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520983</th>\n",
              "      <td>15102</td>\n",
              "      <td>604.08</td>\n",
              "      <td>68</td>\n",
              "      <td>473</td>\n",
              "      <td>737</td>\n",
              "      <td>487</td>\n",
              "      <td>716</td>\n",
              "      <td>450</td>\n",
              "      <td>723</td>\n",
              "      <td>505</td>\n",
              "      <td>...</td>\n",
              "      <td>845</td>\n",
              "      <td>529</td>\n",
              "      <td>910</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520984</th>\n",
              "      <td>15103</td>\n",
              "      <td>604.12</td>\n",
              "      <td>68</td>\n",
              "      <td>473</td>\n",
              "      <td>737</td>\n",
              "      <td>487</td>\n",
              "      <td>716</td>\n",
              "      <td>450</td>\n",
              "      <td>723</td>\n",
              "      <td>505</td>\n",
              "      <td>...</td>\n",
              "      <td>844</td>\n",
              "      <td>529</td>\n",
              "      <td>923</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520985</th>\n",
              "      <td>15104</td>\n",
              "      <td>604.16</td>\n",
              "      <td>68</td>\n",
              "      <td>474</td>\n",
              "      <td>738</td>\n",
              "      <td>488</td>\n",
              "      <td>716</td>\n",
              "      <td>451</td>\n",
              "      <td>723</td>\n",
              "      <td>502</td>\n",
              "      <td>...</td>\n",
              "      <td>845</td>\n",
              "      <td>530</td>\n",
              "      <td>923</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520986</th>\n",
              "      <td>15105</td>\n",
              "      <td>604.20</td>\n",
              "      <td>68</td>\n",
              "      <td>474</td>\n",
              "      <td>738</td>\n",
              "      <td>488</td>\n",
              "      <td>709</td>\n",
              "      <td>451</td>\n",
              "      <td>723</td>\n",
              "      <td>502</td>\n",
              "      <td>...</td>\n",
              "      <td>845</td>\n",
              "      <td>530</td>\n",
              "      <td>923</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>520987 rows × 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bfa7e12-454f-4aba-8b69-f0cf47568867')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0bfa7e12-454f-4aba-8b69-f0cf47568867 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0bfa7e12-454f-4aba-8b69-f0cf47568867');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1857d191-589f-4ce7-9ddc-17364ab3231b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1857d191-589f-4ce7-9ddc-17364ab3231b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1857d191-589f-4ce7-9ddc-17364ab3231b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0b521cb8-ae7a-4439-86fc-0003b03be13d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_keypoints')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0b521cb8-ae7a-4439-86fc-0003b03be13d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_keypoints');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_keypoints"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SdWoiIJR0Qo"
      },
      "outputs": [],
      "source": [
        "merged_df=df_keypoints"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 1"
      ],
      "metadata": {
        "id": "m_J4kLETREm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load the Data --\n",
        "df=merged_df[merged_df[\"task\"]=='p']\n",
        "print(\"Data loaded successfully.\")\n",
        "print(\"Shape of the dataframe:\", df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq5VuVnEMmk3",
        "outputId": "ae88413c-b278-423d-b316-291dc659e8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Shape of the dataframe: (47208, 44)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "BBIBbQSKMnwg",
        "outputId": "1f45b0b5-36ed-4d92-a083-4fd0123215de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        frame     sec  tracking_id  kp0_x  kp0_y  kp1_x  kp1_y  kp2_x  kp2_y  \\\n",
              "0           2    0.08          164    348    796    348    782    337    792   \n",
              "1           3    0.12          164    348    797    351    779    337    793   \n",
              "2           4    0.16          164    350    796    350    781    338    796   \n",
              "3           5    0.20          164    350    798    350    781    337    792   \n",
              "4           6    0.24          164    351    799    351    787    338    793   \n",
              "...       ...     ...          ...    ...    ...    ...    ...    ...    ...   \n",
              "404155   3758  150.32          233    220    568    214    537    189    558   \n",
              "404156   3759  150.36          233    216    578    216    537    191    558   \n",
              "404157   3760  150.40          233    215    568    215    537    190    558   \n",
              "404158   3761  150.44          233    216    570    216    539    192    560   \n",
              "404159   3762  150.48          233    222    571    222    540    198    561   \n",
              "\n",
              "        kp3_x  ...  kp15_y  kp16_x  kp16_y  source_video      time  watching  \\\n",
              "0         291  ...     868     405     868          Fp17  00:00:22       1.0   \n",
              "1         340  ...     853     407     877          Fp17  00:00:22       1.0   \n",
              "2         342  ...     879     398     879          Fp17  00:00:22       1.0   \n",
              "3         342  ...     876     346     927          Fp17  00:00:22       1.0   \n",
              "4         297  ...     875     383     875          Fp17  00:00:22       1.0   \n",
              "...       ...  ...     ...     ...     ...           ...       ...       ...   \n",
              "404155    108  ...     960     357     888          Fp40  00:02:30       1.0   \n",
              "404156    197  ...     681     311     671          Fp40  00:02:30       1.0   \n",
              "404157    203  ...     774     334     733          Fp40  00:02:30       1.0   \n",
              "404158    210  ...     756     130     828          Fp40  00:02:30       1.0   \n",
              "404159    107  ...     859     186     818          Fp40  00:02:30       1.0   \n",
              "\n",
              "        playing_engaged  playfully_engaged  angrily_engaged  task  \n",
              "0                   2.0                0.0              0.0     p  \n",
              "1                   2.0                0.0              0.0     p  \n",
              "2                   2.0                0.0              0.0     p  \n",
              "3                   2.0                0.0              0.0     p  \n",
              "4                   2.0                0.0              0.0     p  \n",
              "...                 ...                ...              ...   ...  \n",
              "404155              0.0                0.0              0.0     p  \n",
              "404156              0.0                0.0              0.0     p  \n",
              "404157              0.0                0.0              0.0     p  \n",
              "404158              0.0                0.0              0.0     p  \n",
              "404159              0.0                0.0              0.0     p  \n",
              "\n",
              "[47208 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa0740ed-f583-4a90-9284-d75a48624515\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frame</th>\n",
              "      <th>sec</th>\n",
              "      <th>tracking_id</th>\n",
              "      <th>kp0_x</th>\n",
              "      <th>kp0_y</th>\n",
              "      <th>kp1_x</th>\n",
              "      <th>kp1_y</th>\n",
              "      <th>kp2_x</th>\n",
              "      <th>kp2_y</th>\n",
              "      <th>kp3_x</th>\n",
              "      <th>...</th>\n",
              "      <th>kp15_y</th>\n",
              "      <th>kp16_x</th>\n",
              "      <th>kp16_y</th>\n",
              "      <th>source_video</th>\n",
              "      <th>time</th>\n",
              "      <th>watching</th>\n",
              "      <th>playing_engaged</th>\n",
              "      <th>playfully_engaged</th>\n",
              "      <th>angrily_engaged</th>\n",
              "      <th>task</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0.08</td>\n",
              "      <td>164</td>\n",
              "      <td>348</td>\n",
              "      <td>796</td>\n",
              "      <td>348</td>\n",
              "      <td>782</td>\n",
              "      <td>337</td>\n",
              "      <td>792</td>\n",
              "      <td>291</td>\n",
              "      <td>...</td>\n",
              "      <td>868</td>\n",
              "      <td>405</td>\n",
              "      <td>868</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0.12</td>\n",
              "      <td>164</td>\n",
              "      <td>348</td>\n",
              "      <td>797</td>\n",
              "      <td>351</td>\n",
              "      <td>779</td>\n",
              "      <td>337</td>\n",
              "      <td>793</td>\n",
              "      <td>340</td>\n",
              "      <td>...</td>\n",
              "      <td>853</td>\n",
              "      <td>407</td>\n",
              "      <td>877</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0.16</td>\n",
              "      <td>164</td>\n",
              "      <td>350</td>\n",
              "      <td>796</td>\n",
              "      <td>350</td>\n",
              "      <td>781</td>\n",
              "      <td>338</td>\n",
              "      <td>796</td>\n",
              "      <td>342</td>\n",
              "      <td>...</td>\n",
              "      <td>879</td>\n",
              "      <td>398</td>\n",
              "      <td>879</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>0.20</td>\n",
              "      <td>164</td>\n",
              "      <td>350</td>\n",
              "      <td>798</td>\n",
              "      <td>350</td>\n",
              "      <td>781</td>\n",
              "      <td>337</td>\n",
              "      <td>792</td>\n",
              "      <td>342</td>\n",
              "      <td>...</td>\n",
              "      <td>876</td>\n",
              "      <td>346</td>\n",
              "      <td>927</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>0.24</td>\n",
              "      <td>164</td>\n",
              "      <td>351</td>\n",
              "      <td>799</td>\n",
              "      <td>351</td>\n",
              "      <td>787</td>\n",
              "      <td>338</td>\n",
              "      <td>793</td>\n",
              "      <td>297</td>\n",
              "      <td>...</td>\n",
              "      <td>875</td>\n",
              "      <td>383</td>\n",
              "      <td>875</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404155</th>\n",
              "      <td>3758</td>\n",
              "      <td>150.32</td>\n",
              "      <td>233</td>\n",
              "      <td>220</td>\n",
              "      <td>568</td>\n",
              "      <td>214</td>\n",
              "      <td>537</td>\n",
              "      <td>189</td>\n",
              "      <td>558</td>\n",
              "      <td>108</td>\n",
              "      <td>...</td>\n",
              "      <td>960</td>\n",
              "      <td>357</td>\n",
              "      <td>888</td>\n",
              "      <td>Fp40</td>\n",
              "      <td>00:02:30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404156</th>\n",
              "      <td>3759</td>\n",
              "      <td>150.36</td>\n",
              "      <td>233</td>\n",
              "      <td>216</td>\n",
              "      <td>578</td>\n",
              "      <td>216</td>\n",
              "      <td>537</td>\n",
              "      <td>191</td>\n",
              "      <td>558</td>\n",
              "      <td>197</td>\n",
              "      <td>...</td>\n",
              "      <td>681</td>\n",
              "      <td>311</td>\n",
              "      <td>671</td>\n",
              "      <td>Fp40</td>\n",
              "      <td>00:02:30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404157</th>\n",
              "      <td>3760</td>\n",
              "      <td>150.40</td>\n",
              "      <td>233</td>\n",
              "      <td>215</td>\n",
              "      <td>568</td>\n",
              "      <td>215</td>\n",
              "      <td>537</td>\n",
              "      <td>190</td>\n",
              "      <td>558</td>\n",
              "      <td>203</td>\n",
              "      <td>...</td>\n",
              "      <td>774</td>\n",
              "      <td>334</td>\n",
              "      <td>733</td>\n",
              "      <td>Fp40</td>\n",
              "      <td>00:02:30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404158</th>\n",
              "      <td>3761</td>\n",
              "      <td>150.44</td>\n",
              "      <td>233</td>\n",
              "      <td>216</td>\n",
              "      <td>570</td>\n",
              "      <td>216</td>\n",
              "      <td>539</td>\n",
              "      <td>192</td>\n",
              "      <td>560</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>756</td>\n",
              "      <td>130</td>\n",
              "      <td>828</td>\n",
              "      <td>Fp40</td>\n",
              "      <td>00:02:30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404159</th>\n",
              "      <td>3762</td>\n",
              "      <td>150.48</td>\n",
              "      <td>233</td>\n",
              "      <td>222</td>\n",
              "      <td>571</td>\n",
              "      <td>222</td>\n",
              "      <td>540</td>\n",
              "      <td>198</td>\n",
              "      <td>561</td>\n",
              "      <td>107</td>\n",
              "      <td>...</td>\n",
              "      <td>859</td>\n",
              "      <td>186</td>\n",
              "      <td>818</td>\n",
              "      <td>Fp40</td>\n",
              "      <td>00:02:30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47208 rows × 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa0740ed-f583-4a90-9284-d75a48624515')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fa0740ed-f583-4a90-9284-d75a48624515 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fa0740ed-f583-4a90-9284-d75a48624515');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-07d57cb7-ca79-4519-a176-b7f7c28d81fc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-07d57cb7-ca79-4519-a176-b7f7c28d81fc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-07d57cb7-ca79-4519-a176-b7f7c28d81fc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_8bfda8af-99ca-4104-9116-42edb3196613\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8bfda8af-99ca-4104-9116-42edb3196613 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- 2. Define Target (y) and Prepare for Feature (X) Selection ---\n",
        "target_column = 'playfully_engaged'\n",
        "video_id_column = 'source_video' # IMPORTANT: Verify this is the correct column name for video IDs in your CSV\n",
        "\n",
        "if target_column not in df.columns:\n",
        "    print(f\"Error: Target column '{target_column}' not found in the dataframe.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "if video_id_column not in df.columns:\n",
        "    print(f\"Error: Video ID column '{video_id_column}' for data splitting not found.\")\n",
        "    print(f\"Please ensure '{video_id_column}' exists or update the 'video_id_column' variable.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "# Drop rows where the target variable is NaN, as they cannot be used for training or evaluation.\n",
        "df.dropna(subset=[target_column], inplace=True)\n",
        "print(f\"\\nShape of dataframe after dropping NaNs in target column '{target_column}': {df.shape}\")\n",
        "\n",
        "# Convert target variable to numeric if it's not already\n",
        "if df[target_column].dtype == 'bool':\n",
        "    df[target_column] = df[target_column].astype(int)\n",
        "elif df[target_column].dtype == 'object':\n",
        "    print(f\"Target column '{target_column}' is of object type. Attempting to encode it.\")\n",
        "    le = LabelEncoder()\n",
        "    try:\n",
        "        df[target_column] = le.fit_transform(df[target_column])\n",
        "        print(f\"Target column '{target_column}' encoded. Classes: {le.classes_}\")\n",
        "        if len(le.classes_) > 2:\n",
        "            print(\"Warning: Target variable has more than two classes. This will be a multi-class SVM.\")\n",
        "        elif len(le.classes_) <= 1:\n",
        "            print(f\"Error: Target column '{target_column}' has only one class after encoding ({le.classes_}). Cannot train a classifier.\")\n",
        "            exit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error encoding target column '{target_column}': {e}\")\n",
        "        print(\"Please ensure the target column contains appropriate values for classification.\")\n",
        "        exit()\n",
        "\n",
        "# Define feature columns\n",
        "# Identify potential keypoint columns (typically floats or integers)\n",
        "potential_feature_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Columns to exclude from features (USER UPDATED LIST)\n",
        "# This list now means other engagement labels (like focused_engagement) MIGHT become features if numeric\n",
        "columns_to_exclude_from_features = [\n",
        "    target_column, video_id_column, # video_id_column is used for splitting, not as a feature\n",
        "    'video_id', # if 'video_id' is different from video_id_column and also an identifier\n",
        "    'sec', 'seconds', 'seconds_rounded', 'sec_rounded', 'merge_key',\n",
        "    'angrily_engaged', 'playing_engaged', 'time', 'watching', 'frame', 'tracking_id','task'\n",
        "]\n",
        "# Add any other known non-feature or identifier columns if necessary.\n",
        "\n",
        "# Filter out columns from the exclusion list that might not exist in the dataframe\n",
        "columns_to_exclude_from_features = [col for col in columns_to_exclude_from_features if col in df.columns]\n",
        "\n",
        "feature_cols = [col for col in potential_feature_cols if col not in columns_to_exclude_from_features]\n",
        "\n",
        "if not feature_cols:\n",
        "    print(\"Error: No feature columns were identified. Please check the column names, types, and exclusion list.\")\n",
        "    print(f\"Potential numeric columns found: {potential_feature_cols}\")\n",
        "    print(f\"Columns excluded: {columns_to_exclude_from_features}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\nIdentified {len(feature_cols)} feature columns: {feature_cols}\")\n",
        "print(f\"Target column: {target_column}\")\n",
        "print(f\"Video ID column for splitting: {video_id_column}\")\n",
        "\n",
        "# --- 3. Split Data into Training and Testing Sets based on Video IDs ---\n",
        "unique_videos = df[video_id_column].unique()\n",
        "print(f\"\\nFound {len(unique_videos)} unique videos for splitting.\")\n",
        "\n",
        "if len(unique_videos) < 2: # Need at least one video for train and one for test\n",
        "    print(\"Error: Not enough unique videos to perform a train/test split. Need at least 2.\")\n",
        "    exit()\n",
        "# Ensure test_size is not too large for the number of videos\n",
        "test_size_videos = 0.3\n",
        "if len(unique_videos) * test_size_videos < 1:\n",
        "    print(f\"Warning: Number of unique videos ({len(unique_videos)}) is small. Adjusting test_size for videos to ensure at least 1 test video.\")\n",
        "    # Ensure at least 1 video for testing, if possible.\n",
        "    # If only 2 videos, it will be 1 train, 1 test. If 3, 2 train, 1 test.\n",
        "    test_video_count = 1\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_video_count, random_state=21, shuffle=True)\n",
        "else:\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_size_videos, random_state=21, shuffle=True)\n",
        "\n",
        "\n",
        "print(f\"Number of videos in training set: {len(train_video_ids)}\")\n",
        "print(f\"Number of videos in testing set: {len(test_video_ids)}\")\n",
        "\n",
        "if len(train_video_ids) == 0 or len(test_video_ids) == 0:\n",
        "    print(\"Error: Splitting videos resulted in an empty training or testing set of videos.\")\n",
        "    exit()\n",
        "\n",
        "# Create training and testing dataframes\n",
        "train_df = df[df[video_id_column].isin(train_video_ids)].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "test_df = df[df[video_id_column].isin(test_video_ids)].copy()\n",
        "\n",
        "if train_df.empty or test_df.empty:\n",
        "    print(\"Error: Training or testing dataframe is empty after filtering by video IDs.\")\n",
        "    exit()\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[target_column]\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "print(\"\\nData split into training and testing sets based on video IDs.\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "if X_train.empty or X_test.empty:\n",
        "    print(\"Error: X_train or X_test is empty. Check feature selection and data splitting.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Distribution of target variable in training set:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"Distribution of target variable in test set:\\n\", y_test.value_counts(normalize=True))\n",
        "\n",
        "# --- 4. Handle Missing Values in Features (Post-Split) ---\n",
        "print(f\"\\nMissing values in X_train before imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test before imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test) # Use transform only on test data\n",
        "\n",
        "# Convert imputed arrays back to DataFrames with original column names\n",
        "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns, index=X_train.index)\n",
        "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(f\"Missing values in X_train after imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test after imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "# --- 5. Scale Numerical Features (Post-Split and Post-Imputation) ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test) # Use transform only on test data\n",
        "\n",
        "print(\"\\nFeatures scaled.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5SDSwVOMeww",
        "outputId": "804881b2-9ed5-48ad-fd80-a2543cbe0de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of dataframe after dropping NaNs in target column 'playfully_engaged': (47208, 44)\n",
            "\n",
            "Identified 34 feature columns: ['kp0_x', 'kp0_y', 'kp1_x', 'kp1_y', 'kp2_x', 'kp2_y', 'kp3_x', 'kp3_y', 'kp4_x', 'kp4_y', 'kp5_x', 'kp5_y', 'kp6_x', 'kp6_y', 'kp7_x', 'kp7_y', 'kp8_x', 'kp8_y', 'kp9_x', 'kp9_y', 'kp10_x', 'kp10_y', 'kp11_x', 'kp11_y', 'kp12_x', 'kp12_y', 'kp13_x', 'kp13_y', 'kp14_x', 'kp14_y', 'kp15_x', 'kp15_y', 'kp16_x', 'kp16_y']\n",
            "Target column: playfully_engaged\n",
            "Video ID column for splitting: source_video\n",
            "\n",
            "Found 17 unique videos for splitting.\n",
            "Number of videos in training set: 11\n",
            "Number of videos in testing set: 6\n",
            "\n",
            "Data split into training and testing sets based on video IDs.\n",
            "X_train shape: (29029, 34)\n",
            "X_test shape: (18179, 34)\n",
            "y_train shape: (29029,)\n",
            "y_test shape: (18179,)\n",
            "Distribution of target variable in training set:\n",
            " playfully_engaged\n",
            "1.0    0.63943\n",
            "0.0    0.36057\n",
            "Name: proportion, dtype: float64\n",
            "Distribution of target variable in test set:\n",
            " playfully_engaged\n",
            "1.0    0.594697\n",
            "0.0    0.405303\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Missing values in X_train before imputation: 0\n",
            "Missing values in X_test before imputation: 0\n",
            "Missing values in X_train after imputation: 0\n",
            "Missing values in X_test after imputation: 0\n",
            "\n",
            "Features scaled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2e8314a7ccff>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.dropna(subset=[target_column], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2EXQhHiPDW3",
        "outputId": "fedc8799-51b4-4a86-f091-24c698647c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the SVM model...\n",
            "SVM model trained successfully.\n",
            "\n",
            "Making predictions on the test set...\n",
            "\n",
            "Accuracy: 0.8233\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Class 0.0       0.79      0.78      0.78      7368\n",
            "   Class 1.0       0.85      0.86      0.85     10811\n",
            "\n",
            "    accuracy                           0.82     18179\n",
            "   macro avg       0.82      0.82      0.82     18179\n",
            "weighted avg       0.82      0.82      0.82     18179\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "           Class 0.0  Class 1.0\n",
            "Class 0.0       5723       1645\n",
            "Class 1.0       1567       9244\n",
            "\n",
            "--- Script Finished ---\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# --- 6. Train the SVM Model ---\n",
        "print(\"\\nTraining the SVM model...\")\n",
        "# Ensure y_train has more than one class for stratification or balanced class weights\n",
        "if len(y_train.unique()) <= 1:\n",
        "    print(f\"Error: Training target variable 'y_train' has only one class: {y_train.unique()}. Cannot train classifier.\")\n",
        "    exit()\n",
        "\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, class_weight='balanced', probability=True)\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "print(\"SVM model trained successfully.\")\n",
        "\n",
        "# --- 7. Make Predictions and Evaluate the Model ---\n",
        "print(\"\\nMaking predictions on the test set...\")\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "if 'le' in globals() and hasattr(le, 'classes_'):\n",
        "    target_names_report = [str(cls) for cls in le.classes_]\n",
        "    # Ensure labels for confusion matrix and report match actual unique values in y_test/y_pred\n",
        "    unique_test_labels_sorted = sorted(y_test.unique())\n",
        "    # If le.classes_ were [False, True] -> [0, 1], and y_test contains 0, 1, this is fine.\n",
        "    # If le.classes_ were ['A', 'B'] -> [0, 1], this is fine.\n",
        "    # We need to ensure the order of target_names_report matches the sorted unique labels if they are numeric.\n",
        "    if all(isinstance(c, (int, float)) for c in unique_test_labels_sorted) and \\\n",
        "       all(isinstance(c, str) for c in target_names_report) and \\\n",
        "       len(unique_test_labels_sorted) == len(target_names_report):\n",
        "        # This attempts to map sorted numeric labels to the string names from LabelEncoder\n",
        "        # This might need adjustment if LabelEncoder classes are not simple True/False or ordered strings\n",
        "        report_labels_ordered = unique_test_labels_sorted\n",
        "    else:\n",
        "        report_labels_ordered = le.transform(le.classes_) # Use the transformed numeric values corresponding to le.classes_\n",
        "\n",
        "else: # Fallback if LabelEncoder was not used (e.g., target was already 0/1)\n",
        "    unique_test_labels_sorted = sorted(y_test.unique())\n",
        "    target_names_report = [f\"Class {i}\" for i in unique_test_labels_sorted]\n",
        "    report_labels_ordered = unique_test_labels_sorted\n",
        "\n",
        "try:\n",
        "    print(classification_report(y_test, y_pred, labels=report_labels_ordered, target_names=target_names_report, zero_division=0))\n",
        "except Exception as e_report:\n",
        "    print(f\"Could not generate classification report with specific target names/labels: {e_report}\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "try:\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=report_labels_ordered)\n",
        "    print(pd.DataFrame(cm, index=target_names_report, columns=target_names_report))\n",
        "except Exception as e_cm:\n",
        "    print(f\"Could not generate confusion matrix with specific labels/names: {e_cm}\")\n",
        "    cm = confusion_matrix(y_test, y_pred) # Fallback\n",
        "    print(cm)\n",
        "\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_6jjY5NQPZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c70b98-dfb6-4d28-d3c7-309cd14fc1bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎓 Train Set Video IDs:\n",
            "['Fp17', 'Fp18', 'Fp19', 'Fp20', 'Fp21', 'Fp24', 'Fp27', 'Fp28', 'Fp29', 'Fp30', 'Fp31', 'Fp33', 'Fp34']\n",
            "\n",
            "🧪 Test Set Video IDs:\n",
            "['Fp35', 'Fp38', 'Fp39', 'Fp40']\n"
          ]
        }
      ],
      "source": [
        "# Assuming your data is loaded into df\n",
        "# and you already split by video_id\n",
        "\n",
        "# Example split (replace with your actual split if different)\n",
        "unique_videos = df[\"source_video\"].unique()\n",
        "train_videos = unique_videos[:int(len(unique_videos) * 0.8)]\n",
        "test_videos = unique_videos[int(len(unique_videos) * 0.8):]\n",
        "\n",
        "# Filter the DataFrames\n",
        "train_df = df[df[\"source_video\"].isin(train_videos)]\n",
        "test_df = df[df[\"source_video\"].isin(test_videos)]\n",
        "\n",
        "# Show unique video IDs\n",
        "print(\"🎓 Train Set Video IDs:\")\n",
        "print(sorted(train_df[\"source_video\"].unique()))\n",
        "\n",
        "print(\"\\n🧪 Test Set Video IDs:\")\n",
        "print(sorted(test_df[\"source_video\"].unique()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 2"
      ],
      "metadata": {
        "id": "pnaL6mE-RMuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV # Added GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Additional model imports (optional, for trying other models)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "\n",
        "\n",
        "# Store a list of columns before feature engineering to identify new ones later\n",
        "original_columns = df.columns.tolist()\n",
        "\n",
        "# --- 1.5. Feature Engineering ---\n",
        "print(\"\\n--- 1.5. Feature Engineering ---\")\n",
        "\n",
        "# IMPORTANT: Define your keypoint indices here!\n",
        "# These are EXAMPLES. You MUST verify and update them based on YOUR data's keypoint model.\n",
        "# (e.g., if your model's nose is keypoint 0, left_eye is 1, etc.)\n",
        "KP_NOSE = 0\n",
        "KP_LEFT_EYE = 1\n",
        "KP_RIGHT_EYE = 2\n",
        "KP_LEFT_EAR = 3\n",
        "KP_RIGHT_EAR = 4\n",
        "KP_LEFT_SHOULDER = 5\n",
        "KP_RIGHT_SHOULDER = 6\n",
        "KP_LEFT_ELBOW = 7\n",
        "KP_RIGHT_ELBOW = 8\n",
        "KP_LEFT_WRIST = 9\n",
        "KP_RIGHT_WRIST = 10\n",
        "\n",
        "# Helper function for distance (Uses kp0_x, kp0_y format)\n",
        "def calculate_distance(df_calc, kp1_idx, kp2_idx):\n",
        "    x1_col, y1_col = f'kp{kp1_idx}_x', f'kp{kp1_idx}_y'\n",
        "    x2_col, y2_col = f'kp{kp2_idx}_x', f'kp{kp2_idx}_y'\n",
        "\n",
        "    required_cols = [x1_col, y1_col, x2_col, y2_col]\n",
        "    if not all(col in df_calc.columns for col in required_cols):\n",
        "        # print(f\"Warning: Missing one or more columns for distance: {', '.join(list(set(required_cols) - set(df_calc.columns)))}\")\n",
        "        return pd.Series(np.nan, index=df_calc.index)\n",
        "    return np.sqrt((df_calc[x1_col] - df_calc[x2_col])**2 + (df_calc[y1_col] - df_calc[y2_col])**2)\n",
        "\n",
        "# Helper function for centroid (Uses kp0_x, kp0_y format)\n",
        "def calculate_centroid_x(df_calc, kp_indices):\n",
        "    x_cols = [f'kp{idx}_x' for idx in kp_indices if f'kp{idx}_x' in df_calc.columns]\n",
        "    if not x_cols: return pd.Series(np.nan, index=df_calc.index)\n",
        "    return df_calc[x_cols].mean(axis=1)\n",
        "\n",
        "def calculate_centroid_y(df_calc, kp_indices):\n",
        "    y_cols = [f'kp{idx}_y' for idx in kp_indices if f'kp{idx}_y' in df_calc.columns]\n",
        "    if not y_cols: return pd.Series(np.nan, index=df_calc.index)\n",
        "    return df_calc[y_cols].mean(axis=1)\n",
        "\n",
        "# --- Face Features ---\n",
        "face_kp_indices = [KP_NOSE, KP_LEFT_EYE, KP_RIGHT_EYE, KP_LEFT_EAR, KP_RIGHT_EAR]\n",
        "if all(f'kp{idx}_x' in df.columns and f'kp{idx}_y' in df.columns for idx in [KP_LEFT_EYE, KP_RIGHT_EYE]):\n",
        "    df['face_eye_dist'] = calculate_distance(df, KP_LEFT_EYE, KP_RIGHT_EYE)\n",
        "\n",
        "df['face_centroid_x'] = calculate_centroid_x(df, face_kp_indices)\n",
        "df['face_centroid_y'] = calculate_centroid_y(df, face_kp_indices)\n",
        "\n",
        "# --- Hand Features ---\n",
        "# Define more hand keypoints if you have them (e.g., fingers)\n",
        "left_hand_kp_indices = [KP_LEFT_WRIST] #, KP_LEFT_ELBOW] # Example: Add elbow if part of \"hand gesture\" context\n",
        "right_hand_kp_indices = [KP_RIGHT_WRIST] #, KP_RIGHT_ELBOW]\n",
        "\n",
        "df['left_hand_centroid_x'] = calculate_centroid_x(df, left_hand_kp_indices)\n",
        "df['left_hand_centroid_y'] = calculate_centroid_y(df, left_hand_kp_indices)\n",
        "df['right_hand_centroid_x'] = calculate_centroid_x(df, right_hand_kp_indices)\n",
        "df['right_hand_centroid_y'] = calculate_centroid_y(df, right_hand_kp_indices)\n",
        "\n",
        "# Distance of hands to face (using face centroid)\n",
        "if 'face_centroid_x' in df.columns and 'face_centroid_y' in df.columns:\n",
        "    if 'left_hand_centroid_x' in df.columns and 'left_hand_centroid_y' in df.columns and df['face_centroid_x'].notna().any():\n",
        "        df['dist_left_hand_to_face'] = np.sqrt(\n",
        "            (df['left_hand_centroid_x'] - df['face_centroid_x'])**2 +\n",
        "            (df['left_hand_centroid_y'] - df['face_centroid_y'])**2\n",
        "        )\n",
        "    if 'right_hand_centroid_x' in df.columns and 'right_hand_centroid_y' in df.columns and df['face_centroid_x'].notna().any():\n",
        "        df['dist_right_hand_to_face'] = np.sqrt(\n",
        "            (df['right_hand_centroid_x'] - df['face_centroid_x'])**2 +\n",
        "            (df['right_hand_centroid_y'] - df['face_centroid_y'])**2\n",
        "        )\n",
        "else:\n",
        "    print(\"Warning: Face centroid columns not found or all NaN, cannot calculate hand-to-face distance.\")\n",
        "\n",
        "\n",
        "# --- Temporal Features (Velocity/Movement) ---\n",
        "# Ensure you have a time column, e.g., 'frame' or 'sec'\n",
        "# 'video_id_column' will be defined in section 2 below.\n",
        "# We anticipate its use here.\n",
        "target_column_temp_ref = 'playfully_engaged' # Temporary ref for this block, will be formally defined later\n",
        "video_id_column_temp_ref = 'source_video' # Temporary ref\n",
        "\n",
        "time_col_for_diff = 'frame' # Or 'sec', 'seconds_rounded' - choose one that increments consistently\n",
        "grouping_cols = [video_id_column_temp_ref]\n",
        "\n",
        "# Check if 'tracking_id' exists and is not in the exclusion list planned for later\n",
        "# This is a bit of a forward reference to 'columns_to_exclude_from_features'\n",
        "# A simpler check for now:\n",
        "if 'tracking_id' in df.columns:\n",
        "    # A more robust check would involve seeing if 'tracking_id' will be a feature or not.\n",
        "    # For now, if it exists, we assume it can be used for grouping temporal features.\n",
        "    # Typically, 'tracking_id' is an identifier, not a feature itself.\n",
        "    if 'tracking_id' not in [target_column_temp_ref, video_id_column_temp_ref, 'video_id', 'sec', 'seconds', 'time', 'task']: # common non-feature identifiers\n",
        "        grouping_cols.append('tracking_id')\n",
        "        print(f\"Temporal features will be grouped by: {grouping_cols}\")\n",
        "    else:\n",
        "        print(f\"Temporal features will be grouped by: {grouping_cols} ('tracking_id' seems to be excluded or target/video_id)\")\n",
        "else:\n",
        "    print(f\"Warning: 'tracking_id' column not found. Temporal features calculated per video ({video_id_column_temp_ref}).\")\n",
        "    print(f\"If multiple subjects per video without tracking_id, their temporal data might be mixed if not sorted/grouped properly.\")\n",
        "\n",
        "\n",
        "if video_id_column_temp_ref not in df.columns:\n",
        "    print(f\"Error: Anticipated video ID column '{video_id_column_temp_ref}' not found for temporal features. Skipping.\")\n",
        "elif time_col_for_diff in df.columns:\n",
        "    df = df.sort_values(by=grouping_cols + [time_col_for_diff])\n",
        "\n",
        "    features_to_diff = []\n",
        "    # Centroid velocities\n",
        "    if 'face_centroid_x' in df.columns: features_to_diff.extend(['face_centroid_x', 'face_centroid_y'])\n",
        "    if 'left_hand_centroid_x' in df.columns: features_to_diff.extend(['left_hand_centroid_x', 'left_hand_centroid_y'])\n",
        "    if 'right_hand_centroid_x' in df.columns: features_to_diff.extend(['right_hand_centroid_x', 'right_hand_centroid_y'])\n",
        "\n",
        "    # Optionally, add raw keypoint velocities (can create many features)\n",
        "    # for i in range(17): # Assuming 0-16 keypoints\n",
        "    #     if f'kp{i}_x' in df.columns: features_to_diff.append(f'kp{i}_x')\n",
        "    #     if f'kp{i}_y' in df.columns: features_to_diff.append(f'kp{i}_y')\n",
        "\n",
        "    for feature_col_name in features_to_diff:\n",
        "        if feature_col_name in df.columns:\n",
        "            # Calculate difference within each group\n",
        "            df[f'{feature_col_name}_vel'] = df.groupby(grouping_cols)[feature_col_name].diff().fillna(0)\n",
        "            # If you have deltaTime (time difference between frames), divide by it for true velocity.\n",
        "            # e.g., df['dt'] = df.groupby(grouping_cols)[time_col_for_diff].diff().fillna(method='bfill').fillna(1e-6)\n",
        "            # df[f'{feature_col_name}_vel'] = df.groupby(grouping_cols)[feature_col_name].diff().fillna(0) / df['dt']\n",
        "        else:\n",
        "            print(f\"Warning: Column {feature_col_name} not found for velocity calculation.\")\n",
        "\n",
        "\n",
        "    # Speeds (magnitude of velocity vectors)\n",
        "    if 'left_hand_centroid_x_vel' in df.columns and 'left_hand_centroid_y_vel' in df.columns:\n",
        "        df['left_hand_speed'] = np.sqrt(df['left_hand_centroid_x_vel']**2 + df['left_hand_centroid_y_vel']**2)\n",
        "    if 'right_hand_centroid_x_vel' in df.columns and 'right_hand_centroid_y_vel' in df.columns:\n",
        "        df['right_hand_speed'] = np.sqrt(df['right_hand_centroid_x_vel']**2 + df['right_hand_centroid_y_vel']**2)\n",
        "    if 'face_centroid_x_vel' in df.columns and 'face_centroid_y_vel' in df.columns:\n",
        "        df['face_speed'] = np.sqrt(df['face_centroid_x_vel']**2 + df['face_centroid_y_vel']**2)\n",
        "else:\n",
        "    print(f\"Warning: Time column '{time_col_for_diff}' (or video ID '{video_id_column_temp_ref}') not found. Skipping temporal feature generation.\")\n",
        "\n",
        "\n",
        "# --- Body Shape/Pose Features (Example) ---\n",
        "if all(f'kp{idx}_x' in df.columns and f'kp{idx}_y' in df.columns for idx in [KP_LEFT_SHOULDER, KP_RIGHT_SHOULDER]):\n",
        "    df['shoulder_width'] = calculate_distance(df, KP_LEFT_SHOULDER, KP_RIGHT_SHOULDER)\n",
        "\n",
        "newly_created_columns = [col for col in df.columns if col not in original_columns]\n",
        "print(f\"\\nShape of dataframe after feature engineering: {df.shape}\")\n",
        "if newly_created_columns:\n",
        "    print(f\"Newly created columns: {newly_created_columns}\")\n",
        "else:\n",
        "    print(\"No new columns were created during feature engineering (check column names and conditions).\")\n",
        "\n",
        "\n",
        "# --- 2. Define Target (y) and Prepare for Feature (X) Selection ---\n",
        "target_column = 'playfully_engaged'\n",
        "video_id_column = 'source_video' # IMPORTANT: Verify this is the correct column name\n",
        "\n",
        "if target_column not in df.columns:\n",
        "    print(f\"Error: Target column '{target_column}' not found in the dataframe.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "if video_id_column not in df.columns:\n",
        "    print(f\"Error: Video ID column '{video_id_column}' for data splitting not found.\")\n",
        "    print(f\"Please ensure '{video_id_column}' exists or update the 'video_id_column' variable.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "# Drop rows where the target variable is NaN\n",
        "df.dropna(subset=[target_column], inplace=True)\n",
        "print(f\"\\nShape of dataframe after dropping NaNs in target column '{target_column}': {df.shape}\")\n",
        "\n",
        "# Convert target variable to numeric\n",
        "if df[target_column].dtype == 'bool':\n",
        "    df[target_column] = df[target_column].astype(int)\n",
        "elif df[target_column].dtype == 'object':\n",
        "    print(f\"Target column '{target_column}' is of object type. Attempting to encode it.\")\n",
        "    le = LabelEncoder()\n",
        "    try:\n",
        "        df[target_column] = le.fit_transform(df[target_column])\n",
        "        print(f\"Target column '{target_column}' encoded. Classes: {le.classes_}\")\n",
        "        if len(le.classes_) > 2:\n",
        "            print(\"Warning: Target variable has more than two classes. This will be a multi-class classification.\")\n",
        "        elif len(le.classes_) <= 1:\n",
        "            print(f\"Error: Target column '{target_column}' has only one class after encoding ({le.classes_}). Cannot train a classifier.\")\n",
        "            exit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error encoding target column '{target_column}': {e}\")\n",
        "        exit()\n",
        "\n",
        "# Define feature columns\n",
        "potential_feature_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Columns to exclude from features (USER UPDATED LIST from original query)\n",
        "# Newly engineered features (if numeric and not listed here) will be included.\n",
        "columns_to_exclude_from_features = [\n",
        "    target_column, video_id_column,\n",
        "    'video_id', # if 'video_id' is different from video_id_column and also an identifier\n",
        "    'sec', 'seconds', 'seconds_rounded', 'sec_rounded', 'merge_key',\n",
        "    'angrily_engaged', 'playing_engaged', 'time', 'watching', 'frame', 'tracking_id','task'\n",
        "]\n",
        "# Add any other known non-feature or identifier columns if necessary.\n",
        "\n",
        "# Filter out columns from the exclusion list that might not exist in the dataframe\n",
        "columns_to_exclude_from_features = [col for col in columns_to_exclude_from_features if col in df.columns]\n",
        "\n",
        "feature_cols = [col for col in potential_feature_cols if col not in columns_to_exclude_from_features]\n",
        "\n",
        "if not feature_cols:\n",
        "    print(\"Error: No feature columns were identified. Please check the column names, types, and exclusion list.\")\n",
        "    print(f\"Potential numeric columns found: {potential_feature_cols}\")\n",
        "    print(f\"Columns excluded: {columns_to_exclude_from_features}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\nIdentified {len(feature_cols)} feature columns.\") # Cut down print for brevity: {feature_cols}\")\n",
        "print(f\"Target column: {target_column}\")\n",
        "print(f\"Video ID column for splitting: {video_id_column}\")\n",
        "\n",
        "\n",
        "# --- 3. Split Data into Training and Testing Sets based on Video IDs ---\n",
        "unique_videos = df[video_id_column].unique()\n",
        "print(f\"\\nFound {len(unique_videos)} unique videos for splitting.\")\n",
        "\n",
        "if len(unique_videos) < 2:\n",
        "    print(\"Error: Not enough unique videos to perform a train/test split. Need at least 2.\")\n",
        "    exit()\n",
        "\n",
        "test_size_videos = 0.3\n",
        "if len(unique_videos) == 1: # Cannot split if only 1 video\n",
        "    print(\"Error: Only 1 unique video found. Cannot split into train and test based on video ID.\")\n",
        "    # Alternative: Split randomly, but this is not ideal for video data.\n",
        "    # Or, use this one video for training and test on a different dataset if available.\n",
        "    # For now, we will exit.\n",
        "    exit()\n",
        "elif len(unique_videos) * test_size_videos < 1:\n",
        "    print(f\"Warning: Number of unique videos ({len(unique_videos)}) is small. Adjusting test_size for videos to ensure at least 1 test video.\")\n",
        "    test_video_count = 1\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_video_count, random_state=21, shuffle=True)\n",
        "else:\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_size_videos, random_state=21, shuffle=True)\n",
        "\n",
        "print(f\"Number of videos in training set: {len(train_video_ids)}\")\n",
        "print(f\"Number of videos in testing set: {len(test_video_ids)}\")\n",
        "\n",
        "if len(train_video_ids) == 0 or len(test_video_ids) == 0:\n",
        "    print(\"Error: Splitting videos resulted in an empty training or testing set of videos.\")\n",
        "    exit()\n",
        "\n",
        "train_df = df[df[video_id_column].isin(train_video_ids)].copy()\n",
        "test_df = df[df[video_id_column].isin(test_video_ids)].copy()\n",
        "\n",
        "if train_df.empty or test_df.empty:\n",
        "    print(\"Error: Training or testing dataframe is empty after filtering by video IDs.\")\n",
        "    exit()\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[target_column]\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "print(\"\\nData split into training and testing sets based on video IDs.\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "if X_train.empty or X_test.empty:\n",
        "    print(\"Error: X_train or X_test is empty. Check feature selection and data splitting.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Distribution of target variable in training set:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"Distribution of target variable in test set:\\n\", y_test.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgdAwocXRN4E",
        "outputId": "85b3bd32-8b79-4c36-b577-bb633bb0388c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 1.5. Feature Engineering ---\n",
            "Temporal features will be grouped by: ['source_video', 'tracking_id']\n",
            "\n",
            "Shape of dataframe after feature engineering: (47208, 63)\n",
            "Newly created columns: ['face_eye_dist', 'face_centroid_x', 'face_centroid_y', 'left_hand_centroid_x', 'left_hand_centroid_y', 'right_hand_centroid_x', 'right_hand_centroid_y', 'dist_left_hand_to_face', 'dist_right_hand_to_face', 'face_centroid_x_vel', 'face_centroid_y_vel', 'left_hand_centroid_x_vel', 'left_hand_centroid_y_vel', 'right_hand_centroid_x_vel', 'right_hand_centroid_y_vel', 'left_hand_speed', 'right_hand_speed', 'face_speed', 'shoulder_width']\n",
            "\n",
            "Shape of dataframe after dropping NaNs in target column 'playfully_engaged': (47208, 63)\n",
            "\n",
            "Identified 53 feature columns.\n",
            "Target column: playfully_engaged\n",
            "Video ID column for splitting: source_video\n",
            "\n",
            "Found 17 unique videos for splitting.\n",
            "Number of videos in training set: 11\n",
            "Number of videos in testing set: 6\n",
            "\n",
            "Data split into training and testing sets based on video IDs.\n",
            "X_train shape: (29029, 53)\n",
            "X_test shape: (18179, 53)\n",
            "y_train shape: (29029,)\n",
            "y_test shape: (18179,)\n",
            "Distribution of target variable in training set:\n",
            " playfully_engaged\n",
            "1.0    0.63943\n",
            "0.0    0.36057\n",
            "Name: proportion, dtype: float64\n",
            "Distribution of target variable in test set:\n",
            " playfully_engaged\n",
            "1.0    0.594697\n",
            "0.0    0.405303\n",
            "Name: proportion, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-bb1745db2ddb>:62: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['face_eye_dist'] = calculate_distance(df, KP_LEFT_EYE, KP_RIGHT_EYE)\n",
            "<ipython-input-21-bb1745db2ddb>:64: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['face_centroid_x'] = calculate_centroid_x(df, face_kp_indices)\n",
            "<ipython-input-21-bb1745db2ddb>:65: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['face_centroid_y'] = calculate_centroid_y(df, face_kp_indices)\n",
            "<ipython-input-21-bb1745db2ddb>:72: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['left_hand_centroid_x'] = calculate_centroid_x(df, left_hand_kp_indices)\n",
            "<ipython-input-21-bb1745db2ddb>:73: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['left_hand_centroid_y'] = calculate_centroid_y(df, left_hand_kp_indices)\n",
            "<ipython-input-21-bb1745db2ddb>:74: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['right_hand_centroid_x'] = calculate_centroid_x(df, right_hand_kp_indices)\n",
            "<ipython-input-21-bb1745db2ddb>:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['right_hand_centroid_y'] = calculate_centroid_y(df, right_hand_kp_indices)\n",
            "<ipython-input-21-bb1745db2ddb>:80: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['dist_left_hand_to_face'] = np.sqrt(\n",
            "<ipython-input-21-bb1745db2ddb>:85: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['dist_right_hand_to_face'] = np.sqrt(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- 4. Handle Missing Values in Features (Post-Split) ---\n",
        "print(f\"\\nMissing values in X_train before imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test before imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean') # Could also try 'median' or 'most_frequent'\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns, index=X_train.index)\n",
        "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(f\"Missing values in X_train after imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test after imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "\n",
        "# --- 5. Scale Numerical Features (Post-Split and Post-Imputation) ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"\\nFeatures scaled.\")\n",
        "\n",
        "# --- 6. Train and Evaluate SVM Model ---\n",
        "print(\"\\n--- Training SVM Model ---\")\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, class_weight='balanced', probability=True) # Added class_weight and probability\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_svm = svm_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nSVM Model Evaluation:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n",
        "\n",
        "# --- 7. (Optional) Train and Evaluate Other Models ---\n",
        "\n",
        "# --- Random Forest Classifier ---\n",
        "# print(\"\\n--- Training Random Forest Model ---\")\n",
        "# rf_model = RandomForestClassifier(n_estimators=100, random_state=21, class_weight='balanced', n_jobs=-1)\n",
        "# rf_model.fit(X_train_scaled, y_train) # Tree models are less sensitive to scaling, but it doesn't hurt\n",
        "#\n",
        "# y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "#\n",
        "# print(\"\\nRandom Forest Model Evaluation:\")\n",
        "# print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
        "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
        "#\n",
        "# # Feature importances (if you want to see them)\n",
        "# # importances_rf = pd.Series(rf_model.feature_importances_, index=X_train.columns)\n",
        "# # print(\"\\nTop 10 Feature Importances (Random Forest):\\n\", importances_rf.nlargest(10))\n",
        "\n",
        "\n",
        "# --- XGBoost Classifier ---\n",
        "# print(\"\\n--- Training XGBoost Model ---\")\n",
        "# # Handle potential class imbalance with scale_pos_weight if it's binary classification\n",
        "# # For binary classification:\n",
        "# # counts = np.bincount(y_train)\n",
        "# # scale_pos_weight_xgb = counts[0] / counts[1] if len(counts) > 1 and counts[1] > 0 else 1\n",
        "\n",
        "# xgb_model = xgb.XGBClassifier(\n",
        "#     objective='binary:logistic', # or 'multi:softprob' for multi-class\n",
        "#     eval_metric='logloss',       # or 'mlogloss'\n",
        "#     use_label_encoder=False,     # Suppress warning with newer XGBoost\n",
        "#     random_state=21,\n",
        "#     # scale_pos_weight=scale_pos_weight_xgb # for binary class imbalance\n",
        "#     n_estimators=100\n",
        "# )\n",
        "# xgb_model.fit(X_train_scaled, y_train)\n",
        "#\n",
        "# y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
        "#\n",
        "# print(\"\\nXGBoost Model Evaluation:\")\n",
        "# print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
        "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
        "\n",
        "\n",
        "# --- LightGBM Classifier ---\n",
        "# print(\"\\n--- Training LightGBM Model ---\")\n",
        "# lgbm_model = lgb.LGBMClassifier(random_state=21, class_weight='balanced', n_estimators=100)\n",
        "# lgbm_model.fit(X_train_scaled, y_train)\n",
        "#\n",
        "# y_pred_lgbm = lgbm_model.predict(X_test_scaled)\n",
        "#\n",
        "# print(\"\\nLightGBM Model Evaluation:\")\n",
        "# print(\"Accuracy:\", accuracy_score(y_test, y_pred_lgbm))\n",
        "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lgbm))\n",
        "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lgbm))\n",
        "\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi_m_jNWTb-i",
        "outputId": "dd5919aa-9557-4aee-9bd3-376a28114b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values in X_train before imputation: 0\n",
            "Missing values in X_test before imputation: 0\n",
            "Missing values in X_train after imputation: 0\n",
            "Missing values in X_test after imputation: 0\n",
            "\n",
            "Features scaled.\n",
            "\n",
            "--- Training SVM Model ---\n",
            "\n",
            "SVM Model Evaluation:\n",
            "Accuracy: 0.7286979481819682\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.52      0.61      7368\n",
            "         1.0       0.73      0.87      0.79     10811\n",
            "\n",
            "    accuracy                           0.73     18179\n",
            "   macro avg       0.73      0.70      0.70     18179\n",
            "weighted avg       0.73      0.73      0.72     18179\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3854 3514]\n",
            " [1418 9393]]\n",
            "\n",
            "--- Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLlA87eNU_0W",
        "outputId": "b267add2-4922-420a-a70e-f1385d95f17e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['frame', 'sec', 'tracking_id', 'kp0_x', 'kp0_y', 'kp1_x', 'kp1_y',\n",
              "       'kp2_x', 'kp2_y', 'kp3_x', 'kp3_y', 'kp4_x', 'kp4_y', 'kp5_x', 'kp5_y',\n",
              "       'kp6_x', 'kp6_y', 'kp7_x', 'kp7_y', 'kp8_x', 'kp8_y', 'kp9_x', 'kp9_y',\n",
              "       'kp10_x', 'kp10_y', 'kp11_x', 'kp11_y', 'kp12_x', 'kp12_y', 'kp13_x',\n",
              "       'kp13_y', 'kp14_x', 'kp14_y', 'kp15_x', 'kp15_y', 'kp16_x', 'kp16_y',\n",
              "       'source_video', 'time', 'watching', 'playing_engaged',\n",
              "       'playfully_engaged', 'angrily_engaged', 'task', 'face_eye_dist',\n",
              "       'face_centroid_x', 'face_centroid_y', 'left_hand_centroid_x',\n",
              "       'left_hand_centroid_y', 'right_hand_centroid_x',\n",
              "       'right_hand_centroid_y', 'dist_left_hand_to_face',\n",
              "       'dist_right_hand_to_face', 'face_centroid_x_vel', 'face_centroid_y_vel',\n",
              "       'left_hand_centroid_x_vel', 'left_hand_centroid_y_vel',\n",
              "       'right_hand_centroid_x_vel', 'right_hand_centroid_y_vel',\n",
              "       'left_hand_speed', 'right_hand_speed', 'face_speed', 'shoulder_width'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your data is loaded into df\n",
        "# and you already split by video_id\n",
        "\n",
        "# Example split (replace with your actual split if different)\n",
        "unique_videos = df[\"source_video\"].unique()\n",
        "train_videos = unique_videos[:int(len(unique_videos) * 0.8)]\n",
        "test_videos = unique_videos[int(len(unique_videos) * 0.8):]\n",
        "\n",
        "# Filter the DataFrames\n",
        "train_df = df[df[\"source_video\"].isin(train_videos)]\n",
        "test_df = df[df[\"source_video\"].isin(test_videos)]\n",
        "\n",
        "# Show unique video IDs\n",
        "print(\"🎓 Train Set Video IDs:\")\n",
        "print(sorted(train_df[\"source_video\"].unique()))\n",
        "\n",
        "print(\"\\n🧪 Test Set Video IDs:\")\n",
        "print(sorted(test_df[\"source_video\"].unique()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4hCw6w1VBLc",
        "outputId": "cba951fe-614d-4a00-b014-2e4afd9b95c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎓 Train Set Video IDs:\n",
            "['Fp17', 'Fp18', 'Fp19', 'Fp20', 'Fp21', 'Fp24', 'Fp27', 'Fp28', 'Fp29', 'Fp30', 'Fp31', 'Fp33', 'Fp34']\n",
            "\n",
            "🧪 Test Set Video IDs:\n",
            "['Fp35', 'Fp38', 'Fp39', 'Fp40']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1yHPvb-OVRRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP3\n"
      ],
      "metadata": {
        "id": "s_lxwjKHWDH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/merged_with_forward_labels_with_tasks.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8ubuLCDWFTI",
        "outputId": "f83ef2fb-62ad-4730-eb18-9886c86be272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-1fcaa27fbc51>:2: DtypeWarning: Columns (38,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df=pd.read_csv('/content/drive/MyDrive/merged_with_forward_labels_with_tasks.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df[\"task\"]=='p']\n",
        "print(\"Data loaded successfully.\")\n",
        "print(\"Shape of the dataframe:\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACX4CjmtWbAi",
        "outputId": "650ed266-d336-4727-ef95-308295e43edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Shape of the dataframe: (47208, 44)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- 2. Define Target (y) and Prepare for Feature (X) Selection ---\n",
        "target_column = 'playfully_engaged'\n",
        "video_id_column = 'source_video' # IMPORTANT: Verify this is the correct column name for video IDs in your CSV\n",
        "\n",
        "if target_column not in df.columns:\n",
        "    print(f\"Error: Target column '{target_column}' not found in the dataframe.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "if video_id_column not in df.columns:\n",
        "    print(f\"Error: Video ID column '{video_id_column}' for data splitting not found.\")\n",
        "    print(f\"Please ensure '{video_id_column}' exists or update the 'video_id_column' variable.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "# Drop rows where the target variable is NaN, as they cannot be used for training or evaluation.\n",
        "df.dropna(subset=[target_column], inplace=True)\n",
        "print(f\"\\nShape of dataframe after dropping NaNs in target column '{target_column}': {df.shape}\")\n",
        "\n",
        "# Convert target variable to numeric if it's not already\n",
        "if df[target_column].dtype == 'bool':\n",
        "    df[target_column] = df[target_column].astype(int)\n",
        "elif df[target_column].dtype == 'object':\n",
        "    print(f\"Target column '{target_column}' is of object type. Attempting to encode it.\")\n",
        "    le = LabelEncoder()\n",
        "    try:\n",
        "        df[target_column] = le.fit_transform(df[target_column])\n",
        "        print(f\"Target column '{target_column}' encoded. Classes: {le.classes_}\")\n",
        "        if len(le.classes_) > 2:\n",
        "            print(\"Warning: Target variable has more than two classes. This will be a multi-class SVM.\")\n",
        "        elif len(le.classes_) <= 1:\n",
        "            print(f\"Error: Target column '{target_column}' has only one class after encoding ({le.classes_}). Cannot train a classifier.\")\n",
        "            exit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error encoding target column '{target_column}': {e}\")\n",
        "        print(\"Please ensure the target column contains appropriate values for classification.\")\n",
        "        exit()\n",
        "\n",
        "# Define feature columns\n",
        "# Identify potential keypoint columns (typically floats or integers)\n",
        "potential_feature_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Columns to exclude from features (USER UPDATED LIST)\n",
        "# This list now means other engagement labels (like focused_engagement) MIGHT become features if numeric\n",
        "columns_to_exclude_from_features = [\n",
        "    target_column, video_id_column, # video_id_column is used for splitting, not as a feature\n",
        "    'video_id', # if 'video_id' is different from video_id_column and also an identifier\n",
        "    'sec', 'seconds', 'seconds_rounded', 'sec_rounded', 'merge_key',\n",
        "    'angrily_engaged', 'playing_engaged', 'time', 'watching', 'frame', 'tracking_id','task'\n",
        "]\n",
        "# Add any other known non-feature or identifier columns if necessary.\n",
        "\n",
        "# Filter out columns from the exclusion list that might not exist in the dataframe\n",
        "columns_to_exclude_from_features = [col for col in columns_to_exclude_from_features if col in df.columns]\n",
        "\n",
        "feature_cols = [col for col in potential_feature_cols if col not in columns_to_exclude_from_features]\n",
        "\n",
        "if not feature_cols:\n",
        "    print(\"Error: No feature columns were identified. Please check the column names, types, and exclusion list.\")\n",
        "    print(f\"Potential numeric columns found: {potential_feature_cols}\")\n",
        "    print(f\"Columns excluded: {columns_to_exclude_from_features}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\nIdentified {len(feature_cols)} feature columns: {feature_cols}\")\n",
        "print(f\"Target column: {target_column}\")\n",
        "print(f\"Video ID column for splitting: {video_id_column}\")\n",
        "\n",
        "# --- 3. Split Data into Training and Testing Sets based on Video IDs ---\n",
        "unique_videos = df[video_id_column].unique()\n",
        "print(f\"\\nFound {len(unique_videos)} unique videos for splitting.\")\n",
        "\n",
        "if len(unique_videos) < 2: # Need at least one video for train and one for test\n",
        "    print(\"Error: Not enough unique videos to perform a train/test split. Need at least 2.\")\n",
        "    exit()\n",
        "# Ensure test_size is not too large for the number of videos\n",
        "test_size_videos = 0.3\n",
        "if len(unique_videos) * test_size_videos < 1:\n",
        "    print(f\"Warning: Number of unique videos ({len(unique_videos)}) is small. Adjusting test_size for videos to ensure at least 1 test video.\")\n",
        "    # Ensure at least 1 video for testing, if possible.\n",
        "    # If only 2 videos, it will be 1 train, 1 test. If 3, 2 train, 1 test.\n",
        "    test_video_count = 1\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_video_count, random_state=21, shuffle=True)\n",
        "else:\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_size_videos, random_state=21, shuffle=True)\n",
        "\n",
        "\n",
        "print(f\"Number of videos in training set: {len(train_video_ids)}\")\n",
        "print(f\"Number of videos in testing set: {len(test_video_ids)}\")\n",
        "\n",
        "if len(train_video_ids) == 0 or len(test_video_ids) == 0:\n",
        "    print(\"Error: Splitting videos resulted in an empty training or testing set of videos.\")\n",
        "    exit()\n",
        "\n",
        "# Create training and testing dataframes\n",
        "train_df = df[df[video_id_column].isin(train_video_ids)].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "test_df = df[df[video_id_column].isin(test_video_ids)].copy()\n",
        "\n",
        "if train_df.empty or test_df.empty:\n",
        "    print(\"Error: Training or testing dataframe is empty after filtering by video IDs.\")\n",
        "    exit()\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[target_column]\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "print(\"\\nData split into training and testing sets based on video IDs.\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "if X_train.empty or X_test.empty:\n",
        "    print(\"Error: X_train or X_test is empty. Check feature selection and data splitting.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Distribution of target variable in training set:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"Distribution of target variable in test set:\\n\", y_test.value_counts(normalize=True))\n",
        "\n",
        "# --- 4. Handle Missing Values in Features (Post-Split) ---\n",
        "print(f\"\\nMissing values in X_train before imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test before imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test) # Use transform only on test data\n",
        "\n",
        "# Convert imputed arrays back to DataFrames with original column names\n",
        "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns, index=X_train.index)\n",
        "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(f\"Missing values in X_train after imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test after imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "# --- 5. Scale Numerical Features (Post-Split and Post-Imputation) ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test) # Use transform only on test data\n",
        "\n",
        "print(\"\\nFeatures scaled.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEcthCf-WfIf",
        "outputId": "9e8490ca-e5be-48ea-a215-b588c57d91bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of dataframe after dropping NaNs in target column 'playfully_engaged': (47208, 44)\n",
            "\n",
            "Identified 34 feature columns: ['kp0_x', 'kp0_y', 'kp1_x', 'kp1_y', 'kp2_x', 'kp2_y', 'kp3_x', 'kp3_y', 'kp4_x', 'kp4_y', 'kp5_x', 'kp5_y', 'kp6_x', 'kp6_y', 'kp7_x', 'kp7_y', 'kp8_x', 'kp8_y', 'kp9_x', 'kp9_y', 'kp10_x', 'kp10_y', 'kp11_x', 'kp11_y', 'kp12_x', 'kp12_y', 'kp13_x', 'kp13_y', 'kp14_x', 'kp14_y', 'kp15_x', 'kp15_y', 'kp16_x', 'kp16_y']\n",
            "Target column: playfully_engaged\n",
            "Video ID column for splitting: source_video\n",
            "\n",
            "Found 17 unique videos for splitting.\n",
            "Number of videos in training set: 11\n",
            "Number of videos in testing set: 6\n",
            "\n",
            "Data split into training and testing sets based on video IDs.\n",
            "X_train shape: (29029, 34)\n",
            "X_test shape: (18179, 34)\n",
            "y_train shape: (29029,)\n",
            "y_test shape: (18179,)\n",
            "Distribution of target variable in training set:\n",
            " playfully_engaged\n",
            "1.0    0.63943\n",
            "0.0    0.36057\n",
            "Name: proportion, dtype: float64\n",
            "Distribution of target variable in test set:\n",
            " playfully_engaged\n",
            "1.0    0.594697\n",
            "0.0    0.405303\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Missing values in X_train before imputation: 0\n",
            "Missing values in X_test before imputation: 0\n",
            "Missing values in X_train after imputation: 0\n",
            "Missing values in X_test after imputation: 0\n",
            "\n",
            "Features scaled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 4. Handle Missing Values in Features (Post-Split) ---\n",
        "print(f\"\\nMissing values in X_train before imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test before imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean') # Could also try 'median' or 'most_frequent'\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns, index=X_train.index)\n",
        "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(f\"Missing values in X_train after imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test after imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "\n",
        "# --- 5. Scale Numerical Features (Post-Split and Post-Imputation) ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"\\nFeatures scaled.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsOPP9-yWqwO",
        "outputId": "e0d87689-d9a4-4c39-c2c5-59f87857b842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values in X_train before imputation: 0\n",
            "Missing values in X_test before imputation: 0\n",
            "Missing values in X_train after imputation: 0\n",
            "Missing values in X_test after imputation: 0\n",
            "\n",
            "Features scaled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- XGBoost Classifier ---\n",
        "print(\"\\n--- Training XGBoost Model ---\")\n",
        "# Handle potential class imbalance with scale_pos_weight if it's binary classification\n",
        "# # For binary classification:\n",
        "# # counts = np.bincount(y_train)\n",
        "# # scale_pos_weight_xgb = counts[0] / counts[1] if len(counts) > 1 and counts[1] > 0 else 1\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "     objective='binary:logistic', # or 'multi:softprob' for multi-class\n",
        "     eval_metric='logloss',       # or 'mlogloss'\n",
        "     use_label_encoder=False,     # Suppress warning with newer XGBoost\n",
        "     random_state=21,\n",
        "     # scale_pos_weight=scale_pos_weight_xgb # for binary class imbalance\n",
        "     n_estimators=100\n",
        " )\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
        "#\n",
        "print(\"\\nXGBoost Model Evaluation:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_tJwmVjWvuV",
        "outputId": "2184e4a1-ed29-42ee-bf12-7dc815220a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training XGBoost Model ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [00:05:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "XGBoost Model Evaluation:\n",
            "Accuracy: 0.6918422355465097\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.44      0.53      7368\n",
            "         1.0       0.69      0.87      0.77     10811\n",
            "\n",
            "    accuracy                           0.69     18179\n",
            "   macro avg       0.69      0.65      0.65     18179\n",
            "weighted avg       0.69      0.69      0.67     18179\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3206 4162]\n",
            " [1440 9371]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Training LightGBM Model ---\")\n",
        "lgbm_model = lgb.LGBMClassifier(random_state=21, class_weight='balanced', n_estimators=100)\n",
        "lgbm_model.fit(X_train_scaled, y_train)\n",
        "#\n",
        "y_pred_lgbm = lgbm_model.predict(X_test_scaled)\n",
        "#\n",
        "print(\"\\nLightGBM Model Evaluation:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lgbm))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lgbm))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lgbm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EqWukyBXG7C",
        "outputId": "edb1204a-dfe6-4193-ebfd-2e459c6cd7ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training LightGBM Model ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 18562, number of negative: 10467\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035062 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8521\n",
            "[LightGBM] [Info] Number of data points in the train set: 29029, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LightGBM Model Evaluation:\n",
            "Accuracy: 0.6706639529127014\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.66      0.39      0.49      7368\n",
            "         1.0       0.68      0.86      0.76     10811\n",
            "\n",
            "    accuracy                           0.67     18179\n",
            "   macro avg       0.67      0.63      0.62     18179\n",
            "weighted avg       0.67      0.67      0.65     18179\n",
            "\n",
            "Confusion Matrix:\n",
            " [[2891 4477]\n",
            " [1510 9301]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-la3OsgDbBUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### randomsearch svm"
      ],
      "metadata": {
        "id": "XaVpxk2sbBaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example using loguniform (better for C and gamma)\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.datasets import make_classification # To generate sample data\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.stats import loguniform\n",
        "\n",
        "\n",
        "svm_model = SVC(random_state=21, class_weight='balanced', probability=True)\n",
        "param_dist = {\n",
        "    'C': loguniform(1e-2, 1e2), # Example range: 0.01 to 100\n",
        "    'gamma': loguniform(1e-4, 1e-1), # Example range: 0.0001 to 0.1\n",
        "    'kernel': ['rbf', 'linear']\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "   estimator=svm_model,\n",
        "   param_distributions=param_dist,\n",
        "   n_iter=25, # Try 100 random combinations\n",
        "   cv=2,\n",
        "   scoring='accuracy', # Or other relevant metric\n",
        "   n_jobs=-1,\n",
        "   verbose=2,\n",
        "   random_state=21\n",
        ")\n",
        "\n",
        "print(\"\\nStarting RandomizedSearchCV for SVM...\")\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "print(\"RandomizedSearchCV fitting complete.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"\\nBest Hyperparameters Found (RandomizedSearch):\")\n",
        "print(random_search.best_params_)\n",
        "print(\"\\nBest Cross-Validation Score (RandomizedSearch):\")\n",
        "print(random_search.best_score_)\n",
        "\n",
        "best_svm_model_random = random_search.best_estimator_\n",
        "y_pred_best_svm_random = best_svm_model_random.predict(X_test_scaled)\n",
        "print(\"\\nPerformance of the Best SVM Model from RandomizedSearch on the (Sample) Test Set:\")\n",
        "print(classification_report(y_test, y_pred_best_svm_random))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI8g8BHdXPBb",
        "outputId": "ef72195e-127d-4ee8-e13e-785a0945e67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting RandomizedSearchCV for SVM...\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n",
            "RandomizedSearchCV fitting complete.\n",
            "------------------------------\n",
            "\n",
            "Best Hyperparameters Found (RandomizedSearch):\n",
            "{'C': np.float64(50.79933389275528), 'gamma': np.float64(0.07427781917044056), 'kernel': 'rbf'}\n",
            "\n",
            "Best Cross-Validation Score (RandomizedSearch):\n",
            "0.5463190777683333\n",
            "\n",
            "Performance of the Best SVM Model from RandomizedSearch on the (Sample) Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.81      0.83      7368\n",
            "         1.0       0.87      0.90      0.89     10811\n",
            "\n",
            "    accuracy                           0.86     18179\n",
            "   macro avg       0.86      0.85      0.86     18179\n",
            "weighted avg       0.86      0.86      0.86     18179\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best_svm_random))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J1wjAU-X-pw",
        "outputId": "5ae9b135-de78-4fdd-9acf-b26c1989b416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.862533692722372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best_svm_random))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fd_Rt_Zt2bg",
        "outputId": "6464f369-8909-4dcb-cd07-cfb5feb727be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[5932 1436]\n",
            " [1063 9748]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iH2TslCOva2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 4\n"
      ],
      "metadata": {
        "id": "dXMvSQZdv1SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# --- 6. Apply PCA (Try different values for n_components) ---\n",
        "pca = PCA(n_components=10)  # You can try 5, 10, 15, etc.\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "print(f\"\\nPCA applied. Explained variance ratio (first 10 components):\\n{pca.explained_variance_ratio_}\")\n",
        "\n",
        "# --- 7. Train an SVM Model on PCA Features ---\n",
        "model = SVC(C= np.float64(50.79933389275528), gamma= np.float64(0.07427781917044056), kernel= 'rbf', random_state=42)\n",
        "model.fit(X_train_pca, y_train)\n",
        "\n",
        "print(\"\\nSVM model trained on PCA-reduced features.\")\n",
        "\n",
        "# --- 8. Evaluate the Model ---\n",
        "y_pred = model.predict(X_test_pca)\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoEf-RHIv2ho",
        "outputId": "068b7d07-7cac-4783-b3e0-952ac0d202d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PCA applied. Explained variance ratio (first 10 components):\n",
            "[0.61551289 0.13249254 0.09284764 0.04058964 0.02723058 0.02514909\n",
            " 0.01556684 0.01007503 0.00863065 0.00542275]\n",
            "\n",
            "SVM model trained on PCA-reduced features.\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 0.8014192199790967\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.67      0.73      7368\n",
            "         1.0       0.80      0.89      0.84     10811\n",
            "\n",
            "    accuracy                           0.80     18179\n",
            "   macro avg       0.80      0.78      0.79     18179\n",
            "weighted avg       0.80      0.80      0.80     18179\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[4938 2430]\n",
            " [1180 9631]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 5"
      ],
      "metadata": {
        "id": "dUP9lUVAybzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Build the MLP model\n",
        "mlp_model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')  # Use 'softmax' and adjust units if multiclass\n",
        "])\n",
        "\n",
        "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Add early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = mlp_model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_data=(X_test_scaled, y_test),\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1SJdlPtydLK",
        "outputId": "30d985ab-dd28-4b87-b3d1-c1bcc8765521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7687 - loss: 0.4750 - val_accuracy: 0.6228 - val_loss: 0.9183\n",
            "Epoch 2/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8704 - loss: 0.2958 - val_accuracy: 0.6079 - val_loss: 1.0498\n",
            "Epoch 3/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8961 - loss: 0.2406 - val_accuracy: 0.6292 - val_loss: 1.0044\n",
            "Epoch 4/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9092 - loss: 0.2131 - val_accuracy: 0.6353 - val_loss: 0.9611\n",
            "Epoch 5/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9193 - loss: 0.1892 - val_accuracy: 0.6710 - val_loss: 1.0331\n",
            "Epoch 6/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9292 - loss: 0.1726 - val_accuracy: 0.6707 - val_loss: 0.8871\n",
            "Epoch 7/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9313 - loss: 0.1607 - val_accuracy: 0.6862 - val_loss: 1.0127\n",
            "Epoch 8/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9346 - loss: 0.1594 - val_accuracy: 0.6624 - val_loss: 1.1393\n",
            "Epoch 9/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9377 - loss: 0.1460 - val_accuracy: 0.6798 - val_loss: 1.1929\n",
            "Epoch 10/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9452 - loss: 0.1329 - val_accuracy: 0.6767 - val_loss: 1.0403\n",
            "Epoch 11/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9488 - loss: 0.1228 - val_accuracy: 0.6696 - val_loss: 1.0712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# --- Parameters ---\n",
        "sequence_length = 30  # Number of timesteps per sequence\n",
        "feature_count = X_train.shape[1]\n",
        "\n",
        "# --- Sequence Preparation Function ---\n",
        "def create_sequences(X, y, video_ids, sequence_length):\n",
        "    X_seq, y_seq = [], []\n",
        "    current_video = None\n",
        "    buffer_X, buffer_y = [], []\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        if video_ids.iloc[i] != current_video:\n",
        "            buffer_X, buffer_y = [], []\n",
        "            current_video = video_ids.iloc[i]\n",
        "\n",
        "        buffer_X.append(X.iloc[i].values)\n",
        "        buffer_y.append(y.iloc[i])\n",
        "\n",
        "        if len(buffer_X) == sequence_length:\n",
        "            X_seq.append(np.array(buffer_X))\n",
        "            y_seq.append(buffer_y[-1])  # Use label of last frame in window\n",
        "            buffer_X.pop(0)\n",
        "            buffer_y.pop(0)\n",
        "\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# --- Prepare Sequences ---\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train, train_df[video_id_column], sequence_length)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test, y_test, test_df[video_id_column], sequence_length)\n",
        "\n",
        "print(\"X_train_seq shape:\", X_train_seq.shape)\n",
        "print(\"y_train_seq shape:\", y_train_seq.shape)\n",
        "\n",
        "# --- Binary Classification LSTM Model ---\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(sequence_length, feature_count), return_sequences=False))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  # 🔁 Binary output\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# --- Train Model ---\n",
        "history = model.fit(X_train_seq, y_train_seq, epochs=10, batch_size=32, validation_data=(X_test_seq, y_test_seq))\n",
        "\n",
        "# --- Evaluate Model ---\n",
        "loss, acc = model.evaluate(X_test_seq, y_test_seq)\n",
        "print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
        "\n",
        "# --- Optional: Print detailed metrics ---\n",
        "y_pred = (model.predict(X_test_seq) > 0.5).astype(\"int32\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_seq, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_seq, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raewHAy-z-KS",
        "outputId": "7f046ca8-4aad-4919-8a2b-17dda728785b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_seq shape: (28710, 30, 34)\n",
            "y_train_seq shape: (28710,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.6287 - loss: 0.6574 - val_accuracy: 0.5894 - val_loss: 0.6105\n",
            "Epoch 2/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.6430 - loss: 0.6116 - val_accuracy: 0.7559 - val_loss: 0.5841\n",
            "Epoch 3/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.6538 - loss: 0.6037 - val_accuracy: 0.7889 - val_loss: 0.5797\n",
            "Epoch 4/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.6531 - loss: 0.6026 - val_accuracy: 0.6765 - val_loss: 0.6189\n",
            "Epoch 5/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.6647 - loss: 0.5982 - val_accuracy: 0.7127 - val_loss: 0.5981\n",
            "Epoch 6/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.6697 - loss: 0.5963 - val_accuracy: 0.7666 - val_loss: 0.5711\n",
            "Epoch 7/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 21ms/step - accuracy: 0.6718 - loss: 0.5951 - val_accuracy: 0.5951 - val_loss: 0.6306\n",
            "Epoch 8/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 21ms/step - accuracy: 0.6679 - loss: 0.5957 - val_accuracy: 0.8091 - val_loss: 0.5626\n",
            "Epoch 9/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.6441 - loss: 0.6298 - val_accuracy: 0.5956 - val_loss: 0.6557\n",
            "Epoch 10/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 21ms/step - accuracy: 0.6364 - loss: 0.6419 - val_accuracy: 0.5956 - val_loss: 0.6555\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7382 - loss: 0.5608\n",
            "\n",
            "Test Accuracy: 0.5956\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00      7281\n",
            "         1.0       0.60      1.00      0.75     10724\n",
            "\n",
            "    accuracy                           0.60     18005\n",
            "   macro avg       0.30      0.50      0.37     18005\n",
            "weighted avg       0.35      0.60      0.44     18005\n",
            "\n",
            "Confusion Matrix:\n",
            " [[    0  7281]\n",
            " [    0 10724]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Train a Random Forest Classifier ---\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=None,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'  # Helps with imbalanced classes if any\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# --- 7. Evaluate the Model ---\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\n--- Evaluation Results (Random Forest) ---\")\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Optional: Feature Importance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "importances = rf_model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "feature_names_sorted = [feature_cols[i] for i in indices]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Feature Importances (Random Forest)\")\n",
        "plt.bar(range(len(importances)), importances[indices], align=\"center\")\n",
        "plt.xticks(range(len(importances)), feature_names_sorted, rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "hPVzipAUOnhA",
        "outputId": "9f3b2f5d-26fd-4e9e-d31f-9f600a1fc7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluation Results (Random Forest) ---\n",
            "Accuracy Score: 0.6611474778590681\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.35      0.46      7368\n",
            "         1.0       0.66      0.87      0.75     10811\n",
            "\n",
            "    accuracy                           0.66     18179\n",
            "   macro avg       0.66      0.61      0.61     18179\n",
            "weighted avg       0.66      0.66      0.63     18179\n",
            "\n",
            "Confusion Matrix:\n",
            " [[2588 4780]\n",
            " [1380 9431]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iLFlIQz7On5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_b0sCd7zIvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- 6. Train the SVM Model ---\n",
        "print(\"\\nTraining the SVM model...\")\n",
        "# Ensure y_train has more than one class for stratification or balanced class weights\n",
        "if len(y_train.unique()) <= 1:\n",
        "    print(f\"Error: Training target variable 'y_train' has only one class: {y_train.unique()}. Cannot train classifier.\")\n",
        "    exit()\n",
        "\n",
        "svm_model = SVC(C= np.float64(50.79933389275528), gamma= np.float64(0.07427781917044056), kernel= 'rbf', random_state=42)\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "print(\"SVM model trained successfully.\")\n",
        "\n",
        "# --- 7. Make Predictions and Evaluate the Model ---\n",
        "print(\"\\nMaking predictions on the test set...\")\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "if 'le' in globals() and hasattr(le, 'classes_'):\n",
        "    target_names_report = [str(cls) for cls in le.classes_]\n",
        "    # Ensure labels for confusion matrix and report match actual unique values in y_test/y_pred\n",
        "    unique_test_labels_sorted = sorted(y_test.unique())\n",
        "    # If le.classes_ were [False, True] -> [0, 1], and y_test contains 0, 1, this is fine.\n",
        "    # If le.classes_ were ['A', 'B'] -> [0, 1], this is fine.\n",
        "    # We need to ensure the order of target_names_report matches the sorted unique labels if they are numeric.\n",
        "    if all(isinstance(c, (int, float)) for c in unique_test_labels_sorted) and \\\n",
        "       all(isinstance(c, str) for c in target_names_report) and \\\n",
        "       len(unique_test_labels_sorted) == len(target_names_report):\n",
        "        # This attempts to map sorted numeric labels to the string names from LabelEncoder\n",
        "        # This might need adjustment if LabelEncoder classes are not simple True/False or ordered strings\n",
        "        report_labels_ordered = unique_test_labels_sorted\n",
        "    else:\n",
        "        report_labels_ordered = le.transform(le.classes_) # Use the transformed numeric values corresponding to le.classes_\n",
        "\n",
        "else: # Fallback if LabelEncoder was not used (e.g., target was already 0/1)\n",
        "    unique_test_labels_sorted = sorted(y_test.unique())\n",
        "    target_names_report = [f\"Class {i}\" for i in unique_test_labels_sorted]\n",
        "    report_labels_ordered = unique_test_labels_sorted\n",
        "\n",
        "try:\n",
        "    print(classification_report(y_test, y_pred, labels=report_labels_ordered, target_names=target_names_report, zero_division=0))\n",
        "except Exception as e_report:\n",
        "    print(f\"Could not generate classification report with specific target names/labels: {e_report}\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "try:\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=report_labels_ordered)\n",
        "    print(pd.DataFrame(cm, index=target_names_report, columns=target_names_report))\n",
        "except Exception as e_cm:\n",
        "    print(f\"Could not generate confusion matrix with specific labels/names: {e_cm}\")\n",
        "    cm = confusion_matrix(y_test, y_pred) # Fallback\n",
        "    print(cm)\n",
        "\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD2-ZOr5zIzJ",
        "outputId": "a0835fe1-1b23-4b90-b628-def3fc01d970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the SVM model...\n",
            "SVM model trained successfully.\n",
            "\n",
            "Making predictions on the test set...\n",
            "\n",
            "Accuracy: 0.8613\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Class 0.0       0.86      0.79      0.82      7368\n",
            "   Class 1.0       0.86      0.91      0.89     10811\n",
            "\n",
            "    accuracy                           0.86     18179\n",
            "   macro avg       0.86      0.85      0.85     18179\n",
            "weighted avg       0.86      0.86      0.86     18179\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "           Class 0.0  Class 1.0\n",
            "Class 0.0       5827       1541\n",
            "Class 1.0        980       9831\n",
            "\n",
            "--- Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckFOilYF0QtO",
        "outputId": "2b79431a-6e61-4b46-9796-12451200dcab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.13.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# Note: KernelExplainer is slow, but works with any model\n",
        "explainer = shap.KernelExplainer(svm_model.predict, X_train_scaled[:100])  # Use a small sample\n",
        "shap_values = explainer.shap_values(X_test_scaled[:50])  # Again, small sample for speed\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "fa7ccd61e14e48e6a6140711c53aa186",
            "ba99f64c17ba400fbced5cfe9470a69d",
            "c19fc3792eed45c9894678b18ce01727",
            "9b255af148b148f1be331c42df687c29",
            "ff887d3ef7944230b18dd85c4228ede2",
            "1b2788e1a8b2468f9864bf89a0d777b6",
            "80030398f1a74069a79706ff23e2b723",
            "eed4717c4e864972a8f48d54b9c3cd4c",
            "9c8ecdf4a34148209f26a2371e575476",
            "d9395972b3b743db9eff57e109b71c49",
            "0bca2bb47e4a4f19aa6ef6b265500252"
          ]
        },
        "id": "PK_juDSe1OuS",
        "outputId": "6d9af9ee-ecda-4b21-bd06-7388c3421285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa7ccd61e14e48e6a6140711c53aa186"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'feature_names' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-252c1ea95202>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Summary plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'feature_names' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary plot\n",
        "shap.summary_plot(shap_values, X_test.iloc[:50], feature_names=feature_cols)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "JOlAXi6Z1U2R",
        "outputId": "97f2cf11-0231-4e39-ce92-8d3342e4adb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x950 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvUAAAOsCAYAAADKtEkGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Xd8VFX+//HXnZIeQknohI6AUoQAFpAinSBFYe2LdV3k54qgYkFh1VWBXVwUscD6xYp9Y1R0AQXFAkRAQEB6T4AQ0su0+/tjIGGY0AIpM76f328e7pw595zPHZKZzz1zzrmGaZomIiIiIiISsCyVHYCIiIiIiJwfJfUiIiIiIgFOSb2IiIiISIBTUi8iIiIiEuCU1IuIiIiIBDgl9SIiIiIiAU5JvYiIiIhIgFNSLyIiIiIS4JTUi4iIiIgEOCX1IiIiIhJUpkyZQlRU1Bmf27VrF4Zh8NFHH51T+2U9rjzZKjsAEREREZHKUK9ePX766SdatWpV2aGcNyX1IiIiIvKHFBoaymWXXVbZYVwQmn4jIiIiIn9IpU2jcTgc3HfffdSsWZPq1avzl7/8hXfffRfDMNi1a5fP8YWFhYwbN44aNWpQr149Jk6ciMvlquCz8FJSLyIiIiJByeVy+f14PJ7THjNp0iReffVVHn74Yd5//308Hg+TJk0qte5jjz2GxWLhgw8+4J577uGf//wnc+fOLY9TOSNNvxERERGRoJOXl4fdbi/1ucjIyFLLMzIymDNnDo8//jgPP/wwAAMGDKBv377s3bvXr363bt2YNWsWAP369ePbb7/lo48+4p577rlAZ3H2lNSLBDGn08kbb7wBwG233XbKNzcREZEqwxh59nXNT075VHh4ON99951f+Wuvvca7775b6jHr16+nsLCQa665xqd82LBhLFmyxK9+//79fR63bduWb7755mwiv+CU1IuIiIhI0LFYLCQkJPiVf/7556c8JjU1FYC4uDif8tq1a5dav3r16j6PQ0JCKCwsPMdILwzNqRcRERERwbvFJcDhw4d9yg8dOlQZ4ZwTJfUiIiIiUoUY5/BzYV1yySWEhYWRlJTkU/7f//73gvd1oWn6jYiIiIgIUKtWLf7617/yzDPPEBYWRseOHfnwww/ZsmUL4J3SU1VV3chERERERCrYc889x913382zzz7LqFGjcDqdxVtaxsTEVHJ0p2aYpmlWdhAiUj60+42IiAQc49qzr2t+XH5xnOCWW25h+fLl7Ny5s0L6KwtNvxERERGRKuTCz5U/F8uWLeOHH36gc+fOeDwePv/8c9555x3+9a9/VWpcZ6KkXkRERETkmKioKD7//HOef/55CgoKaNq0Kf/617+4//77Kzu001JSLyIiIiJyTOfOnfnxxx8rO4xzpqReRERERKqQyp1+E6i0+42IiIiISIBTUi8iIiIiEuCU1IuIiIiIBDjNqRcRERGRKkRz6stCI/UiIiIiIgFOSb2IiIiISIBTUi8iIiIiEuCU1IuIiIiIBDgl9SIiIiIiAU6734iIiIhIFaLdb8pCI/UiIiIiIgFOSb2IiIiISIBTUi8iIiIiEuA0p15EREREqhDNqS8LJfUiQc6VG4K7wI7L6cFur+xoREREpDxo+o1IkDJNky9m7ebw/9qS8X1LXrr9N/b/nlvZYYmIiEg5UFIvEqS2rszi10UZGB4PFpeb/EwXn8/aVdlhiYiInIFxDj9ynKbfiASp/VtyicjJIyI3HwNw2awcdrnwuE0sVr0RioiIBBMl9SJBKsJ0EZmbX/zY5nJTsyhfCb2IiEgQUlIvEqxyivzLsos0Ui8iIlWcPqPKQnPqRYJVVIhfkREVooReREQkCGmkXiRIZdvCWFs3jsWN6pEZGkK7wxlcmZOtkXoREZEgpKReJEhlRYUw75JWeAxvAv9dfH2yi6rzDyX0IiIiQadcp98kJyeTkJBASkpKeXYjIqXYFBZRnNAftyEsHI/HrKSIREREzoa2tCyLgB2pP3jwIHPnzuXHH38kIyODatWqcdFFF3H//ffTrFmzyg5PpNJZbP7X7DabgcWiN0EREZFgE5BJ/ebNm7n33nuJiIjgmmuuoW7dumRnZ7Nx40aOHj1a2eGJVAluq8U7iHHCwLzbZsVjmliM4EjsHW6T13/1sHyfSbs4g3GdLFQLDY5zE3As3UHRm2swwmyE3dMNz5F87+MIO2F/7YbtkjoVEoe5NwPPS9/AvqMYwzpiGd2lQvotb+bhHDwvLoFthzD6tcX48xUYluDZP8PMLYSXv8FcvRvjsuZwT2+MMHv5dPbbHpjzNeQVwi29oE87b7nbDfO+gW9/g9YN4P8NhJrR5ROD/OEFXFJfVFTEI488Qp06dXjttdeIioqq7JBEqqQQtxsiQsDpBtMEmwW7zQiqLytv+dzNB5u9Vy0LNpn8d6vJilusGEFy0fJHVvTfjeSMfNf7uwsUzvsFHO7i5wvfWE31Ffdga1e3XOMwj+Ti7vYMpGZ5H7+7ArYexPJYYrn2W97MAgfuK/4B2w55H7+3AmPtHqz/vrGSI7twzCEvwHe/e//3+ythyUaM5PsvfEcbdkO3SZB/bBvh+Uvh/Qkw6gq453WYu6Sk7oc/wZppYA+49KuC6T28LCrlknzevHkkJCQwbdo0PB4PCQkJTJkyhRUrVjBmzBiuvPJKBgwYwIwZM8jPz/c5dtGiRezdu5d77rmHqKgoHA4HDoejTHE4nU769u3L7bffXurzb775JgkJCaxevbpM7YtUpst3HSDC6YJQG4TZwWal19Y9lR3WOSk4UsSv87aSMmsTR7dlF5cv+t3J2E/yixP641almsz/1c2RApOZKR4eX+5m7SHfOmu3Opjz3xySvs+noMhTIechp2cWOnH8ZwWFkz7H8fpPFE7+ivwJXxQn9MCxhP6ExwVOCmf/fOa28x24XvsBx6TPcC/belbxuL7ZStGkz3HM+xn3i9/iTC3AQQje3xYTz3MLz6odz697cU1Owj1zMeaR3DPHuukAnif/i2f6V5gHs3yf23IQ15Rk3M9/jZmadYoWzp5nymeY2w5jHvs/MDHnfOsd3T5VfIVOzP98h2fSh5iLfyu90oEMeC4Jpn4EW1PPO86z4nLDe8vh4bfhs1Vgmpgrd8B3mwEXBk7ADZ//ivn7BYjpp9/h0Xfg5a8gpwCe/qgkoQfv7+3TH0J6NvznG7y/tx7vf3/bAwvXnHuf29Pg7x/Bs5/CviPnfw4SlCr0UtHtdjNt2jQ+/vhjxo0bx5gxY4qf27x5M0uWLGH48OEMGTKElJQUFixYwPbt25k9ezaWY18J/vDDDwBER0dz1113sXbtWkzTpFWrVvy///f/uPzyy886HrvdTmJiIm+//Ta7du2iSZMmPs9/9tlnxMfH06lTp/M+d5GKFl7goOf+dNbXqUGB1UKdAged9h0G86KAGATJTc3n01HLKEj3fliufX0LA16+jLl51fj7/wrBakCs/1fpt39SRGxNG4ddVgCeXeHmw6EWRraysGBxHi9+nFNc97/f5/Pqg7UIsQfACxKkTLeH/D5zcP+026fcQwgnjzsZx5PPY+WuX9NO33aRk8IeL2Cu3uet//xi7DOGY5/Q55THFD2zCMfjJyTtVgOTMMLIxXL8oiK3EPfM/2Ed3/+U7Xg+XYNr1Gvg9l4KuGcuxp7yKEbtaqXHungjnsEveL9ZA8wZX2NZ9ThGfC08y7bgGjALilzetqb/D/uKSRjN4057/qfifvgjPNO+Bk5aauh0Yz6djPHcKP/43B7Mq6fBj9u8j5//EqYOx3hiWEmlralw2WTIOHYB81wSLHoMurcuU5xn7doZ8NkJG3KMHQDDL8PAcex3BgzceDAht5Sb8p2L1/4Hf3m15PFzn8C+dP9663fDst/A4z6h8NjvT945xrBiK/SeCgXHBjCfT4KfnoY2Dc+tHQl6FTZSX1hYyMMPP0xSUhJTpkzxSegBtm3bxlNPPcWECRMYNWoUzz//PNdffz2rVq1i0aJFxfV27/a+8T/00ENERUXxj3/8g0mTJpGVlcXf/vY3VqxYcU5xjRgxAoCkpCSf8rVr17Jr1y6GDRtW2mEiVV5qwzgsdjsdMnK57HA2TXML2doyHiNAFspufHdncUIP4HGa/PDKVqZ/e2wk0W0WJ0AllUxMp4fDR1wnFjHlRw8ut8n/fek7Wrplr4vv1p56ZFLKn2vhZr+EHsCC26/MwCxO0gA8208/YulOWl+c0B/nfPprTIer1PpmgQPHs0t8C90mFlx+8ZhPJWO6/GMsPmzq58UJPQB7j+J5ffkp63ueSvb9fT6UjfnSN962nllYnNADcCQP97+/OWVbp2Nm5OF5oeQcT343MGctKX20/qv1xQl9cd3nv8Q8MUF9YWFJQg9Q6IR//LdMcZ61X7b7JvQAr/wP9hzy+V0BMCxuuOg812E88b7v473pUNqGYibw4pelt1Gv+rn1+eynJQk9QFY+/PPzc2tD/hAqJKnPzs7m3nvvZeXKlcycOZPERP+5iI0bN6ZXr14+ZccT/6VLlxaXHZ+O06RJE/71r3/Rr18/rrvuOubMmYNhGLz88svnFFvjxo3p1KkTX375JS5XyZtmUlISVqu11FgrS0ZGBkVFJW+gubm55OSUjDo6HA6OHPH9kEtNTT3t47S0NMwTvuJWH8HTRx5WTpaPhQMHUgPiPNL3+C96Tz/qosB57EGIDYo84PR4M3enG3KPffCdtG1nah7k5DnIKfD/9E3PLkm8Av3fPBD7MFOzKY0FNxZccGx03vvYLB6tBxMzq/C0fbj2lrJxQmYBJb9Evudh5hRBXmnTOUvJ2o7mQ4HjlK9VaVNkjpeV9lqZBzL9+0j1lpX2XMHOg359nuiU/x4ZeVB8UVPKeRU4IKvAv83UUuLLd2Bm5hU/dOw+6FfFvb/ktSmP36uCHaVMp/GYGLv8R88Nj4mRU1j2312XGw6X/vtaqgMZpZfnFJzb32Bpr33q0XL5O68qzOJL+DP/SIkKSeqnTp3KunXrmDVr1imnxzRt2tSvLDY2lujoaPbv319cFhoaCsCQIUN8FsPFx8fToUMHNm7cSEFBwTnFN3LkSI4cOcLy5d5RlLy8PBYvXkyPHj2oVavWObVVnmrWrFl8/gBRUVFER5esog8JCfGLt169eqd9XLduXZ/XUX0ETx9Nj2ZimCZ2t5twpwvDNGl6NIv69esFxHm0vaY5J0voFUtCIysYBtis3pyk0A15LihwlyTzIb4XNNe2MqhRLZSEi0J8yq0W6N6+JK5A/zcPxD5sg9t4132cxMDAigcbbmzHEnrwftgfnzISMqLt6fsY0QFO2trVcnUrjJjwUs/DUjsayxVNfOp7Lx+sfumv0f9ijOjwU75WlhGX+p2TZaS3rLTXyjLSf5qnMbKzz3EnirjR97P0bP89jBa1oV2D4z34p/Vdm2I0qOHf5uD2/v9OlzXH0qBm8cOQP13pF6f1ustKni+H36vwQZ2hRqRvp83rwN19IPSk6XmXt4R6Ncr+u2uzwtDOJ53haZLKG3pA85MWclePhN6XnNvf4Iiu/m1f261c/s4lsFVIUt+vXz8sFgtz586lsPD8vuquU8f71Vlpv4i1atXCNE1yc8+8IOlEffr0ISYmpngKzqJFiygoKGD48OHnFatIZYpJy6btvkM0yMunTkEBjbNzaLtuF6Y7MBaHNrm6HpdNuoTwuFBsEVbaXN+EhL+14cM/R9K+QSnLgQwDiwVu6WRjVmIIDaMh3AZjLjaY0dP7Vjf5thi6tw/FZoX4Olaevqs6DeO0C0VlsjSIIfzTMVja1gGbBaNhDITaMRrEED57OGHPD8KoHQVRIVj7tsRoUhNCbYRc357IOcNP33azWEI+uh3jotpgt2Idegmhb91y2mPCF9yCdXAbsFmwtKmD/S+XQ/0aOEJiMGMiwG71bms5/47TtmOdcS2W266AcDs0rIH15Rux9Dn13HLj78Mx/toLIkOhTjWM6aMwRngTfevjg7H8v94QFQq1o7E+OxzrDWXfVtP26ViMvm3AZsNsWhuaxnoT1oGXYPngr6XHV78Gxn/vg4sbHKvbDuP9k+rechU8/SeIqwbR4fC3QTCpnKewRoXDF49AQnPvVfpVbeCzh6FRLHz6ALQ9Fu+gjrDgvvPvb+5YuO5y7zeFzevC/42DO/tCRKj3nKPCjp37EHj8OvhsElzV1htb5+bwxaPemM/FxKEwIRGqhUOtaJgyCm7rff7nIkHHME/8ruYCS05OZurUqbzyyiscOXKEJ554gk6dOjFz5kzCwsKK6yUkJNC4cWM+/vhjn+PT09MZOHAg/fr149lnnwXg1Vdf5fXXX2fSpElcd911PvXvuOMONmzYwHfffedzdXo2/vWvf/H+++/z+eef89BDD3Hw4EGSk5OxWv2nMIgEguVv72PBZzk+ZTEeJ8981L6SIrpwUnNMGs8o8JmC3CjGYOeEMKwBsmZARERKZxqnv/g+kWG+VY6RBJYKWyg7YMAAnnnmGdasWcN9993nt1Xl7t27febOA8yfPx+Anj17+rRjtVpJSkrymQO/ZcsW1q9fT0JCwjkn9OBdMOt2u5k1axbr168nMTFRCb0EtKwQ/7+DLIsdj6fcruMrTL1og7euC6H2sW/dW9Qy+OD6ECX0IiLyh1Wh3zv37dsXm83GI488wrhx45g1a1bxzaNatGjB5MmTGT58OPHx8aSkpLBkyRI6depE//4l24Y1adKEW2+9lTfeeIO7776b/v37k52dzfvvv09YWBj3339/mWJr2rQpHTt2ZOHChRiGwTXXXHMhTlmk0tTPOzZKb5pYPB48Vit1HXlYgiTx/VM7GyPbWjmcZ1Iv2tANp0RE5A+twieT9urVi+nTp/PQQw8xbtw4XnrpJQBat27N+PHjefnll/nkk0+IjIxk9OjR3HvvvcV71B937733Uq9ePT788ENmzZpFaGgoCQkJ3HPPPTRv7r+47myNGDGCtWvXkpCQQMOG2v9VAlujnal0Wn8ES5ELu8tNblQ4rdNSMd2dMKzBcSt4u9WgfjUl8yIiwUXv62VRrkn90KFDGTp0qF959+7d+fHHH/3Ku3XrRrdu3c6q7ZEjRzJy5MjzjvFEISHenTG0N70Eg/zqEYTmHSh+HJVbQG5MVNAk9CIiIlJCn+4n+PDDD6levTp9+pz6boMigSLT9L/baqbHhscd+HPqRURExFfQ7uV29OhR3O5T3+0PICIigsLCQlauXMnatWtZvXo148aNKx6xFwlkuTH+26YVVgvDYtXXmiIiIsEmaJP6W2+91e9uaye766676Ny5M48//jjR0dFce+213HzzzRUUoUj5Wlm3NgU1qhF/1HsHRI8Bn7RqxhiPqV1iRESkyjqXO8Xq06xEue5TX5nWrl3rc3vk0jRo0EALYiVo/WtJAZNWGnTemUbN3ALWNKlLUUQIRx6PPPPBIiIilcRj/Pms61rM+eUYSWAJ2pH6jh07VnYIIpUqLywEp93k51YlF652w8Rjmli0/aOIiEhQCdqkXuSPLirUAHy/iAu3G/qqUkREqjh9UpWFdr8RCVI3tTGIDfdN6sddqps0iYiIBCMl9SJBqnakwXejoad9E+1te3j1apOnu+tPXkREJBhp+o1IEGtRHW4M/wmA2y65TaP0IiISAPRZVRYathMRERERCXBK6kVEREREApySehERERGRAKc59SIiIiJSZZzLHWWlhEbqRUREREQCnJJ6EREREZEAp+k3IiIiIlKFaPpNWWikXkREREQkwCmpFxEREREJcErqRUREREQCnObUi4iIiEiVYVZ2AAFKI/UiIiIiIgFOSb2IiIiISIDT9BsRERERqUK0pWVZKKkXkSopd1cum2dvIm9vPvWurkeL21pgsV3YLxdzv95FxqvryTbsrO3QknRrKK0vDqfPgQ3w2TqM+jFYJ/bD0rYeuRsz2fmv3yg6UEDt4fE0uqslhlH6B4+nyM3hmWvJWbKPsDY1qP1wJ0IaRJG76hCpL6zHneUg9sYWxN7Y8rTxudfsp+hf32Eeycd+fQdCbk24oOcvIiLBQ0m9iFQ5RUeLWDJ0MUXpRQAcXJZG7s4cOv2j8wXrI2fhTvYMScJlsfDOwKvI3ugG8mn27mLMjSsA72ItzydrMRdN5OeBy3BlOQFI/98BCvfm0eqpS0tte8+YxWQu2ApA7uK9ZCfvJP7DQfzW4zPMIjcAmV/swZXpoO7Yi0ttw73lMLndZ0O+t0/Xws2Yh/MIndDzgr0GIiISPDSnXkSqnH3Je4sT+uN2vLsDd6H7gvWRMXsdmLCzXm2yoyKKy3tsXetbMauA7CcWFSf0x+2Z83up7ToP5ZP5wTafMseuHPY/uao4oT/u4EsbThmf8z+rihP644pe+uGU9UVEgoWJcdY/UkJJvYhUOaanlA3NPGCaF3CjM7fH29dJU2gspfXh8vgVme5TxOIxoZQ2TFcpZadqAzDd/n1ymvoiIvLHVq5JfXJyMgkJCaSkpJRnNyISZBomNiKkeohPWePrGmMLv3AzBmvc1Q6ApgcOEVlQWFz+U7NLfCtGhhL15NVYI337bnRH6fPh7XUjqTa0qU+ZrV4E9Sd3xjhpTUDtu9ucMr6QPydAiNW37O5up6wvIiJ/bAE3p/7AgQNcc801pT7XrFkzPvjggwqOSEQutLDYMHp/2puN/95E3p5c6l1dn9b3tr6gfVQb2YKGHw7h6CvruLlgNymtL+KILYzCxKGwJx7j82MLZScNIDQhnq5L+rNj2gYK9+dTZ3g8TR9oe8q2G7/Tj4PPpJD7zX5C29Sg7uQuhDaPofX/BpP6r3W4Mx3E3tSSOvecug3rJXWJXPIXiqYv9S6U/VMHQsZdeUFfAxERCR4Bl9Qf17t3b3r37u1TFh0dXUnRiMiFFtO6OpfPubx8+7iuJTHXtaQJ4LvktS48OsC3bkIsl37Q66zatUaFUP/ZK/z7692AmN4Nzjo+W/em2Lo3PXNFEZGgornyZRGwSX2LFi0YPHhwZYchIuWocH06jp3ZpDWpTa7HwsVtwlh3yMM3291cFGeluyeX1VsLyW1Rk36t7USHeD8I1qe5+WqHSeMaFoa2MAi3e8v355isSDWxH8wn/YiLBq0jST/qonFOLhe3i+KXPDsG0DMqDzN5LZlpJhlNG/Bbm0bUrxNC++xMMpYcwIiNIG5wQ+wxIaXGbbo9uL/dRsH6I5ht6hHVpxFFP+zDdHoosthx5LrIjwihRnwo1XfuxoyJ4KirBq48J0VhVuyRNqKaRrFzwS5qGAU0qOfA6NwMmtQueW3WHcaxK5vIng2xhBi4v92GUTMC62VNMPdnwKod0LExuUcMilILqN6rLtZwK45lu8CEkF5NMKylz8B0r0/FszMD21XNMKqHX9B/UxERKR+VktTPmzePOXPmMHr0aCZOnEjXrl1JTExk0KBBzJkzh61btxIVFUW/fv0YO3YsERERpbZTVFSEaZqEhYWVOZYbbriB7OxskpOTsVh8P+AWL17MpEmTmDJlComJiWXuQ0TOjWma7LttMUfe2syHvbuyraF3brnHZrAkOpKjdu9bly0qBFdEFOyAaoudJF1nY97PRby9zXJsPrqH6iHwzZ+s/HjA5P5vPbg8YJihNEp3svdXN6ZhwXBHErWwgJwQFwBt0g/xzoJV1M7PJ9QwSB7Yhzcu60znHVk8/sk67G4PljALCR/0Ju7qej6xe1KzKOj1MuaWQxiAAzsb7Q0IcxZhwcSFhSNUw2IrpLa5EqfbxSrLFWTYanKkThhuuwWXzYozLIRLjmyi7f4fMTAxLQbGUzdgPnIt+2/5mqx3NgNgibRR255BWGaG9/FFtQjdth3D7cbE4BBN2UMTQqtZaFYzE3PXUe9r1yaWmkv+jLVeyTecpmlScNv7OOf/4i2IDCHio1uwD7ywU59EROTCq9Ddb9xuN88++yxz5sxh3LhxPPTQQ8WJ9ObNm5k4cSLt2rXj/vvvp2PHjixYsIAJEybg8fjvAvHOO+/QvXt3unfvzpAhQ3jllVdwOBznHNPw4cM5ePAgK1as8HsuKSmJqKgo+vbte+4nKyJllrt4L5nzN7GhaUO2NaxbXG5xmVyaW+B9EGLFFVEyUp7tsXDbQjdvbzR9FphmOuC+JW4mLPUUb2JjmrAnMrx45xvTZZITYi8+ZlNsXV6+rAsANtPksUVLqZGXzy/N6rHkksYAeAo9bLh/hd+OPM5/LMbccqj4cShOYpxHKcTbvg0PURTQ0rWRSHcBu4zmZBs1yKkegttuwQScYSGEuou48sDPWPG2b3hMeGIBeW+uKU7oATx5LtIzS0bTPb8fweX2XvQYmDRlB6EUEpOdXpzQA7g2pZP7j+99Ynct2lKS0APkOSgY++mF3XVIROQMtKVl2VRYUl9YWMjDDz9MUlISU6ZMYcyYMT7Pb9u2jaeeeooJEyYwatQonn/+ea6//npWrVrFokWLSgK2WOjSpQtjx45lxowZPP744zRt2pS5c+dy//3343af2z7WgwcPJjQ0lKSkJJ/ytLQ0VqxYwcCBA8/rm4ALKSMjg6Kikr27c3NzycnJKX7scDg4cuSIzzGpqamnfZyWlubzga0+gq+PunXr+jwOhPMoXHsYgIM1YzhZdeexv3G7/9vXrhwDSrnr7NrD4LNFvAk+czZL2ULzt9pxxf87zOWmZbo3vp21S2LK35FLZlpJouxwOChK2e3XVihFuE94u7XjIopsAHIMb3vOEO/zpmGAYVC9KAubedL7mduDc/FGv/Zd2PGccD6eE76ENYAocgnDf9DDucb773b838Pza6pfHXNnBmQXBu3fh/pQH+pDgoVhluMQTHJyMlOnTmXatGm88847bN26leeff57LL/dd/JaQkEDjxo35+OOPfcrT09MZOHAg/fr149lnnz1tX8888wyffvopTz31FIMGDTqnOKdMmcLXX3/NwoULqV69OgCvv/46r776Km+99RZt2px62zmRqszpdPLGG28AcNttt2G3289wRNWQ98MBdnT/iI2N6/NJry4+z6XZbXxXI8o7Gl/d94K7TQ3YtMcB0b5z3Qc0gR/2Q+7xezmZJhS4KU7sHS5w+n4jOO6nlUz63nuzp7wQO50njCU3LJQJySvpvXEPANEXV+eqlb5T84oeTsY57Rufsgyqk0M1wo8l1nmEUo/fieUgO4yWbLFcTGbNEPKj7ZhAYWQYdtPFmI3vEuI54QZUITby3nuSXdcu8mnfjoMGHCipRi42vB/mHgx+4kqqk0etYxcSx0U+eAXVpvUvfuxavpO8Hi/71LG0rUP0bxMREakoDuMvZ103xHy1HCMJLBUyUj916lTWrVvHrFmz/BL645o29d/hITY2lujoaPbv33/GPm6//XYAli9ffs7xjRgxAqfTyZdffgl455UmJyfTqlUrJfQilSDyyvrEPZJAm/1pdNyyu/hmTkaElTXRx6aaONxEZuVjOTY9r2Goh/eGWnn4citGkav4mMbRMLuvlXkDLFQ7luvbPSZtMnOxHbvBUygmdQsLivu/at92xq5YCUBuiJ0HrxlIXmgIA9bt4KqN3pH4kFqhtJ9zmV/sIY/2xdKjWfHjfMLIqRZL6LGE3oGNHMLZGNqOjNDqNDa3E2emEZ3pwF7kxgBCCh24LHa+aXQVRRbvhZgZEQov303kyIup9WBnsHovSGx1I4hrcuyCxDCw9miCNdr71u6x2dhqXISTEHLj62Pt0rAkzp6NiXrsKp/Ybd2bEjqpd/G3HUb9aoT/Z/RZ/ZuJiEjlqpCFsv369SM5OZm5c+cyY8aMcpnOUqdOHaxWK5mZmed8bIcOHWjevDlJSUnceOONrFy5kgMHDvDQQw9d8DhF5OzU/ccV1PpbR1rszSGvUXVyCw0aN7JzINtkzQE38TUsXGR1sGNHLnkNY+hU347VYtBhYCjjr/Sw8oCHutUsJNQ1MAyD5tUNBjcz2HQEovJc7MsIp1nzENKOeqiX76Zh85pszzWwWAwuim6L585Q8rNMbHVqMblBLV6MsVLP0ZSc1dEYNcKI6VQLSylTfYyYcCK++394Nh+kaFcO0Y1qUPviWji2ZIDLg8tqo2Ghm3yLhfAGt2Pdm0rnmEjyXGF4ijy4bAbWUCsR9cLZvySV3PChhEYVYbSqDzGR3tdmWg9qPdAJ1/5cwjrEgdXA8+t+jBoRWBrXxMwrhI0HsLSqS9NckwYHC4jqUBPDasH1ezqYJrbWcX6xA4Q9O5iQv3XHsy8La8f6GDZrqfVERMqP5sqXRYUk9QMHDqRLly488cQTjB8/npkzZ/ol9jt37vQ7Lj09nZycHBo0OPO+zvv378ftdlOzZs0yxThixAhmzJjBhg0bSEpKIjQ09Jyn8YjIhWWvE4G9TgQRwPEUtGF1g4bVjyfT4bSt7b/lYp1oC0Mv8k+4o0IMutQDCOP4d3DNa1kB77z2NpHHa4Zg6d2GKCAKqFPcQjg1BzQ6q9gtresQ3rrkyJBWNY+1fCyW40/U9H5LGYm/xoMbllLqZa8bib1uyVHWjiV1jcgw6OL9tiA0BkIblNSzXRR75tjrVsNSt9oZ64mISNVRYQtlBwwYwDPPPMOaNWu47777yM/P93l+9+7dLF261Kds/vz5APTs2bO4rLSReI/Hw8sve+eBXnXVVX7Pn43jC2bfeustli5dSp8+fXQzK5FKtHa/i4Gv5tBoaiY3v51LWrb/Lljnw+EyeeRrB81m5JMwu4BPfnOdtn7+75lsGvY/VjV8l83XLaZwZ/Yp6+asTufXAV/zU6P32XTLMhwHC7zTgZ7/BC4aB+3uh9cXnfJ4ERGRc1Wh+9T37dsXm83GI488wrhx45g1axZRUd7xqhYtWjB58mSGDx9OfHw8KSkpLFmyhE6dOtG/f8lCrmeeeYa8vDzat29PnTp1yMzM5JtvvmHTpk307NmTq6++ukyxVatWjT59+rBw4UIAhg0bdv4nLCJlklNo0ndODkfyvPPi3/nFwY4jHn7824UbPX50kYN/Lvcm8juPmox6r4gf/2LQrZH/dBOP08PG/gsp2pMLwJGPd5K/IYNLN47CsPh+TezKcvBr369wHfXOoT/49nYKd+Vy6Shg0tslFe+eA7WiYaT/vHwRkT8ybVVZNhW6Tz1Ar169mD59Ops3b2bcuHHk5no/JFu3bs2MGTNYt24dL7zwAmvWrGH06NHMnDnT56ZQV155JS6Xi08//ZTnn3+eN954A6vVysMPP8z06dP9biB1LkaOHAlAo0aN6Ny58/mdqIiU2VebncUJ/XE/7XKxI/3ctqw9nXfW+rblMeG9daWP1md/n1qc0B9X8HsWuSmH/eoeWbivOKE/Lmv5QTz/+da/4beXnWPUIiIipSvXkfqhQ4cydOhQv/Lu3bvz448/+pV369aNbt26nbbN4cOHM3z48AsVoo/j2/1dc801GIauEkUqS0yY/9+f1QJRoRfu7zImDNJyTyo7Rfu2mJBSy62llNtiStk21GpA9VLujB1T+t2yRUREzlWFj9RXZR988AE2m63UCxERqThXt7LRuaHvNJg/dwmhdvSFe8t6qIdv8l0zHO5MKH2cI6pzHDFX1/etP6wxERdV96tbs38Dojr6Ltivd0crLI+M8F6ZHBceAvcNKVvwIiIiJ6nQOfUVKSsrC6fTedo6YWFhWK1WvvvuO3bs2MHChQsZMWIEsbFn3h1CRMqP1WLwzb3VePXHQjakuunVws6tXUofLS+r2xPsxFe3sGCdi1oRBn/tZqNR9VNfNLRJHsDB1zeT+0s60ZfVps4dF5Vaz7Ba6Lh0MAde2Uzexkyq965H3VtbgMWAH/4B//cthNjg7n5wcfwFPScREfnjCtqk/sEHH2T16tWnrZOYmMjdd9/NY489RkREBFdffTX33XdfBUUoIqdTLczgwT7+21VeSH1bWOnb4uz2YbeG26h/3yVnVdcWE0L8w+39n+jWyvsjIiJygVWJpD4lJeWCtzl+/Hiys0+95RxAXFwc9evXL5f+RUREREQqSpVI6stDmzZtzlxJRERERKoUbWlZNlooKyIiIiIS4JTUi4iIiIgEuKCdfiMiIiIigUjTb8pCI/UiIiIiIgFOSb2IiIiISIDT9BsRERERqTK0+03ZaKReRERERCTAKakXEREREQlwSupFRERERAKc5tSLiIiISBWiOfVloZF6EREREZEAp6ReRERERCTAafqNiIiIiFQZ2tKybDRSLyIiIiIS4JTUi4iIiIgEOCX1IiIiIiIBTkm9iIiIiEiA00JZEakych0m724yScuDES0N2sV5F0sV/ryfgq92YGscA5i4d2cR1qUOG38/wmcHw6jjKGTk4X1Ed6jHr1d3YMlhG1f88BsdLQXYY8PwHMwjjCxCyMe4ojUMvBQMA8/ybRR9tYmfouL44bJODG5tp3NdA0+ug/x3N+BOyyN8xEXsrB/HR797qB4KN11soXqYFnGJiEjVoqReRKqE7CKTru+4+T3D+3jqT/DuEAsDv0rh6PglJ9Q0Ae+tSV4ddBWv9WoHwIvE88Xj86j15DL6h0RRPyuX/GN1a7KLUI6WNDF2IK74xrgn/RcLcCXgafoD3f7y//hPDxf9bn8T1+9HAPjs3b3cMeY6nMd2Y5i2wsPKP9uoE6nEXkREqg5NvxGRKmH+b2ZxQg/gMWHKUieZU5afVLMkmR73zc+EOl0AbKpXh086tqNGQSHxWUc5nvzbKCDixIQeMF/5Gvffk33KeuzcRt/fN/HLC+uLE3qAf119ZXFCD7AnG15Z4zmPMxURkdMxMc76R0ooqReRKmFfjulXdvSIAzOr6JTHVCtyEFVU8vyBmGoAGJS0ZcXpd5zhMTHyC/3KG2ZlEnk4x6cstVr0WcUqIiJSmco1qU9OTiYhIYGUlJTy7EZEgsA1Lfzfjnq1jyD0yoYnlZYk1Kvj63EkKhLwJuoDN/4OgPuEtzYHkXiw+jbRsBZ0bu5T5LBa+bp1W3L7tvQp779pm19cw1pqPERERKqWgPxkcjgcvPLKK1xzzTVcfvnlDBs2jLlz5+JyuSo7NBEpoysbGLzSz0LdSLAaMLKlwey+FuLevYawfk3AAEvtCKy1IzEAS9Mokrq1xOLxUC8ri5mffEaHjHT+e013Jg8dwNHoSEyrBWIiSKcZzvBjI+4JzSFpEvYP78Lo3QqA3bGx3HLzbXToVJPH7o+nxiuDsBwL5O/2/dzUwoPdArXCYVpvC4mlXICIiMiFYpzDjxxnmKZZbt8jJycnM3XqVF555RUSEhIuWLsTJkxg2bJlXHPNNbRv355169bx2WefkZiYyJQpUy5YPyKBzul08sYbbwBw2223YbfbKzmis+P2mFgtvm/WptuDYbX4/G/TNHG7PVgN49j7u4FhGMXHF9c7fqzbDVZrqe2eqU+PaWIx9AEiIlLe8oz7z7pupPlCucURaAJu95vly5ezbNkybrrpJsaPHw/A8OHDiY6O5p133mHEiBF06NChkqMUqTosThNrUeDMAS9wmhS5wTBMrIZJvtMgLgIOH3VSw+IiL8dJaN1ocotMapgOrBl5HI2IxBlmJ8oONotJTpGJ53AekfXDKTiUS83CIvIa1MBjWnAUmUTn5BJSI5xcrKTnQ6NqJkcLoUaYyeF8E9OE2pEGR4sM4sJNSM8hJzKSfLdBdKhBVIhBgdOk0A01jm1veaTAJMoOoTYl/iIiUvEqJamfN28ec+bMYfTo0UycOJGuXbuSmJjIoEGDmDNnDlu3biUqKop+/foxduxYIiIiio/9+uuvAbjhhht82rzhhht45513WLhw4Tkl9f/+97956623mDp1KkOGDCku37p1K2PGjOGSSy5hzpw5WCz6ul0CT/6/V9LviUPYC0yOfvQmNRdchy0+prLDKpVpmkz6zsOLa0wKTpxJZ4LddHPl9k3858M5ND16mJ014rj7ur/wa7144nJz2Fi3GphuDAuEmh4KDSudd6Xz4JfL+OfAq9gTG01GpAOnxUrPbduY/+ZbTLzuWj5u1x4TMAzvbgtWA9wmYJpYAI8H2h5N47X35jC951A+a9sZw2LQoTZszoQCl8FVDaHICSsOmFQLhSeusDChm7XUcxQRESkvFTr9xu12M23aND7++GPGjRvHmDFjAEhISKBFixbs37+f4cOHEx8fT0pKCkuWLKFLly7Mnj27OKkeOXIkhYWFfPnll379DRo0iLi4ON58882zjtHlcnHnnXeyY8cO3n77beLj4yksLOTmm2/m6NGjvPfee9SuXfuCvB4iFcnx017Sr3jDpyykb1NiF91SSRGd3oLNHm74vPStIsMcDvY//RdqFuQVl2WGRdDwsVfICw0rqXjSIHn3Lbt44b1kLn9sLE5bSaLdbedOVjRpevqATBOOhVO9II/M8Ejf5w3g+HQdj3ni+l2+v8lK90YaCBARKYtcY/xZ140yZ5ZjJIGlwj51CgsLefjhh0lKSmLKlCnFCf1x27Zt46mnnmLChAmMGjWK559/nuuvv55Vq1axaNGi4nrp6enExcWV2kdcXByHDh06p7hsNhvPPPMMFouFRx99FKfTybRp09i1axdPPvmkEnoJWIVfb/crcyzZiemumnusf73z1OMLXfZu80noAaoX5nPZni2nbXN5qybUyC/gkv1pPuXrGjQ4c0DH5+mDf0IPPkn8yRcTpzsXERGR8lAhSX12djb33nsvK1euZObMmSQmJvrVady4Mb169fIpO574L126tLissLCQkJCQUvsJDQ2lsNB/7+kzadCgAY899hibN2/mnnvu4bPPPuP666/nqquuOue2ylNGRgZFJ+zJnZubS05OyZ7aDoeDI0eO+ByTmpp62sdpaWmc+GWN+giePmwtanIya5PqHDx8qEqeR72QAr94j9tVozbukxapegyDHTXrnPIYgIYZmZgY7KvhO+WoZl7eKY44ybFTsLrd/s+dZup88+olTwbb75X6UB/qI3j7kMBWIdNvIiMjyc/P5/XXX6djx45+9RISEujVqxczZszwe6537940atSoeErNVVddRdOmTZk/f75f3VtvvZVDhw7x1VdflSneyZMns3DhQpo3b85bb711yosHkUBgFrk43Hs+rp/2ewtsFmq8N5Lw69pWbmCncKTA5Ip33Ww5etITx96hpn3+Fg9+V3IX2H93H8T919yGxePBU7zmxfSOsAM2t5tZ7ySzM64m0wf2KC6Pyc9nzgcfct+115IeFXXqgE6YfvPAd18wv/NVHIn0botps4ALwDAIsYDLbeI5VrdbfYOlN1oJ04JZEZEyyTEeOOu60ea/yjGSwFIhC2X79etHcnIyc+fOZcaMGYSFhZ35oFOIjY3l8OHDpT53+PDhMk+XycnJYe3atYB3ik9GRgZ169Yta5gilc4ItVF9yc0snPAq4UfdXDXlJsIuqrrTyWqFG6y91cp/t5nFd2zNcUB0CDSwuzgY3YuvEhoQ6chld7vWuNq14Otf19Fi5W8suPgydrWKp1u8lcgQC7+tyiB+wx6K7uxEvfQMVv3+OesHXc7++nHEHCjkopEt+a1jKnNiW7IlE7rWBSwGUXZYmWpiApfXM8hxGPTMO0Bzq52EmFSWNKpG17oGIy8y+GYPHCmAYS0NHC74fLuHBlEGQ1sa2CxK6EVEpGJVSFI/cOBAunTpwhNPPMH48eOZOXOmX2K/c+dOv+PS09PJycmhwQnzXy+++GIWLlxIWlqaT9KdlpbG4cOHyzxl5u9//zuHDh3iwQcfZNasWTzxxBPMmTMHq1W7WEjgMmwWDnb0/q31blajkqM5s3C7wQ1tSkuIrXBpU8C7uLXH8eLLO8E9nXj05OptYoHYYw+aAQmU3CmjNlzrvbh5spSe7mh/ckkj6NmIG4AT99wa3dq31rjOeq8QEZHKU2ELZQcMGMAzzzzDmjVruO+++8jPz/d5fvfu3T5z54HiKTY9e/b0aQfgvffe86l7/PGgQYPOObaPPvqIb7/9lttvv50//elP/O1vf2P16tXMmzfvnNsSkcrjOVpA/t+/IXv0exTM/hnT6Z0Lv+agyV/+52bMQjfL9moRq4iIBJ8K3ae+b9++2Gw2HnnkEcaNG8esWbOIOjantUWLFkyePNlvS8tOnTrRv3//4ja6d+9Ojx49eOedd8jNzaVdu3asX7+epKQkBg0aVOqc/dPZtm0bM2fOpFOnTtx5550AjB49mhUrVjBv3jy6du16zm2KSMUz3R6yes/F/at3pxvHhxtw/biHzTNG0X2BG8exta5v/uYmaYSFoc215aSIiASPCv9U69WrF9OnT2fz5s2MGzeO3NxcAFq3bs2MGTNYt24dL7zwAmvWrGH06NHMnDnT78ZPzz33HLfffjsrV67k+eefJyUlhXvuuYcnnyzty/RTKyws5NFHHyUsLIynnnrKZ6rNE088QWxsLI8//jjZ2dnnf+IiUq6ci7cXJ/THFb23jvlLsooTevCuu52ZotF6EREJLuU6Uj906FCGDh3qV969e3d+/PFHv/Ju3brRrVu3M7YbGhrK2LFjGTt27HnFFxYWxgcffFDqczExMXzxxRfn1b6IVBwz31FKoYk73+lXnOdUUi8iIsFF3z+LSFAIGdASo47vFpW27o0ZfHUtv7pjLtFbn4hIVWVinPWPlKjQOfUVKT09/Yx1oqKizmt7TRGpOoyIEGK+uYP8xxfh2nAQ+1VNiHx2AEPjLLw9GP692oPDDbe3s/DXjkrqRUQkuARtUj9w4MAz1nnyySdLnR4kIoHJ1rY21T65ya/8prYWbmqrRF5ERIJXlUjqU1JSLnibs2fPPmOd5s2bX/B+RUREROR8aFpNWVSJpL48nM2CWxERERGRYKDvo0VEREREApySehERERGRABe0029EREREJPBoq8qy0Ui9iIiIiEiAU1IvIiIiIhLgNP1GRERERKoMTb8pG43Ui4iIiIgEOCX1IiIiIiIBTtNvRERERKQK0fSbstBIvYiIiIhIgFNSLyIiIiIS4JTUi4iIiIgEOCX1IkGsIMtJ0YYaFK6MY88vmZUdjoiIyBmZ5/AjJZTUiwSpojwX749dR9HqOByba/DpxN9Y/eG+yg5LREREyoGSepEgtWnRQbL35VPv8FGa7j9IZH4hP83fXdlhiYiISDnQlpYiQargcCFXrN9K9dx8AFrvOsC6giZ43CYWq7YLExGRqkl3lC0bJfUiQapRVjY5xxJ68H4td3FqmhJ6ERGRIKTpNyJByp5b6Fdmyy7EdHsqIRoREREpT0rqRYJUysWN/crWXhyPYdWfvYiISLDRp7tIkFpZvw7z+nQlLzQEgC31a/PkwKtwe7QJmIiIVGXGOfzIcZpTLxKkGhcWkdw4nmcbNcTmduOw27nI6cZq0ZugiIhIsCnXkfrk5GQSEhJISUkpz25EpBThOU4APBYLDrsdAHu2UyP1IiIiQSggR+r37dvHK6+8wsqVK8nJyaFOnToMGjSIMWPGEBoaWtnhiVQJReFWvzJ3hFUj9SIiUqVpS8uyCbikfteuXdx222243W5GjRpF/fr1Wb9+PXPnzmXDhg3MmjULw9Avg8hOm5194SE0LHAA4DAMVkRE4vaYVSqxP5rvYezH+Xy63kn9ahb+PjCMmxNC+X6fyf3full3GHo0MHiln4VWB/bgum0Oll+2cdRenS0JvWgxayBxnWN92kz/1y/kPb4Ee0EBZkw4Nf4zlIiRbU4bh5nnIOe+LylcsB5LzXAiH+tJ+D1dzulcPE43ex/6mfT//I4RaqHu/e2p/2gnHLkulj6/kW3fHCSiRghd72pO22ENcTs9LHltN79+fRh7iIWu19bjihsanPNrKCIiEnBJ/Ysvvkhubi5z586lQ4cOAFx77bU0btyY2bNns3DhQgYPHlzJUYpUvjCbQUrNaLY4XYS7PaSH2AkLpUol9ABjP85nwRrvVKGdGR5ufS+fRjWsXPMFZHuvR/h2r8mw/7r57e//wLb7MAC1HBlc+vPnLLwljMRVw7BHeqcY5a08SN6ErwjBBYCRVUDmqA8J3Tsea/3oU8aR++DXFP5nNQCefCc5f03G2rImIVc3P+tzSX1uLQdfWF/8eN9jKwmJj2Lt9iJ+X5gKQE5aIUue+o3qjSPZ+msuqz5NA8CR7+bbeXuIqRvKxb1jS21fRETkVColqZ83bx5z5sxh9OjRTJw4ka5du5KYmMigQYOYM2cOW7duJSoqin79+jF27FgiIiKKj01JSSE+Pr44oT9u6NChzJ49m+Tk5HNK6m+44Qays7NJTk7GYvFdYrB48WImTZrElClTSExMPL+TFqlghUVuooqc1Cl0EuLxYHN7SHNbK3+k3uOBacnw9vcQHQ6xV/Fk+n7+tGUVR8IiebbLYF5cdRnZDt+3p80ZsK4wjnYUYODCoJAwj4Ol8bF89tBeLHWjGdTRymWP/JcQnFhxY8GDCbg9VvJbPU5EaC5G3WoUemrgOOBN+rNiq7OuTlM6/boR+0mhFn2yCVft6ux/bAWFG48SfVU96tbIovC9NWS7rGy9tD0NJ1xO0ytqsWLWZrZ9uJ+QJrHUP5hFZIH3QuXgC+vYakRx8i4NP83ZRk6Wh46/7aR6Vh5Z0RH83rwBm78/oqReRP7QNP2mbCo0qXe73UybNo2PP/6YcePGMWbMmOLnNm/ezJIlSxg+fDhDhgwhJSWFBQsWsH37dmbPnl2ccDudTsLCwvzaPl7222+/YZrmWU/BGT58ONOnT2fFihVcfvnlPs8lJSURFRVF3759y3jGIpWnmgVa5hYWr4avW+gk2vBU/kj9c0nw2PvFD99lKwZOwLuAN+mzl/jHoHg+Jt7nMJvbTVxuPh5CsWABDH5o3JJfG18ELmCfi5f2ucj3RDOQvVjx3mTLACI5QEReBuQBGUcJZzcuGuEmjJjsVLruPky2LZqYk0ItstrY1/szXEe8N/Kqvn0LJkcIBeKAWou+4ZMDbn67tB4H1x4FLBRGh5EbEcIlv6dhd3so+OUQIReH4ArzXe+TuiqdTjtTicj03vU3sqCI6tl55Pyp0YV4lUVE5A+mwvapLyws5OGHHyYpKYkpU6b4JPQA27Zt46mnnmLChAmMGjWK559/nuuvv55Vq1axaNGi4nrNmjVj165dpKen+xx/fIed/Px8srOzzzquwYMHExoaSlJSkk95WloaK1asYODAgaVeRIhUdVFFbmpn5TL0543c9M0aumzZS7VCF57K3v3mze99HnovMUreimymh4d/W0qPXft86v31x2XUzssFDEwsgI332/Xya/7HVi2w4vYpC8P3PcEAQsgBvCNCYW4nm2vW48R77ebb7GzLCS1O6AGqk+nTjsU0aZ6+71hCX8JjtZAZEw6Y2HDT4sBBMEte9/CiIhocPlqc0B8XUeigfX2NUImIyLmrkKQ+Ozube++9l5UrVzJz5sxSp7I0btyYXr16+ZQdT/yXLl1aXHbzzTdTVFTEhAkT+OWXX0hNTWXRokU8++yz2GzeLx4KCws5W9HR0fTr149ly5aRmZlZXJ6cnIzH42HYsGFn3VZ5y8jIoKioqPhxbm4uOTk5xY8dDgdHjhzxOSY1NfW0j9PS0jBPSDbUR/D0EVPoYMyiX+i4M5VmBzMY+MsW+q/bzsGDByv3PCLPvENVaEwYLy36lufe+5oHli7i0/+8zD8/+6j4eQMTh8XKj01a+R0b7nRg4HvhUtpXueYJb38GkBYdw9LGrfm9Zl3WxzXg2yZtKIryfYv0lPKW6bLaMKz+7Vs97uKLi3pHM7l88zaapR6k9d79XLFpG55T3dm3uqtK/16pD/WhPoK3Dwlshnnib8AFlpyczNSpU4mMjCQ/P5/XX3+djh07+tVLSEigV69ezJgxw++53r1706hRI958883isgULFvDKK6+Qm5sLgN1u57bbbmP58uVs3LiRpUuXEhUVddZx/vrrr9xxxx088MAD3HjjjZimybBhw4iKiuLdd9899xMXqQLW/3MjO55e61PmCbMy/MDoyt0h6t3lcNNLJY9DbVB0woh19UhY808yFh/iwF1LqM0BanDiSLiJBSezrryaJ/tfS8cDWViOvYtZMJm68B067t2Pg5K1OKEcJYqDxY89WMghHg92DDxkhkbwv8Yd4YTXJTwulGs/7smOPp9R+Ju3/5ocoR5pxXUKbSH8t1MfGl7dgG2f7y/pr8hJu62pWE0PFpuFEFch9hO+PcgJD2P5JRfR25qD++eSD+bIHvVp+d3Ic31FRUSCSrrx2FnXjTWfKcdIAkuFzKnv168fycnJzJ07lxkzZpz3dJbrr7+ekSNHsm3bNhwOB82bNyc6OpoPP/yQ2NjYc0roATp06EDz5s1JSkrixhtvZOXKlRw4cICHHnrovOIUqUyWUq7XLR68U9crc4bHjd0hrhq8vRyiw2Bsf9iRBu//ALWi4N5B0KQ2Ne+sjb1+JFnv/k5O6n6ijBwsjiKyIiN4r2U7Pqp3EYOPbuea0IOktmiNq1oUAy8Lo13CZbgXrsf6exbObDdG4xo4W19G9rbdRHgysLaMo8iMwVh/BJvNIKN+bXbWbUjXjnFExIax74dDRNQJ45KbmxFRO4LW3w3n0EsbKNh4lOjeV2GPdZIzdyXpWXC4R3uG3nUxtZpF0ahbLHt/OEy1RhE0ijAp+iYSe4Moat16EZmfbKcgeRueAgeZdaqT2aUxI0c1pv7F1Uifs4H8FQcJ7xRH7NhLKvEfRkREAlmFJPUDBw6kS5cuPPHEE4wfP56ZM2f6JfY7d+70Oy49PZ2cnBwaNPDftzkkJIS2bdsWP964cSNHjx4t83SZESNGMGPGDDZs2EBSUhKhoaEMGjSoTG2JVAX7G9bCabNgd5XMFN/TOA6jshfKAvRr7/05rm1DSEzwqxY9uCnRg5v6lNUCxh37gXpAO9+DLuqB5a4efjvZnCj82A9ANND4hOdajThpgW7NMOo/4RtbjWs7UgNoeUJZ62GNaD3shEWud5Tsix9+SS14omupsdQe3/E0kYqIiJydClsoO2DAAJ555hnWrFnDfffdR36+7wKx3bt3+8ydB5g/fz4APXv2PG3bRUVF/POf/yQkJIRbbrmlTPEdXzD71ltvsXTpUvr06UN09Kn3tBap6nLtIXx/WVv21avJkRpRbGjdiDUt4yt/oayIiMhpmBhn/SMlKnRLy759+2Kz2XjkkUcYN24cs2bNKp4q06JFCyZPnszw4cOJj48nJSWFJUuW0KlTJ/r371/cxvbt25k6dSrdu3endu3aZGRk8Pnnn7N//36eeOIJmjRpUqbYqlWrRp8+fVi4cCFAlVogK1IWdhtkxUSyqlPJeHJIiIGlKozUi4iIyAVVYSP1x/Xq1Yvp06ezefNmxo0bV7zYtXXr1syYMYN169bxwgsvsGbNGkaPHs3MmTN9bgpVvXp1ateuzX//+1+ee+453n33XZo3b868efMYMmTIecU2cqR3gVqjRo3o3LnzebUlUtncTv8ReafT1Ei9iIhIECrXkfqhQ4cydOhQv/Lu3bvz448/+pV369aNbt26nbbNWrVqlbpLzoVgt3tn4V5zzTWVuzuIyAUQm5/n3Rv9hN/l2MI8jdSLiEiVpmk1ZVPhI/VV2QcffIDNZiv1QkQk0IQdzaXFzn2EOJxgmtQ4mk2T33bjcWukXkREJNhU6Jz6ipSVlYXT6TxtnbCwMKxWK9999x07duxg4cKFjBgxgtjY2AqKUqT85MZVo07679ROP4ppGFhMk4K4aCyl3ChJREREAlvQJvUPPvggq1evPm2dxMRE7r77bh577DEiIiK4+uqrue+++yooQpHydSg8isO1qhOTXwCGgQf4rXZdPB5TU3BERESCTJVI6lNSUi54m+PHjyc7O/u0deLi4qhfv3659C9S2eKK8jlcUFg8p94CtMrOUEIvIiJVnD6nyqJKJPXloU2bNmeuJBLEIjJy/crCjuThcZuagiMiIhJktFBWJEjVbBblVxYTH6GEXkREJAgpqRcJUs2urkuDrjWLH1tDLHR/UN9giYhI1Waew4+UUFIvEqSsdguDX7oU6zWHsPY5wg1JV9KkR+3KDktERETKQdDOqRcRMAwDS8MiACJiQys5GhERESkvGqkXEREREQlwGqkXERERkSrD1JaWZaKRehERERGRAKekXkREREQkwGn6jYiIiIhUGZp+UzYaqRcRERERCXBK6kVEREREApym34iIiIhIFaLpN2WhkXoRERERkQCnpF5EREREJMApqRcRERERCXCaUy8SzHIKaLPsAFFHizDaboPubSo7ogpXlOtk8xcHyD/ioFmv2tRpG1PZIYmIyGloS8uyMUzTNCs7CBEpB3mFmF0mY2w6UFL2+p1wZ+/Ki6mCFeU4ef/Wn8nam+8tMKDf1Ha0Hly/cgMTEZFTOmD8/azr1jefKMdIAoum34gEq/d+8k3oAZ74qHJiqSSbvzhQktADmLDi1W2VF5CIiEg50fQbkWB14Kh/2cEscHvA+se4ns9LLzqrMhERqTo0haRs/hif7CJ/RMM6Y1pOmpd4Tec/TEIP0Kxnbb+y5r38y0RERAKdRupFglWHxhya+1de/Wgfh0OqMbR6Hv2nD6jsqM6ZZ9Vu3G+vxNiZhrVGKPRuA7hYs/YoLzVK4PcadWgXZ/C3y2y0iSu5YHEt3kK1pN9o0Cqab7Ij6LB3J43CPVw52H+xcHqWm89+KCArz+TqTqG0bx5SgWcoIiJy/sp1oWxycjJTp07llVdeISEhoby6EZFSZBeZXPqmix1ZJaP1/+5j4b5OgTNS7076FefI17F58rDiLi4/EB1N4wdn4LZYvQWmSYjHw9IxIVweb6Vo1vcU/S0JgPGDEnlqyVdEOxwAuGxWohf9BVuvFoA3of/zsxkcyfYAYBgwZUw1BnQJr8AzFRGR4/afw0LZBlooWyxwPt1PIT09nd69e5OQkMBbb71V2eGIVBnvbjJ9EnqAp3/yVFI0ZeN65msMj8snoQeon5NDfGZGSYFh4DANpv/gAsDx9GIAVterT6fU/cUJPYDN5Sbr6SXFj5N+KChO6AFME95YmFcepyMiImfBxDjrHykR8En9tGnTcLvdZ64o8geTXuBfdrQI3J4AWoJ0JI9TLZmKzc/xLTDgSD6Ybg/mUe/JZ0REULMg3+9Yz5GSsqxc/wudrLwAeo1EREQI8KR+2bJlLF26lDvvvLOyQxGpcka2NLBZfJPTa1saWE9ePFuFWUZ3wsTqNxqTER5BSv0mvpU9JqMvsWJYLdiubQ9A9127WNKshV+71W7sUPy/+3QKwzjpJbm6U+gFiV9ERKSiVMpC2Xnz5jFnzhxGjx7NxIkT6dq1K4mJiQwaNIg5c+awdetWoqKi6NevH2PHjiUiIsKvjby8PKZNm8a1115L27ZtyxzLDTfcQHZ2NsnJyVgsvtc4ixcvZtKkSUyZMoXExMQy9yFSGdrGGrzcy2TCl7kUuO10b2bn1f5lXAC64yDM+R9k5GJeHI+5+TBEhGCMSsBYsh62H4QBHeCGK7yT0jfvg1f/B3lFcPNVcNXFPs2ZLjf85zvM5VswLmmIOaIzvPkj7D2Kp0drcnc4cCzeSmZBPrsvvoQmu1NpnJuK1XCxv14DJg+6jma5GeRYQ7ln2U/EFhawcOgVrDlSh0VfH6KLEUpRrZp4cvLpcOgQ3zRvwpV7duAybGxt1Yp1m6uTNWY1+2OjaLArg4HZTtbUr0dBiJ0+7oP81W0DOp3/P4KIiJRB4Aw+VSUVmtS73W6mTZvGxx9/zLhx4xgzZkzxc5s3b2bJkiUMHz6cIUOGkJKSwoIFC9i+fTuzZ8/2S7hfeukl3G439957L5s3by5zTMOHD2f69OmsWLGCyy+/3Oe5pKQkoqKi6Nu3b5nbF6ksGfkmU//nJKfAm8gv3exizs8Gk3qeY2K/+zAkTIKj3nnmBmASiokNY9YXYB6bvvLm97B2F4y5Cro+DHmF3vK5i+GjB2HkZcVNmrfNhbd/9P5vwHz8E3B68GDh8Py9uLEDEImLjjgByKIuLgwSR93F+oYld4T9pVk8S1s0Iy80FNaZ/MdTnVc2eBh6xMn6hk3ouW8LrQ/uK65f7WA6m/a7+Cy+Pk9+spIwl3f6XotNqXQ9spn6BUfgP+DYlErIU0PO7bUSERGpJBU2/aawsJCHH36YpKQkpkyZ4pPQA2zbto2nnnqKCRMmMGrUKJ5//nmuv/56Vq1axaJFi3zqrl+/no8//pgHHniAqKio84pr8ODBhIaGkpSU5FOelpbGihUrGDhwIGFhYefVh0hlePdXF/tPmnY+/XvnuTc0d0lxQn+cgQMDN4Z50nz0l/4Hs74oSejBu/J0+n9LHu7PgHd+8m3P6V3gWkBUcUIPYMPlU++7ls18EnqALy5u7U3oj7dvMZhzlfcCYme9WJ+EHqDN4d3sirTRe/u+4oTeG4TBtugGHB8hcr6wDNPh27+IiEhVVSFJfXZ2Nvfeey8rV65k5syZpU5lady4Mb169fIpO574L126tLjM5XLx9NNP061bN/r373/esUVHR9OvXz+WLVtGZmZmcXlycjIej4dhw4addx8XSkZGBkVFJXfDzM3NJSenJGtzOBwcOXLE55jU1NTTPk5LS+PEXU3VR/D0kV3kv9gz1wEHUs+tD/fRXL92TqnQCVn+C1NdR3NL+sgt8ib6pTBPeks6+QvY3LBS5rqfPCEeyDmW5FtOvug4xu5xE+70T9idx7fIBMh3cHBfakD9m6sP9aE+1Mf59FFVaPebsqmQfeojIyPJz8/n9ddfp2PHjn71EhIS6NWrFzNmzPB7rnfv3jRq1Ig333wTgLlz5/LGG2/w/vvv07BhQwBSUlK45557+Nvf/sYtt9xyznH++uuv3HHHHTzwwAPceOONmKbJsGHDiIqK4t133z3n9kSqgq3pHi6ZVYDjhMHoWy+1Mf+6c1wE+vMWuHIynLBrjgc7JiFYKPR9S03sBOP6wsCnfNv4x03wyLUlxyc8Cb/sKn7sbdmCCzuHaMTx8QYbTp/R+pzQEBIeuZ+jkSXrbFqlHmJLXJxPdw8uWsb4b37gh5Yt6b7/F2rml1yYpEXV4LHef+LXmGo8vGy1z3FtM3fRKsc7sm+9tgNhH91+xpdHREQurL3GM2ddt5H5WDlGElgqZKS+X79+WCwW5s6dS2Fh4ZkPOIX09HTeeOMNhgwZgmma7N27l71793L48GEAsrKy2Lt3LwUFpezldxodOnSgefPmxVNwVq5cyYEDBxg+fHiZYxWpbC1jLST1yeXS7F00yM9gXLVUXh5qP/OBJ7usFXw0Abo0x2xWG7NXO8yWjaBDPObj10LvthAfC3dfDW+NhQGXwtt/g45NoWU9ePpGeHiET5PGZ/fDTZdDo5owuAPGa7dD91bYGscQO7I+IV3qYoRb8IS4OFQjlKJQGxgmkU4Hcz/9lFY5ucQ6ivjT2rV88vr/MefDT2mfn0mLGJPHrfsZv30DRdEhbGpYnbHXjWFVfEvSI6JZV68Z/2t7JY0MD/G4+ahLKw7HhGM1XLTIO0BTjkC9atj+eiWh/7nxwvxDiIiIVIAKu6PskSNHeOKJJ+jUqRMzZ870maeekJBA48aN+fjjj32OT09PZ+DAgfTr149nn32W33//nZtuuumM/T733HPnvLh1wYIFzJgxg//7v//j3XffZdmyZXz11VdER0efUzsiVcbhLMyL/4ZxOLukbPIo+PsNlRdTBctxmFz8hpu9J6wt+H+XGsy62nrqg0REpFJppL5sKmz3mwEDBmC1Wnn88ce57777eOGFF3y2qty9ezdLly71mVc/f/58AHr27AlAgwYNeO655/za3rFjB6+99hpDhgyhR48etG/f/pzjGzx4MC+++CJvvfUW33//PVdffbUSegls737vm9CDdxHr1OtLnYcejD7ZYvok9ACvrTN57iqTCPsf4zUQEQk0uv1f2VTolpZ9+/bFZrPxyCOPMG7cOGbNmlW8e02LFi2YPHkyw4cPJz4+npSUFJYsWUKnTp2KF8SeanvJlJSU4jbKuv1ktWrV6NOnDwsXLgSoUgtkRcqk0OFfVuTyLlL9gyT1haXcbNrlAbc+MUREJMhU+B1le/XqxfTp09m8eTPjxo0jN9e7gK1169bMmDGDdevW8cILL7BmzRpGjx7NzJkz/faoLy8jR44EoFGjRnTu3LlC+hQpN3/qjhl+0p70f+4FFfT3VBWMbGkQc9K64OtaGUSH/DEuakRE5I+jXEfqhw4dytChQ/3Ku3fvzo8//uhX3q1bN7p163bO/SQkJBSP1p8Pu927iPCaa67B+IOMZEoQa1Ib9yt3U/i31wkpcGG76hIsM2+r7KgqVFyEwbejrUz9ycP2TJOBTQymXPHHuagREQlE2qqybCp0+k1V98EHH2Cz2Uq9EBEJOKkZWP/2BlGZx/YpXvQrPLEApv+5cuOqYJfWMfjvcC2MFRGR4Ba0SX1WVhZO5+nvnhkWFobVauW7775jx44dLFy4kBEjRhAbG1tBUYqUo3e/x8j0vRMsr3wN0279w8ypFxER+aMI2qT+wQcfZPXq1aetk5iYyN13381jjz1GREQEV199Nffdd18FRShSzjylrAb1mH+ohbIiIhJ4NP2mbMp1n/rKtGnTJrKzs09bJy4ujmbNmlVQRCIVbF86Ztu/YeSccDO2+4bAv++ovJhERETOYJfx7FnXbWI+Uo6RBJagHalv06ZNZYcgUrkaxuJaMoU9Y2cSebSQuDuHYJ04vLKjEhERkXIQtEm9iAAdm7Dkro4A3HbbNVhtWjAqIiISjJTUi4iIiEgVojn1ZaENm0VEREREApySehERERGRAKfpNyIiIiJSZQTltowVQCP1IiIiIiIBTkm9iIiIiEiAU1IvIiIiIhLgNKdeRERERKoMU1talolG6kVEREREApySehERERGRAKfpNyIiIiJSZWj6TdlopF5EREREJMApqRcRERERCXCafiMiIiIiVYam35SNknqRIOfICsdVGEJRgRu73V7Z4YiIiEg50PQbkSDl8Zh8OGMPqcsu4fCKVvzrzt/ZuSG3ssMSERGRcqCkXiRIbV6RxW8/ZBc/Lsr3kDxnbyVGJCIiIuVF029EgtSBHQV+ZQd3F+Jxm1ismq8oIiJVk1nZAQQojdSLBKnGrSP9yhq0jFBCLyIiEoSU1IsEqZadq9F1SE0aZ+ym/f4N1I12MPz/NTqvNs2sAhwf/IpzyVZMj+fU9Tbsw3znR8ztB09d50gO5oKfMZdtxjRPPS5jekz2/JzO1sVpOPJcgHe9QMrGIr5NKSCv4NRxnEp2louVP2Sz7XfvtxlFR4vY8989HPrx0GljERERqao0/UYkWLncDP1sPpaf1gJg/h6CMeZhaHZp2Zr7eTe5A+dBViEA1isaE7XoLoyIEJ965sPvw7QvvA8MA/OfN2CMH+hb59uNMHQm5BV5C65ui/nlRIwQ37ckR56LT/+6ikMbvWsDwmLsDJjZmWe/cLJplxOA6AiD6X+rSesmvnGcyvo1ubwyMxWn05u8t25qo/EHa3Afu2CofWVterxzFdZQ61m+MiIicmHpG+WyKNeR+uTkZBISEkhJSSnPbkSkNJ+uwPLV2uKHRoED/vafMjdX8OAXxQk9gPvH3Tj+z/dv29yaBtO/PKHAhEc/xMw4aded8e+WJPQASzbCgp/9+tzw6b7ihB6gMMvJ3DkHihN6gJx8k9c+yTnr83jv/w4XJ/QAm3e6SA0vmap06IdD7Pl091m3JyIiUhUE3Eh9fn4+b7/9Nps2beL333/n0KFDdOrUiddee62yQxOpWjbs8S/7fT+43WA991Fozwb/qTTu304q27jfm8ifqNAJ2w9BzaiSst/2+3dQSlnGdv8tOA9kAdG+ZTsPuE4Vtg+nw0P6IadfeV5EGJBV/Djr92y/OiIiIlVZwM2pz8zM5LXXXmPjxo20bNkSaxmSE5E/hF4X+5dd2bpMCT2ArVcz/7KeJ5Vd3hJOmkJDzUho19C3rOdF/h30bO1X1KBzDb+yNvX8v5bt2Orspt7YQyw0aR7mV14jy/fiofblcWfVnoiIXHgmxln/SImAG6mPjY3liy++oE6dOgD06NGjkiMSqaJ6t8P10HCMf36G1e3B3bwe1rljfaqYOYW4kjZgZhdgMT0Y9aphRoVirkvFvXYvlgNHsVzWBE90ONSIwGxQHfZnYhgGlisb41y9H/ObTdj/1BFL79YYtathzrsDxr0FWfmYYXaMf4zCCCtJus30HMyr28HvB2FfOobFgL6tMQ4choOZUKc6AM5lO4hfvJ62US62pYfgtlqofVEEA+MP4dpRxNeFcXgwaBjtoX5deHVpAQ0y8kg76iYyN592LcPIbVGT5QdMci022tS2MKyFwZhrQpj1UhYZzlAshklc1xg2GI2I27qX/BgLl7aNoX7/BiUv0vo9sPx3aB8PV5ZyMXIqqUfh89VQuxoM6QQ2DUCIiEj5qZSkft68ecyZM4fRo0czceJEunbtSmJiIoMGDWLOnDls3bqVqKgo+vXrx9ixY4mIiCg+NiQkpDihP19Op5NBgwYRHx/Pf/7jP9f4zTffZNasWbz22mt06tTpgvQpUlHcDg9f7Y7naKNrCXcXkmOLoc9eC42PDYh7th0mv8dLkJaJDUfxvsAm3lESC25vvW83YwKF1MCCiYEBJniW78azfCc2cnC/+g2eG7pie/dOPAkt8OTnYyMPo9CEe2bj9rix/rUf5sodePr+E3KOz823g8eJ8b+NmP9bixHxBnzxCDlzN+J4Zy0AHQF7jYbsjo6j9rfbKPzvburHd2NYxD6cViuRRQ4OrarB4Vo1+P1Yq6GFRRx6M52MsFBmDuhCToQN8NDCXsiyJx/n2awMUqPjuHPIGF490gja1oBOJd9s/PTMRmY+1hae/wwmvVfyot7VB16768wv/uJ1MHSad+oRQEIzWPokRPp/SyAiInIhVOj0G7fbzbPPPsucOXMYN24cDz30EBaLN4TNmzczceJE2rVrx/3330/Hjh1ZsGABEyZMwHOarfPOh91uJzExkXXr1rFr1y6/5z/77DPi4+OV0EtA2vXVfg6mZOCwhpIVEoPHBSv+sb74+aJnFmOm5WDF5fMFpgGlfqlpxVPKF50WHIQDYL63Ek/KLpx/fQu7M7e4DQMT46E3AfA8+skJCf3x3izH/muH/CKc975dnNAfd1HmAaweN7vD67GmVkvy7WGEOV1EFxZhMU2yo6N83syKwkLJi4wgtrCIXltK7qK7zRnGS5cPwAB+rV2PhS06eLsO9X0r/Le9BdtWpcKTH/me7uvfwLqzWET70DslCT1Ayg5487szHyciIlJGFZbUFxYW8vDDD5OUlMSUKVMYM2aMz/Pbtm3jqaeeYsKECYwaNYrnn3+e66+/nlWrVrFo0aJyi2vEiBEAJCUl+ZSvXbuWXbt2MWzYsHLr+1xlZGRQVFSyY0hubi45OSW7fjgcDo4cOeJzTGpq6mkfp6Wl+ezLrT6Cp4+snf47wuTszSN1fyqmaeLZchgAA/+LZqPU+/mVPnfRPPFt5PeDGDvS/OpYcvMoysmDLf6LbUsuH7z/9ezK9KtjMz2Eup1gGGSF+N9Uy2n3/9LxeFntnHyf8i1x9bz/rVnvWHAGGL7nZlosbF1zEIr8F9U6fyu5SDjlv8eWVL/jjpcF+u+V+lAf6iN4+6gqNKe+bAyzHO+0kpyczNSpU5k2bRrvvPMOW7du5fnnn+fyyy/3qZeQkEDjxo35+OOPfcrT09MZOHAg/fr149lnny21jx49etCmTZvz2v3m7rvvZvfu3XzxxRfYbN5EYOrUqXz55Zd8+eWX1KpVq8xti1SWtJR0vrjed3S43mVxDH7buw6l6MmvcPz9f1hxYD021eY4E7CclOznU43SxgHsFBJCAabNgn3Xszie/JzQeZ/61HE3qY9150t47ngD8z/LfZ4zcB27sHBj4MA9pCuZX2WBu+StKd8awtL6bbGZbpoU7GddXEufNnY3aUBhuO/UlrpphwkvcvBBwkUsb1myUPeVj1/jLz8vZkNcQ9rf/Q9MwwLRdm9yf0yko5D9d1uIaT8BUjNLGg21w54XoXaM3+vgY/h0SDppK98vJsHgst0jQETkj+R3419nXfci84FyjCSwVMhI/dSpU1m3bh2zZs3yS+iPa9q0qV9ZbGws0dHR7N9fyvZ3F9DIkSM5cuQIy5d7k428vDwWL15Mjx49lNBLwKqbEEv7+9vgtnsfR7apTo9nS6aShUzqg+1PHXEbIXiOvxXYrZihIZjFKb13hr0LKw7sfmP6FpzYKcCMCMX25u0YDWoQ8tL1FHVsXzyC765ZA8sXkwAwpo2C/sfmrlstx1b1eMAwASf0bIt17l1E/d91GNHexbX51hDWxDYlL8xOXEwOHTJ20CzLu3WmCThDbJguJxnHd90xTaofzSLU6WR1fBw/NKgNponNMLmnaQHX5ewA4OLD+3jxqzeJcRdBvgu7y7stZv3cTBa0PkRMbAR8eD80q+1tt04MvH3vmRN6gJfvgO7HFi+Eh8Dka5XQi4hIuaqQhbL9+vUjOTmZuXPnMmPGDMLCqtZisT59+hATE0NSUhK9evVi0aJFFBQUMHz48MoOTaTMCl0mf41qwbqbmxLhcJITGcbbOVZuOPa8ER5C+IJbMV++1jv9xOmCiBCwWyE9D9NtYh7KwtIkFrvLTWiRB6NGOOQ6vMMBdium0wNZeViaxWIcm+5ihNkJXTMFz/5MzOw8rG1KdpIxakVh/foBzMM5EGbzJvZZBRjRod6bUR3b+Sb05hqEjG6HZ382MRaTEDMUo2Y4tatZMQ/n0Ndi4Dich6tWNTxYMKPtFLkNQh0uijwGZpGLmGgr1ggbT+WY2O0QZjOICY2Ga2fg2p/BoRwP99QJ446oSI4UmNQN85C6K4u6Tatjs8d6A77yItj2AuzP8Cb1pUzzKVX9mvD9VO9uPlFhWiArInIOym0KSZCrkKR+4MCBdOnShSeeeILx48czc+ZMv8R+586dfselp6eTk5NDgwYN/J67kEJCQhgyZAjvv/8+hw8fJikpidq1a5/yWwWRQPD+JpNfDgI2K1k2K5gwaZmbG9r6fkFn1PSfo06D6t6ZivEl+8QXb8hY7aQEte5Jd4I6xtKgOjSoXupzRtwJx0SEev8bFe5bJ8SGtWlNAE7c7+r4saG1ogg9ueHIY19LnPDW1rC6/5xLW4Oa1D/2v61AA7t3wW7DVqV8M2cY0LCM39gdu0gREREpbxW2UHbAgAE888wzrFmzhvvuu4/8fN/Fa7t372bp0qU+ZfPnzwegZ8+e5R7fiBEjcLvdzJo1i/Xr15OYmKgbW0lA25XlP9axNxvcHo2BiIiIBJsK3ae+b9++2Gw2HnnkEcaNG8esWbOIivLeOr5FixZMnjyZ4cOHEx8fT0pKCkuWLKFTp07079/fp53333+/eAW3y+UiLS2NuXPnAtCqVSuuuuqqc46tadOmdOzYkYULF2IYBtdcc815nq1I5RrUzGDKD75l/ZsaWC3aLUBERCTYVOg+9QC9evVi+vTpbN68mXHjxpGb6709e+vWrZkxYwbr1q3jhRdeYM2aNYwePZqZM2cW72V/3Ntvv80rr7zCK6+8gtPp5MCBA8WPv/nmmzLHdnx7y4SEBBo2bHiG2iJVW9f6Fmb1gSjDuy98n3iYN0jfPomISNWmLS3LplxH6ocOHcrQoUP9yrt3786PP/7oV96tWze6det2xnaTk5MvSHwnCwnx7rZRlfamFzkf93QE2+oFOLHy1+tuwW7XG6CIiEgwqtDpN1Xdhx9+SPXq1enTp09lhyJywVgNEyuuyg5DREREylHQJvVHjx7F7Xaftk5ERASFhYWsXLmStWvXsnr1asaNG1c8Yi8iIiIiFUvTasomaJP6W2+91e8Wyie766676Ny5M48//jjR0dFce+213HzzzRUUoYiIiIjIhVElkvqUlJQzVzpHTz31FEVFRaet06BBAxo2bFgu/YuIiIiIVJQqkdSXh44dO1Z2CCIiIiJyjnQ3lbKp8C0tRURERETkwlJSLyIiIiIS4JTUi4iIiIgEuKCdUy8iIiIigUdbWpaNRupFRERERAKcknoRERERkQCn6TciIiIiUmVo+k3ZaKReRERERCTAKakXEREREQlwSupFRERERAKc5tSLBDsnWAorOwgREZGzY1Z2AAFKI/UiQWzXi5upNzmcek9EsKLvIvJ351Z2SCIiIlIOlNSLBKmMnw6xZfKvWIq8uwhkpWTw663LKjkqERERKQ+afiMSpA7O3eBXlpFyFNPtwbDqel5ERKombWlZNkrqRYJU2JZ9YBpU9+QSYjrJtERjwVPZYYmIiEg5UFIvEqRii9LpUJhJtFkAgAeDPEtoJUclIiIi5UFJvUjQshQn9N5HJlGegtPUFxERqXyaflM2mlgrEqTcFv9rdkNvlCIiIkFJSb1IkNoSV9uvLDs0vBIiERERkfKmpF4kSH130cX81LwtTosVgMPRMXx26RV4DI3Wi4iIBBvNqRcJUiEeC6uatWFtfAtCnU5ywyPwAIZpgqbhiIhIFaU7ypZNuY7UJycnk5CQQEpKSnl2IyKlaLkvFUwTp81ObngEAPWPHNSbpYiISBAKuJH6zZs389VXX7Fq1SoOHDgAQKNGjRg6dCgjRozAZgu4UxIpF00y97GhoBFFoaG4DYMQt5vaOUePjdSLiIhIMAm4DHj+/PmsXLmSXr16MWLECNxuN8uXL+f5559n2bJlvPjiixiaM3zBmdkFUODAqBNTUmaasC8DalfDCLX7H5OZD043Rlx0RYYqx+yJrUP60Wj21aqJy2qhWn4BFqeTofr7EBGRKkxbWpZNwCX1f/rTn5gyZQqhoaE+ZZMnT2bhwoUsX76cHj16VGKEAcrhgk37oUkcxEQUF5umiXnDHMxP1oDTDVe3wbLgHth5GHPUbNh9GKLD4eEhGDdfDo3jMN0ePH95C88by8Hjxuh3MdYP/4oRE4G5aT9sT8Po2RYzpxAyC+Ciuni+2wo2G0atcIzoMIwa4bAtDS6qD+G6YVJZ/NykObtCSi62siMj2NSgHqaSehERkaBTKUn9vHnzmDNnDqNHj2bixIl07dqVxMREBg0axJw5c9i6dStRUVH069ePsWPHEhFRkmR27Nix1Db79evHwoUL2b59+zkl9TfccAPZ2dkkJydjsfguMVi8eDGTJk1iypQpJCYmlulcA8KSDXDji3AoGyJC4bnr4f8NhAMZmBc/jJnpPqHuJjx3/R/G5ykYrgIMPJg5+fD4e5iPv4UxoiueunVh3lK8e66YsOgXzKv/4T3+l93eUsONx7RgEgoWAzzmsStzw/v/VhdWVxZGjSiYOxZGXlbBL0rg21+9OhzI8ynLDw/X+IeIiEgQqtAtLd1uN88++yxz5sxh3LhxPPTQQ8WJ9ObNm5k4cSLt2rXj/vvvp2PHjixYsIAJEybg8XjO2PahQ4cAqFmz5jnFNHz4cA4ePMiKFSv8nktKSiIqKoq+ffueU5sBxeWGW1/2JvQA+UXwtzdh+0G4bQ5kFvkf88WvGK5CDLz/Lt5U3AlYMD9dCa8tPSFxNIAQjF+2wi87S9owrVhwAibGiQk9gAmmy4aHUDiaC2NehBzdCfVc5Vr8/7zzrRYtlBURkSrOOIcfOa7CkvrCwkIefvhhkpKSmDJlCmPGjPF5ftu2bTz11FNMmDCBUaNG8fzzz3P99dezatUqFi1adNq28/Pzeeutt4iKiqJnz57nFNfgwYMJDQ0lKSnJpzwtLY0VK1YwcOBAwsLCzqnNgLL9IBw46ltmmvDjFli5HSjlgsrlBNz+5XgAC4b75GMMvL9qvuUm1tPe4dTk2NSRnAL4ddfpzkJKcSA8BIvDQZ3DmTTZd4jwgkLSdWcKERGRoFQhH/HZ2dnce++9rFy5kpkzZ5Y6laVx48b06tXLp+x44r906dJTtu12u5k8eTL79+9n0qRJxMTEnLJuaaKjo+nXrx/Lli0jMzOzuDw5ORmPx8OwYcPOqb3ylJGRQVFRych5bm4uOTk5xY8dDgdHjhzxOSY1NfW0j9NCXJjVI/DTrhG0qoeBC99k3MRsXq3U+AxMwINpL+3Xypvwn1xmnmbc2Ns3EGLjYHXr6c8jLc27cPeYcnmtAqyPSw4fYcjyX+m+ejOdf9vBoO/WMvKXTaSlHQyo81Af6kN9qA/1UTF9SGAzTLP89rdLTk5m6tSpREZGkp+fz+uvv17qnPiEhAR69erFjBkz/J7r3bs3jRo14s033/R7zuPxMHXqVL744gvGjh3L7bffXqY4f/31V+644w4eeOABbrzxRkzTZNiwYURFRfHuu++Wqc2AMn8Z3Pm6dyoOwH0D4d9/hvV7oOtjmIVOwIoJGPPuxLioHvT/O2a+w3+cvX0TzDv6Yz7wPhSP2DsxhneAH3bA4dxjZd6E3kN48aEnTsExcGElC8Nigem3wgPXlNvpB6s3b/mZsMW7fcrcVoM/7R6FxaqvLEVEpGpabbx81nU7mWPLMZLAUiELZfv160dycjJz585lxowZF2Q6i8fj4amnnuKLL77grrvuKnNCD9ChQweaN29OUlISN954IytXruTAgQM89NBD5x1nQPhzT+jXDn7YAm0bwMWNvOXt4iFjHsbLX0NOAca4gRB7bJQ+dS5Gcgqs2Ao1o6B5PahXHXpfjGG1wrVd4Ov1kJWHcdVF0LkZpssNC36CjXvh+ssxshxYjuRCx3g876VgmgbWJjUw6lXDqB+FsW4PdGkBTWpX2ksTyCymB7fVIC86HLfVQli+g/ACB9579SmpFxGRqklbWpZNhST1AwcOpEuXLjzxxBOMHz+emTNn+iX2O3fu9DsuPT2dnJwcGjRo4FN+PKFPTk7mjjvu4C9/+ct5xzhixAhmzJjBhg0bSEpKIjQ0lEGDBp13uwGjfk0YVcoOM+EhMGGof3m1CLjpKu9PKYwGNeB23+cMmxVu7u5bduy/lkcG+jdyUcOziVxOIcRSSGq9Gnhs3mlP+dFh1DySqS0tRUREglCFLZsbMGAAzzzzDGvWrOG+++4jPz/f5/ndu3f7zZ2fP38+gM/iV9M0efrpp0lOTua2227jr3/96wWJ7/iC2bfeeoulS5fSp08foqN10yQJXNEud3FCf1xmjWpYdEdZERGRoFOh+9T37dsXm83GI488wrhx45g1axZRUVEAtGjRgsmTJzN8+HDi4+NJSUlhyZIldOrUif79+xe38e9//5vPPvuMVq1a0bRpU7788kufPho2bEj79u3PObZq1arRp08fFi5cCFClFsiKlEV2eDUg16fMbbFo8o2IiFRpGnoqmwq/+VSvXr2YPn06Dz30EOPGjeOll14CoHXr1owfP56XX36ZTz75hMjISEaPHs29997rc1OojRs3ArBlyxaeeOIJv/YTExPLlNQDjBw5koULF9KoUSM6d+5cpjZEqoooZ75fAu8IsevNUkREJAiVa1I/dOhQhg71n4/dvXt3fvzxR7/ybt260a1bt9O2+dprr12w+E5mt3v3Rb/mmmswNO9YAtwlaZtYHdmB0CInFo+JI8ROqyNbsHBlZYcmIiIiF5huRXOCDz74AJvNVuqFiEigSY+K5s+/LCDOkY7V7qTLgV/o9/u32lVAREQkCFX49JuKkpWVhdPpPG2dsLAwrFYr3333HTt27GDhwoWMGDGC2NjYCopSpPx837QjTbbmsbFeCxy2EJw2C7tjanCbvoUSEZEqTINPZRO0Sf2DDz7I6tWrT1snMTGRu+++m8cee4yIiAiuvvpq7rvvvgqKUKR8xRQW8e1FJduK7q9en+01G3CHqaWyIiIiwaZKJPUpKSkXvM3x48eTnZ192jpxcXHUr1+/XPoXqXSG/593mMfExFBKLyIiEmSqRFJfHtq0aVPZIYhUqgiHAwjxKauWn1c5wYiIiJwl7dJWNlooKxKkEpyHaHIorfix1e1m0JpVGHq7FBERCTpBO1Iv8kfXYEQLbh72Fjtr1yU7PILmB1OJaFoNw6preRERkWCjpF4kSIUOvYiiOzrR9D+rMUygThQx80dWdlgiIiKn5dHKrzJRUi8SpAzDIGLONSQ3TSM8083QKXdhjwyv7LBERESkHCipFwly+XF28uPsGCH6cxcREQlWmlwrIiIiIhLgNHQnIiIiIlWG7ihbNhqpFxEREREJcErqRUREREQCnKbfiIiIiEiVoVsklo1G6kVEREREApxG6kWC2A8bHHy2qTvufDsHQ3N5YHQMkeG6lhcREQk2SupFgtTOVBcp93/B2yuTqV6Yx6ovLmJ2+t08NKFpZYcmIiIiF5iG7ESC1Pr3f2PidwuoXpgHQJf9v3PVrHm4PZqtKCIiVZeJcdY/UkIj9SJBKubHX3FarHzeoiP7omswePs6uu7ZhMX0ANbKDk9EREQuICX1IkFqdUwdHrnxEX5q2BKAB/q4eGnR29xpWJTSi4iIBBlNvxEJUgvaditO6AFcVhsT+lxfiRGJiIicmabflI2SepEg5bT5fxGXFxJWCZGIiIhIedP0G5GgZUCIAeF2sBjgcEO+E9M0vc+JiIhI0FBSLxKkDKsFomxgHEvgw2zeXF6b34iISBWmj6my0fQbkSBlhlhKEvrjQqwapBcREQlC55zUJycnk5CQQEpKSnnEIyIXSmn70ZtgnJzoi4iISMCrEtNv8vPzefvtt9m0aRO///47hw4dolOnTrz22mt+dV0uF9OmTWPjxo2kpqaSn59PXFwcF198MX/+859p3bp1JZyBSNVjKXSB2wLWE67dC1xUkT97ERERuYCqxKd7ZmYmr732GrVq1aJ169YcOXLklHWdTiebNm2iQ4cODB48mIiICA4ePMhnn33GmDFjePHFF+nSpUsFRi9SNTXIzuCXgpoQaj22UNYDTndlhyUiInJa2qqybKpEUh8bG8sXX3xBnTp1AOjRo8cp64aHh/PWW2/5lV977bUMGTKEt956S0m9CBBbkAOeGlB4LJE3TQyPB2ug31E2+ReYkQw5BXBTd3gg0X/twDfr4dlP4FAW9G0Ph7Lhl53QtQU8fT00rFU5sYuIiJSTC5bUz5s3jzlz5jB69GgmTpxI165dSUxMZNCgQcyZM4etW7cSFRVFv379GDt2LBEREcXHhoSEFCf0ZVWjRg1CQ0PJyck5p+Py8vK46aabKCgo4L333qNmzZrFz82ePZs33niDyZMnM2zYsPOKT6Siba9VD7Is3sWxAB4Ts8iNC6NqXM3PWwLPfAIZufCnK2DmGIgI9a2TlAKPvg+702HIpdCnDdzzGuDxPr9mO0x8B+rFQHo2mCaYHnC7StpYt+vY/zBg0x74ZgPsftn/QqA0X66Gh9+BHYdgUEd4+U6oHXPepy4iInKhnfdnu9vtZtq0aXz88ceMGzeOMWPGFD+3efNmlixZwvDhwxkyZAgpKSksWLCA7du3M3v2bCyWsm++43a7ycnJweVycfDgQd5++23y8/O58sorz6mdyMhI/vGPf3DHHXcwZcoU/v3vf2MYBitXrmT+/Pn0799fCb0EpOzwcHDbfJJXq4WqsVfY0t/gzldKHr+2GOxWeOnOkrItqXDdv8F17JuGD36Gj36mOKEv3p/TBalHT2j8DFOM9h6C7zfBVW1PX2/nIRg+vWTK0scrIKcQvn7sjKcnIiJlp+k3ZXNeSX1hYSGPP/44y5cvZ8qUKSQmJvo8v23bNmbMmEGvXr0AGDVqFDNmzGDBggUsWrSIAQMGlLnvnTt3cv31Jbe8j4qK4rbbbvO5qDhbbdu25d577+WFF17g7bffZsiQIUyePJl69erx6KOPljlGkcoUX5jFGiPWp8y0V5EtLT/6qZSyn32T+qSUkoT+OM+JCf2J/z1HyzefOan/LMV/DcL/foXsfKgWUfoxIiIilaTMQ+XZ2dnce++9rFy5kpkzZ/ol9ACNGzcuTuiPO550L126tKxdA9CgQQNmz57NCy+8wMSJE4mPjyc3Nxen01mm9m666SauvPJKZs+ezf33309WVhbPPPMMUVFR5xXnhZSRkUFRUVHx49zcXJ/pRg6Hw2+RcWpq6mkfp6WlHbvDqPoItj7qZmVwMsNjkl4FzqOohn9S7Krl+7eWGVLaVwoeSk/kz/Hrh14XA2c4jzr+02w81cIpMkr6qmr/5upDfagP9XE+fUhgM8wTfwPOQnJyMlOnTiUyMpL8/Hxef/11Onbs6FcvISGBXr16MWPGDL/nevfuTaNGjXjzzTdL7aNHjx60adOm1C0tTyU/P5+bb76ZBg0a8OKLL571cSfKzMxkxIgR5OTkMHbsWG6//fYytSNSFQydcYDPqe1b6PbgetCO1VLJw/VpR6Hzw3Dg2LQZiwHvj4frLi+pk18EXR6HjftLyprVgh2+H2ReBiXJvoeSKTon1wHsNnC8f+YYi5zQ7VH4dXdJ2XM3wsPDz3ysiIiU2VLjP2ddt5epXO24Mk+/6devH8nJycydO5cZM2YQFhZ2IeM6ZxEREfTu3Zv58+ezb98+GjZseM5trF69uvgqdsuWLRc6RJEKdaBmLTh5sN5aRW4iXbcGrJkO/7cUjuTA6Muhc3PfOhGh8NNUmP897DoMiZdCj4vg0odgw56Sele2gUGXwu7DsPcI1ImGfAekZ8HF8fDtb/DbXm9diwU+mHB2MYbaYflTMH9pyULZvu0vwMmLiIhceGVO6gcOHEiXLl144oknGD9+PDNnzvRL7Hfu3Ol3XHp6Ojk5OTRo0KCsXZ/S8a+ZsrKyzjmpT0tL4+mnn6Z58+ZcdtllvPPOO3z66aeMGDHigscpUhFM8M4JL3B57y5rt0KYlSqznWXtGHjoDIvQq0XA/ztp7c2vM+DrtbAtzZtktznD37rT5d0GM/UoJHaGxnFnH2NUGNw78Ozri4iIVJLzWig7YMAArFYrjz/+OPfddx8vvPCCz1aVu3fvZunSpT7z6ufPnw9Az549y9Tn0aNHiYmJ8ds5Jz09ncWLFxMREUHz5s1PcXTp3G43jz32GEVFRTz77LPEx8ezfv16/vnPf9KxY0eaNm1aplhFKlWhB7JP2NrR7QK3B9O0UTVWy5aRxQKDOp19fbsNRnYrv3hERESqgPPe0rJv377YbDYeeeQRxo0bx6xZs4oXl7Zo0YLJkyczfPhw4uPjSUlJYcmSJXTq1In+/fv7tPP+++8XT31xuVykpaUxd+5cAFq1asVVV10FwMKFC3nvvffo1asXDRo0wGazsWfPHr744guys7N5/PHHz3kq0Guvvcavv/7KY489RrNmzQB4+umnufHGG3n00UeZP38+ISEh5/U6iVQ4dynzyp2eqrGlpYiIyCloS8uyuSD3oOnVqxfTp0/noYceYty4cbz00ksAtG7dmvHjx/Pyyy/zySefEBkZyejRo7n33nv9Rtrffvttn5XcBw4c4JVXvPtYJyYmFif1l156KZs2bWL58uWkp6fjdDqpVasWXbt25frrr6dDhw7nFHtKSgpvvPEG/fr185lqU79+fR577DEeeeQRXnjhBR566KEyvTYilcZ6ijdFvVeKiIgEnXPe/eZsJSQkkJiYyJQpU8qjeRE5g0tfL2TtjpO2eA2x4noyvPJ3vxERETmFb403zrpub/O2cowksFSJu8WLyIVnOEuZfuMqbatHERGRqkOzRMsmaJP6wsJCcnNzz1gvNjb2jHVEApK7lLdFj94qRUREglHQJvWLFi1i6tSpZ6yXkpJSAdGIiIiIiJSfckvqKztZvvzyy5k9e3alxiBSqYxTzJs3TbRaVkREJLgE7Uh9bGysptbIH1pUhAUMz7Ek/hjD0FxFERGp0rSlZdlUkXvGi8iF1rfVsWt2wyj+CYmwaucbERGRIKSkXiRI3dvZSmwdO4RYwGZAuI1He4dgnGpajoiIiAQsJfUiQapWuMHKWywMqLmZrjX38c5IK09eaa3ssERERE7LxDjrHykRtHPqRQQaRsPIMO+i9VGtmlVyNCIiIlJeNFIvIiIiIhLgNFIvIiIiIlWG7n1eNhqpFxEREREJcErqRUREREQCnJJ6EREREZEApzn1IiIiIlJlmLpJYplopF5EREREJMApqRcJYi4PrHE25htHG7ZnVnY0IiIiUl40/UYkSBW5TPp8BD8XXA3Ax2+avJfo4bqLdC0vIiJVl6nZN2WiT3eRIPXBZg8/p5a8M7pMgwmLnJUYkYiIiJQXJfUiQWrNLzl+ZXsLLLg9ZiVEIyIiIuVJSb1IkGq9YZ9f2cV7D2GYSupFRKTqMi3GWf9ICSX1IkGq7YFD3PXNKqILCgHosOcAdy/6BdCboIiISLDRQlmRIFW/IIOnFq5h6v++IDfUTo38QtLCqmOQiBJ7ERGR4KKkXiRI1SrMxoUbww2h+S4A6hZmKp8XEREJQkrqRYKUAbgsFha2aU1qTDX6/r6FZkcyMFFeLyIiVZepyeFloqReJEi5rS4S/3IHKfHxAEwePJDXF3zAmMoNS0RERMpBuV4LJScnk5CQQEpKSnl2IyKl+Kx9m+KEHsBttTJ1UH/tfiMiIhKEAm6kfsqUKXz++eenfL5Ro0Z8+umnFRiRSNW0o2YdOOleU3tq1MBtWLBWTkgiIiJnZFo1SbQsAi6pHzlyJF27dvUrX7VqFcnJyfTo0aMSohKpemJzsiHMt6xafgEW045m1YuIiASXgEvq27dvT/v27f3Kv/zySwCGDRtW0SGJVEmHIqqDwwNWAwwDPCZZ9jA8hnHBRuqL/r2cold+xnMoD9OwYL20AeFP98PerREAptNN/lPfUvTeOiw1wwmfdBWhIy6+QL2LiIjIcZWS1M+bN485c+YwevRoJk6cSNeuXUlMTGTQoEHMmTOHrVu3EhUVRb9+/Rg7diwRERGnbS81NZWVK1fSrl07mjdvfk6x3HDDDWRnZ5OcnIzF4rvEYPHixUyaNIkpU6aQmJh4zucpUpmaHc2E8IbgKZlD3/LwYSxmA/xG6vemw/Ofwub9FLZsxvadtXD8lk5sjSJqJcZTuL8Id1oe4cNaYXfn407eiJnvJPeHg2QRRaYlliLDRuQ32dTt+QZ1do/HWieag3/+nNT3dmFiozpHiR75Lqk9EohIbEHub5k4jzqoN6oJcYMbsvnfv5GRtJdct4WUbi3YV686aeGhWOuGcPfloSS2tVNU5CH5q2y+XV3IAYsd+0VRXFGYQ8GuPL6vVYONtnAsVoMRLeCxy63UCIPXf3Hz8W8u6kYbTLzSTrs62lZBRESCT4Um9W63m2nTpvHxxx8zbtw4xowZU/zc5s2bWbJkCcOHD2fIkCGkpKSwYMECtm/fzuzZs/0S7hN99tlneDyeMo3SDx8+nOnTp7NixQouv/xyn+eSkpKIioqib9++59yuSGW7NPUgo3PzaZaZSsPsDL5u3p4xq9dgGvf6pvQFRdD9UdiTDkDYknX/n737jo+qyvs4/rkz6R0IvVcBRTGEppSghCJBArsgq7uurmtZyIMiCCKCYKe4IEuToouCIopujKiIKCCiQgRFpEjvkRLSCCkzc58/AoEhQcKkTcbv+3nN6/Gee+45v9HNzG/OPedcwqnNdiLIOGLAz4n59bM/34cv5/DjHABeeHHaCMOOhRy8yLAGkGIPxnHfJ4SMj+LXd04CQQBkEEgtTmDfcIBfN2bkd3/y82NY6wVgO5yJxQYLB91KupcfnDSBLI4fs9F3h50P/h7Ani/PkLglr28fskk/eo6RjasS4B1IerY3ZOe1+e8fTL4+YueOOg4mrrHl9/XhDjs/D/WjfpgSexERd+WwaIqoK8osqc/KyuLpp59m/fr1hY5879mzh6lTpxIVFQXAwIEDmTp1KkuXLmXVqlX07Nmz0HYdDgcJCQkEBATQo0ePa47rjjvuYMaMGcTHxzsl9UlJSXz//fcMGDAAPz+/32lBxD2F5qSwdPnrGOSN1A/dtAqbEQAMwWmkPiExP6G/oBpH2c31BJFTYPZ9Dr74cQ47BkephZ9pAxMCySHN9CPT6kvS2mQyZu3g8jsCZwjhnKXgx07u4Uz8suxsb1yD9CDnv7fqNhu7TR/mfnWOsPMJ/QXBOXaCs+2kBPg4N2gYbDpu8usxu1Nxeja89aOdp6OU1IuIiGcpk2+2tLQ0hg4dysaNG5k2bVqhU1nq16+fn9BfcGEkf82aNVds+/vvvycpKYno6OirTtMpTHBwMNHR0axdu5aUlJT88oSEBJdH/0tLcnIy2dnZ+ccZGRmkp6fnH+fk5HD69Gmna44fP/67x0lJSZiXbHGoPjynj5ppx/IT+gus5jlOXNZHRmoaV1Zw+8sLJRkEYb9sXCDIkQ2mSSa+OGyOAtc6MMg0fK/YW2GjMxdKsrJzCr3m8vd4Kbuj4Dn7JUWe9t9cfagP9aE+itOHVGyGaZbeptUJCQlMnDiRwMBAMjMzmT9/Pq1bty5QLzIykqioKKZOnVrgXLdu3ahbty5vvvlmoX08+eSTfPHFF7zxxhu0atXKpTh/+uknHnjgAR5//HHuvvtuTNOkX79+BAUF8fbbb7vUpkh52/a3N7hhcYJTmQMDi20ZWC9ZKptxDprFwfEz+UUnqcE22uKFjQb85jTe7sM5/DlHMmEkU9mpfRM4aQ2i6f81o3L/hmyN+sTpd4HNCllel42qA5Za/jiOZ4LdYO5dnTgbcDHx/83Lyi/+frxzjz97V59h67as/HNnva181rgavg4HmT6X/MAwTW6sAr1qm0z+5uL0mwBv2DrUj8aVNVIvIuKuPgpdUuS6d6beU4qRVCxlMv0mOjqahIQEFixYwNSpU0tsOktKSgpr166lcePGLif0ADfddBONGzcmPj6eu+++m40bN3Ls2DFGjRpVInGKlIdDoVVoiYHlkqw62T+YSpfvUx/kD+ueh+ffh51HONe4IUkHqhG8O5UqwTYq9bqBrCQbjqQM/O5sho/tLPYVOwgNDSb580ynhbg2Px+aDb+eBs+1wbBaaPm/7uwbsZGcE+fwqhOET61AAkwIaxfO2d1p5JzOoeagBlTrV4cdU34h9ePD3LfxZ77v0JQj1UP5zd+X6tV9eLqjL4Nv9iGzeVU++CiVtVuySPLygqbBTDiXSs7Bs6ytVoVd3n5YLAYxjQye62wl3B+qBxks326nRrDB6E5eSuhFRMQjlUlS36tXL9q2bcv48eMZPnw406ZNK5DY79+/v8B1p06dIj09ndq1axfa7ooVK8jNzS2RKTL9+/dn6tSpbNu2jfj4eHx9fendu3ex2xUpL9Uzc4hvfge3HN5IcHYGeys3ZHv4ddxlOuDyTS2b1IT//h8A/sDlP5GDLm98bDQAjT7ez/FnNpJ7OIPQOxtS+9+dsIZcHIkPv7M+4XfWL1K8bf7dDv6d9wyKAVeoE+Bv4a93VeKvd11a6gdUvWK7j9/qzeO3ehcpBhERkYqqzBbK9uzZE6vVytNPP82wYcOYPn260xz4gwcPsmbNGqd59YsWLQKga9euhbYZHx+Pt7c3d9xxR7Hju+OOO/jPf/7DW2+9xddff83tt99OcHBwsdsVKS+/Bddmf6XK7K/U0KncgaXEFtOExjQkNKbh1SuKiIgUkandb1xSpltadu/eHS8vL8aMGUNcXBwzZswgKChvDLBJkyaMGzeO2NhY6tWrR2JiIqtXryYiIqLQXW22bdvGvn37iI6OJiwsrNixhYSEcNttt/Hpp58CeoiVVHz7qlQHDjiVnfH31cNkRUREPFCZTy6NiopiypQp7Ny5k7i4ODIy8varbt68OVOnTmXr1q1Mnz6dLVu2MGjQIKZNm1boHvXx8fFAySbfAwbk3fSvW7cubdq0KbF2RcrDptrVOBjqT+sje7hl3zaqp57ivRuaKKkXERHxQKU6Ut+3b1/69u1boLxTp05s2LChQHn79u1p3759kdoeO3YsY8eOLXaMl/L2zpt3e+edd2IYynykYss1bfx94xp+qlWbo6HV6LlrF9G7qmBwW3mHJiIi8od19OhR1q1bx4kTJ/jTn/5EnTp1sNvtpKamEhoaitVqvXojhSjT6TfubtmyZXh5eRX6Q0Skoond9jMPDrqLzXXqADChR09eSfgI0wT9ZhUREXdleuh3lGmajBgxgpkzZ2Kz2TAMg1atWlGnTh0yMjJo0KABzz77LI899phL7XtsUp+amkpubu7v1vHz88NqtbJu3Tr27dvHp59+Sv/+/QkPDy+jKEVKT1JoGJt96uQf261WpkZ1YxgmmoMjIiJStqZMmcKrr77K6NGjuf3224mOjs4/FxoayoABA1i+fLmS+ss98cQTbN68+XfrxMTE8NBDDzF27FgCAgK4/fbbGTZsWBlFKFK6NtWvB84PHORoaCgOjMs3tBQREZFSNn/+fO69915efPHFQp/me+ONN+Zv2OIKt0jqExMTS7zN4cOHk5aW9rt1qlatSq1atUqlf5Hy1vDMcaCRU1m7w3uAluUSj4iISFF46paWhw8f5pZbbrni+cDAwKvmrr/HLZL60tCiRYvyDkGkXP394BZqfL+G8bcP5HRgMLft3cab78/GOvs1Cjx8SkREREpVtWrVOHz48BXP//DDD9SrV8/l9j02qRf5o2vcpQFD/jOVhxJXk+XlTVBONllNa4OLq+pFRETEdQMGDGDu3Lncd999hIaGAuTvtvj555/z3//+l1GjRrncvmGaplkikYqIe7HZccROwrLiBwDMQF+M/42G7jeVc2AiIiJX9mH4O0Wu2//UX0oxkpKVmppKly5d2L9/P507d+azzz4jOjqajIwMvv32W26++WbWrVtHQECAS+2X+cOnRKSMeFmxf/gE/xvdnlUP3YRt3ywl9CIi4vYcRtFfFUloaCjfffcdo0aN4ujRo/j5+bF27VpSUlJ45pln+Prrr11O6EHTb0Q83olGYQBEVQoq30BERET+4Pz9/Xn66ad5+umnS7xtjdSLiIiIiFRwGqkXEREREbfhqVta/uMf/7hqHcMwWLhwoUvtK6kXERERESllX375Zf5uNxfY7XaOHz+O3W6natWqBAYGuty+knoRERERkVJ24MCBQstzc3N57bXXmD59OqtWrXK5fc2pFxERERG3YRpFf3kCb29v4uLi6NGjB3FxcS63o6ReRERERKSc3XTTTaxbt87l65XUi4iIiIiUs1WrVmmfehEpXJYNvstpRIojkLan4Oaa5R2RiIjIH9Ozzz5baHlKSgrr1q1j8+bNPPnkky63b5imabp8tYi4rXO5Ju3esrHtVN6xYcBbd1i553rdoBMREfe1rOa7Ra476PhdpRhJybJYCv/+rVSpEo0bN+af//wnDz74YIEdcopKI/UiHuqNnx15Cf35DwcTGLLKrqReRESkHDgcjlJtX9/uIh7qg19NvEwHGOS/zmbZsTt0c05ERMTTaKRexEMZZ9KxWYOdyrxMB3lj9h6yD5iIiHgch4d8RR06dMil6+rVq+fSdUrqRTzUTccP8kXIDXDJshmr6cDQMhoREZFS16BBA5fmx9vtdpf6U1Iv4qHqJZ/A2y+XXOvFP/OeO3/E5JZyjEpEROSP4fXXX3d50asrlNSLeKjlN7QnN9X5T/zbes3yF86KiIi4I9PiGd9T9913X5n2p4WyIh4q3bfgAyySgiuVQyQiIiJS2jRSL+KhTNPMWxN74eUZAx8iIiIV2jfffMPmzZtJTU0tsM2lYRiMGzfOpXaV1It4KhNwXHasRbIiIiLlIjk5mT59+rBx40ZM08QwDC48A/bCPxcnqb/m6TcJCQlERkaSmJjoUociUjaCcrOvcEaJvYiIuC/TKPqrInniiSfYunUrb7/9Nvv27cM0TVauXMmvv/7KI488QuvWrTl27JjL7bvFSH1mZiaLFy9mx44d7Nq1ixMnThAREcG8efMKrb9q1So2bNjAzp072bdvH3a7nY8++ohatWqVceQi7qtV0iHW+zR1KrM6tKWliIhIefjkk094+OGHueuuuzh9+jQAFouFJk2aMGvWLAYMGMBjjz3GO++841L7brFQNiUlhXnz5rF9+3aaNm2K1Wr93frvvfcen3/+Ob6+vtSpU6eMohSpWJqfPEZATpZT2d+3rMWsaJPrT6XBm2vhsx/h0rmHNjt8lAhPvQMzP4OjyeUWooiIyNWkpKRw/fXXAxAUFARARkZG/vkePXqwcuVKl9t3i5H68PBwVqxYQfXq1QHo3Lnz79Z/9tlnCQ8Px8vLi0mTJnHw4MGyCFOkQvmoZSTv/GcGL9w2gKTgMAZs+x4fmy1/S8ukDJO3f3GQY4fBLS00CCvnZH/tL5DwA2w9CDm50DcSbmoIMS9Bdi5gQnAgtGsKf2oHz7wLJ9MvXv/YInjvcWjTAN75BqwWuKcz1Lxsxx+HAz7eApv2QbvGEHOztvkUEXEjpod+JteqVYukpCQAfH19qVatGj/99BP9+vUD4OjRo8Xa177EkvqFCxcyZ84cBg0axMiRI2nXrh0xMTH07t2bOXPmsHv3boKCgoiOjmbIkCEEBFzcbs/Hxyc/oS+KGjVqlFTY/Pbbb9x9991UqVKFN998Ez8/v/xzTz/9NCtXrmTmzJm0b9++xPoUKQunA4P4070jsHnl/ZlP79IHMHgR2J1s0nFRLqfP5dV97hs7X93jRbta5XTz7vnlMG6pc9naHeBlzRuRB8CA9ExYvTXvdTm7Hf4xB2y5kHH+DsWLH8CGF6B57Yv1HpgP//364vE/usLCB0v07YiIiFyuS5curFq1irFjxwJw1113MXnyZKxWKw6Hg+nTp9OzZ0+X2y/2N7jdbuell15izpw5xMXFMWrUKCyWvGZ37tzJyJEjadWqFY899hitW7dm6dKljBgxosAWPuWlevXqjB8/nn379vHKK6/kl8fHx/PZZ5/x97//XQm9VFgXEnrg/Gh03nz6f39vz0/oATJz4YVvXHssdbFlnIOXPiz8nO1aYjIhJf1iQg9w5ixM/eji8e4k54Qe4PW1sCfpGvoRERG5do8//jh33nkn2dl5G1lMmDCBDh06MG7cOJ555hnatGnDf/7zH5fbL1ZSn5WVxejRo4mPj2fChAkFnpy1Z88ennvuOUaMGMHAgQOZNGkSgwcPZtOmTaxatao4XZeorl27ctddd/Hhhx/yxRdfcODAAaZMmUKrVq145JFHyju8fMnJyfn/Q4C8eVjp6RenH+Tk5OQvvLjg+PHjv3uclJSUv52S+vCsPq50A+/48d84kl5wsezR9HJ6H2fOQuaVduq5ksIX+xZ6y/ZIXuw5OTmkbj9QeHNHzwAV/7+5+lAf6kN9FKcPKV2tWrXi8ccfx9fXF4BKlSrxxRdfkJycTGpqKmvWrKFmzZout2+Y5rVthZGQkMDEiROZPHkyS5YsYffu3UyaNImOHTs61YuMjKR+/fosX77cqfzUqVP06tWL6OhoXnrppUL76Ny5My1atLji7jeXmjRpEu+9916xd7/Jycnh/vvv59ixY1StWpUTJ07w9ttva0cdqbAi3shlywnTab64T24umWP8eGOryYOfOI+CT+xsZXzn31+kXmoiRsGW/UWsfPGOg/OxmTcH/6cDztVn/xP+df52ZnYu1HsUTqRdPF89FA5OB19vF4MXEZGS9Fb994pc928HB5ZiJCVr+/bttGzZstTad3mkfuLEiWzdupUZM2YUSOgvaNiwYYGy8PBwgoODOXr0qKtdlwofHx9eeOEFMjMz2bdvH08++aQSeqnQIo7u5433XqNOymksDgf9fklkwfvzAXjgJgtP32oh1BcCvGFoGwtjbinHzbDeHwHdrncuCwmA1x6Cm+qfL7jwWFwDAn25+KhcR97/v7khrJ0Aj96Rdz7YH56MhUd6XGzT1xsSRkBEg7zjNg0h4XEl9CIiUupuuOEGbrzxRl588UX27NlT4u27vFA2OjqahIQEFixYwNSpU50WmFZU69evx27PG73ctWsXvXr1KueIRFzXZ+cW+v/wNff98DUOw8BimtgNA6v5f2AxeK6rF891Jf8JduWqUXX4ckLezjQWS96i1wtb2z4UfXErS8PIeyquxQJvfw2vfAQZ2fDXzjD2T3nl0++HafddrH+5do3hh+cv9iUiIlIG5syZw7Jlyxg/fjzjxo2jdevWDB48mEGDBlG/fv2rN3AVLn+j9erVi2effZZNmzYxfPhwsrKyCtTZv7/g7fRTp06Rnp5O7dq1C5wrTzt27GDWrFm0b9+enj17snjxYr777rvyDkvEZUfDKuf/s+X8LLvjwWHYL0t0yz2hv9SFJPvyZ1VYLHkvw7hY5+7O8MMU2DUDxg10TtAN4+rbVCqhFxFxS6ZhFPlVkTz88MOsXr2ao0eP8uqrrxIYGMiTTz5Jo0aN6NixI6+++mqxnihbrG+1nj178sILL7BlyxaGDRtGZmam0/mDBw+yZs0ap7JFixYBeYtT3UVmZiZPPfUUISEhPPvss4wZM4ZatWrxzDPPkJysB9pIxfROq478WLNe/rHDMBjbY1A5RiQiIiLVq1cnLi6OdevWcejQIV555RUMw2DEiBHFGrEv9j713bt3x8vLizFjxhAXF8eMGTPyn5LVpEkTxo0bR2xsLPXq1SMxMZHVq1cTERFBjx49nNp5991381dl22w2kpKSWLBgAQDNmjWjS5cu+XU3b97M5s2bgbwRdoBly5bl9/vPf/7zmt7DSy+9xJEjR/jPf/5DlSpVAHjhhRf45z//yYQJE3j11VfdazRTpAhsFiu3PDKBu7Z+R53UZBJa3MxPtRrwenkHJiIiIgDUrFmT66+/nhYtWrBt2zbOnj3rclsl8vCpqKgopkyZwqhRo4iLi2PmzJkANG/enOHDhzN79mw++OADAgMDGTRoEEOHDs3fy/6CxYsXO23PdOzYMebOnQtATEyMU1K/adMm5s+fX+D6C64lqf/444/59NNPuffee+nQoUN++Q033MCQIUOYMWMGS5Ys4a9//WuR2xRxB01PJ7HRuw7/bXPJXTHTzHtdccNLERGR8mV6+FeUaZqsWbOGd999lw8//JBTp05RqVIlBg8ezF133eVyu9e8pWVRRUZGEhMTw4QJE0qjeRG5ihcf/5qxVdtzaQJfNSOFpGcrY7l8zrqIiIibWNTw/SLX/fv+P5diJCXr66+/ZtmyZbz//vucOHGCkJAQYmNjueuuu/JnvhRHiYzUi4j7WdX0RkhxHu44GRha4RYWiYiIeIKuXbsSFBRE3759ueuuu+jVqxc+Pj4l1r7HJvWZmZkFFu5ezmq1UqlSpTKKSKRspfoFFCw0zu/zLiIiImXqvffeo0+fPqW2DbzHJvVvvfVWgXn3l6tZsyYJCQllFJFI2Sp0Xp3yeRERcXMOD72j/Kc//alU2y+1pD4xMbG0mi6SPn360Lp169+t4+vrWzbBiJQDH7sNLOf/xM+vjTVKZwmNiIiIlDOPHamvU6cOderUKe8wRMpN65NH2GhpkHdwftBD8+lFREQ8kx6pKOKh/mY7WKDstr3bsJqOcohGRESkaEyj6C+5SEm9iIfqFNuUlz99m+CsvAXj7Q7tYUH696DtLEVERDyOx06/EfnDa1WfEQ824O+jhmM7Z6FW9+ZY5jxc3lGJiIhIKdBIvYgHMwfdwkfPdOCTl9thX/IoVAku75BERER+l2kYRX5VNGlpabz88sv07NmTm2++mY0bNwKQnJzMv//9b/bs2eNy2xqpFxEREREpZUeOHKFr164cPnyYpk2bsnPnTjIyMgCoXLkyr732GgcPHuTVV191qX0l9SIiIiIipeyJJ54gPT2dH3/8kWrVqlGtWjWn87GxsXz88ccut6/pNyIiIiIipezzzz9n2LBhtGzZEqOQqUONGjXi8OHDLrevkXoRERERcRsVca58UZw7d46qVate8Xx6enqx2tdIvYiIiIhIKWvZsiXr1q274vn//e9/3HzzzS63r6ReRERERKSUPfbYYyxdupRJkyaRmpoKgMPhYM+ePfztb3/j22+/Zfjw4S63r+k3Ih4ufG8mAWdyMe88CzXCyjscERGR3+WpT4r961//ysGDB3n66acZO3YsAL169cI0TSwWCy+++CKxsbEut2+YpmmWUKwi4kZMm53UmIXs+y6VTKsPtR1p1Fs2CGv0deUdmoiIyBXNb/Zhkes++Gv/UoykdBw6dIjly5ezZ88eHA4HjRs3ZsCAATRq1KhY7WqkXsRDZb37E5//4k9GlSpgmvxq1KHNkC+4abeSehERkbKUmZlJ586defDBB3nkkUeKNc3mSpTUi3iove/vp2p2Krcf34K/PYejAVX4sVJjbrQ7MKxaTiMiIlJWAgIC2L9/f6FbWZYUfbOLeCjjeAodTu4g0J6NBZO6mae4+cweHA7NuBMREfdlWowivyqSXr16sXLlylJrX0m9iIeqdfYkBiZc8qqdeRoP3f5XRETErY0bN45ff/2Vv/3tb6xfv56jR4+SnJxc4OUqTb8R8VAnQ8KoxyGnsmyrF37K6kVERMrc9ddfD8D27dt5++23r1jPbre71L6SehEPlente8mRAZhYTAcOwFpOMYmIiFyNpz5Rdvz48aU6p15JvYiHqp16krxk/gIDL4cDw3SgmXciIiJla8KECaXavpJ6EQ8VkpXOtuo1+Xe32zgaGkafX7Yx5Jt1OCf6IiIi4gmU1It4qKSQIG6/+1+k+gcAsLZJM46GhTBdOb2IiLixirarTVE9++yzV61jGAbjxo1zqf1rfqJsQkICEydOZO7cuURGRrrUqYiUvsmPrGF0k05OZYHZWaSN9sfipVn1IiLinuZe/1GR6z7yy52lGEnJsliuPPXVMAxM08QwjIq9UDYzM5PFixezY8cOdu3axYkTJ4iIiGDevHkF6qalpbFixQrWr1/PgQMHSElJoXr16rRp04YHHniAGjVqlMM7EHE/pqF58yIiIu7C4XAUWnbw4EFmzZrFunXr+PTTT11u3y2+9VNSUpg3bx7bt2+nadOmWK1XHkXctm0b06dPxzAMBg4cyBNPPMGtt97KJ598wuDBg9m3b18ZRi7ivgZu/oGQc+ecyu7//rtSXXlf0mxZdnIzbdd8nWmanMnSQ7ZERMS9WSwWGjZsyNSpU2natCn/93//53JbbjFSHx4ezooVK6hevToAnTt3vmLdBg0asHz5curUqeNU3qlTJ4YOHcrcuXOZPHlyqcYrUhHUTE1n9expTO0WzdHQMPpu/5khX68Dbivv0Jxk5JisP+SgfqjBdVUMft2VhdWA02/v4Nd3D+Cwm2RH1KTbpAhO+vjiMKFJqMkH2+1U8jfod52Fd7Y7yMyFh2628NVheOTjXJJSHTSq6cUrURbIdXBjTSt1wtxiHENERH5PBRp8KkldunRh9OjRLl9fYkn9woULmTNnDoMGDWLkyJG0a9eOmJgYevfuzZw5c9i9ezdBQUFER0czZMgQAgIC8q/18fHJT+ivplatWoWWt2/fntDQUPbu3XtNcS9ZsoRp06Yxc+ZMOnTo4HQuJyeH3r1707RpU+bOnXtN7YqUt1OBQbTatZtF77yZX+YATNOB4R436VhzwE7/ZbmkZOUd35BzjogDydQ5fpJm+44AeXv1+G06xtOP+fNe51aQ44Cs8/MNDRMCvMCa935GrrERlHIOv4xcqgBnTkHsTiu5FgtWC7zYy49RUb4FAxERESlniYmJvzvv/mqKndTb7XYmT57M8uXLiYuL47777ss/t3PnTlavXk1sbCx9+vQhMTGRpUuXsnfvXmbNmlWswC+XkZHB2bNnady48TVd16dPH2bNmsVHH31UIKn/6quvSE1NJTY2tsTiFCkrP1arQQ92O5Wl+/jibVjcJKWHR1bY8hN6gG0+/tQI8KV5SnqButcfPsl7jksSegDfiwk9QK7FQq7Vih+5AFhMCM21c8rXgt0BT32WxeCbvKlXyV3+DYiIyB/Fm2++WWh5SkoK69at44MPPuCf//yny+0X65stKyuL0aNHEx8fz4QJE5wSeoA9e/bw3HPPMWLECAYOHMikSZMYPHgwmzZtYtWqVcXpuoCFCxdis9no06fPNV0XFhZGt27dWLNmDampqU7n4uPjCQkJoVu3biUZqsuSk5PJzs7OP87IyCA9/WLyk5OTw+nTp52uOX78+O8eJyUlcekGSOrDc/pI9/EmKSDI6dx/b2jDKTd5H0nJ6ew6XXDe+2k/b04F+RcoPxnoD5dvCGAteIs218d5TY7XJV3YHfDT8YuNeNp/c/WhPtSH+ihOH+7CtBhFflUk9913X6Gvxx57jHXr1vHkk08yY8YMl9t3eUvLyZMns2TJEnbv3s2kSZPo2LGjU73IyEjq16/P8uXLncpPnTpFr169iI6O5qWXXiq0j86dO9OiRYtCd78pzBdffMGYMWPo2LEjr7766jUvBExMTOSRRx5h5MiRDB48GIBjx47Rr18/Bg4cyKhRo66pPRF3cDTiRXq17M+YjV9SNy2Vt1rejJfDwqwvumO4yZaWreZms+2E80dQj8MnCTl7jlu37KJSVt4X0llvL166vT1HGlaBjEsyez8LXJbEB6WcIzjt4hdZjmFw2jfvpqSXBQ6OCaZWqEbqRUTc1ZwbPy5y3X9tjSnFSErWwYMHC5QZhkGlSpUIDg4udvsuT7+ZOHEimZmZzJ8/n9atWxdap2HDhgXKwsPDCQ4O5ujRo6527WT9+vWMGzeOFi1a8OKLL7q0s0dkZCT16tXjo48+yk/qExISME1TU2+kwlrRKIIXv/mC2w7krTNpeWo1T0T3xTTd55myC2K8iV2WQ1IGWAyIzM2k5rkcsFhZ0a8tOfuSsTpMNteuTnalALBYwB84dz6xz7bnjdafn4Ljh4M/NTJZ9SOYQKC/wVmLFezg5wWvxPgpoRcRkXJhGAZVq1bF37/g3WiAc+fOcfLkSerVq+dS+y4n9dHR0SQkJLBgwQKmTp2Kn5+fq025bMOGDYwaNYpGjRoxc+ZMgoKCrn7RFfTv359XX32VHTt2cN1115GQkEDLli1p1qxZCUYsUnZMiyU/oQfws9t49Pt1mNYu5RiVs/Z1LBx81JcfjpnUCTGoG+rHwQOBeHkZ1K7jw7G0anz5ay73nbPT83ofTtitOEwrDUK8+XyPnVA/g9saWlix18G5HJNBLb2xWHw4fNrOiTQHN9XzIjMXfk6y07yqhSqBSuhFRKR8NGzYkLfeeou777670PMfffQRd999d9k/fKpXr160bduW8ePHM3z4cKZNm1Ygsd+/f3+B606dOkV6ejq1a9d2tWsgL6EfOXIkDRo0YPbs2YSEhBSrvb59+zJ79mzi4+Pp2rUrSUlJBdYIiFQkHY4W/PtrcuY0FtPEfcbqwcdq0LHuxXjqN7i4O02tEAt/jbx4fOkeWQNvuPjx1a+Z8xSculWs1K2SVxZihVsbuMXuvSIiUgSmh25pebUZ77m5ueW3+03Pnj2xWq08/fTTDBs2jOnTpzttVXnw4EHWrFlDVFRUftmiRYsA6Nq1q8v9fvfddzzxxBPUr1+f2bNnExoa6nJbF4SFhREVFcVnn33Gb7/9hp+fH7169Sp2uyLlpUnyScDEyNvIEhMLYLjVlpYiIiKeLC0tjZSUlPzj06dPc+jQoQL1UlJSWLp0KTVr1nS5r2IPX3Xv3h0vLy/GjBlDXFwcM2bMyJ8G06RJE8aNG0dsbCz16tUjMTGR1atXExERQY8ePZzaeffdd/NXZdtsNpKSkliwYAEAzZo1o0uXvCkD27dvZ8SIEZimSd++fdmwYUOBmO644w6X3kv//v1ZtWoVX3/9NTExMcWaziNS3vJS+FwM8kYGTOw4sOJOo/QiIiKebNq0aTz77LNA3pz6xx57jMcee6zQuqZp8vzzz7vcV4nck46KimLKlCmMGjWKuLg4Zs6cCUDz5s0ZPnw4s2fP5oMPPiAwMJBBgwYxdOjQArcXFi9e7LQ907Fjx/If+BQTE5Of1O/duzd/i6Z///vfhcbjalLftm1b6taty+HDh+nXr59LbYi4DzM/oYe8VN6C3aXF5CIiImXFNDznbnKPHj0ICgrCNE1GjRrFX/7yFyIiIpzqGIZBYGAgbdq0ITIy0uW+rjmp79u3L3379i1Q3qlTp0JHzdu3b0/79u2v2m5CQkKx+i8JhmHg7e1N/fr1ufnmm0ulD5GyYimwqXse0zQ1Vi8iIlIGOnbsmL/t+9mzZ/nTn/7EDTfcUCp9ec5PoRKwadMm9u3bR//+/cs7FJFiO+PrW6DslG+w0+i9iIiIlI1nnnmm1BJ6KKHpN+4oKyuLjIyMq9YLDw9n06ZNHDlyhP/+979UqlRJe9OLRzgUWIud1QJpfXov/vYcjgVU4Zvq13O3YdVIvYiIuK2K9qTYa/XNN9+wefNmUlNTcTgcTucMw2DcuHEuteuxSf2qVauYOHHiVeslJiYyf/58fvrpJxo2bMiECRO0QFY8QmjOWX4KrcvukDpYTQd2i5XgnMzzI/We/YEpIiLibpKTk+nTpw8bN27MmwprGPnbXF74Z7dM6hMTE0ur6SLp2LEjs2bNKlLdefPmlXI0ImWvwdlD/JrpS1JAZeyGFYvDTuSpHRgOe/4TWEVERKRsPPHEE2zdupW3336b9u3b06hRI1auXEnDhg2ZNm0a3377LZ9++qnL7XvsSH14eDjh4eHlHYZIufGq7E+PHV9zxL8emV5+1Mr8jTB7EqZh0Ti9iIhIGfvkk094+OGHueuuuzh9+jQAFouFJk2aMGvWLAYMGMBjjz3GO++841L7Gq4T8VDmgFvwIZ1G537h+vQfqWw/jCMwBMPLevWLRUREyolpGEV+VSQpKSlcf/31APlTvS9d/9mjRw9WrlzpcvtK6kU8lPWRrmQ1vR47/phYyaUSxqv/KO+wRERE/pBq1apFUlISAL6+vlSrVo2ffvop//zRo0eL9SwZj51+I/JHZwT4YN04inXDZhJwJpeIp+/Bq32j8g5LRETkD6lLly6sWrWKsWPHAnDXXXcxefJkrFYrDoeD6dOn07NnT5fbV1Iv4sGMQF/2dKoMQJuIuuUcjYiISBFUrFk1Rfb444+zatUqsrOz8fX1ZcKECfzyyy/5u9106dKF//znPy63r6ReRERERKSUtWrVilatWuUfV6pUiS+++IKUlBSsVivBwcHFal9JvYiIiIhIOQkLCyuRdrRQVkRERETchqfufgNw6NAhHnnkEa677joqV67MunXrADh16hTDhg1jy5YtLretkXoRERERkVK2fft2OnfujMPhoH379uzZswebzQbkPV9p/fr1nD17loULF7rUvpJ6EREREZFSNmrUKMLCwvjuu+8wDINq1ao5ne/Tpw/vvvuuy+1r+o2IiIiISClbt24d//rXv6hatWqh+9HXq1ePo0ePuty+RupFPNxZ04cMhx+mWd6RiIiIXJ1pqXhz5YvC4XAQEBBwxfMnT57E19fX5fY1Ui/iwcZ/YzIqbTDjz/6Zm96ws/O0MnsREZHyEBERwYoVKwo9Z7PZWLp0KR06dHC5fSX1Ih7qq725vJxowWbk3ZDbme7FP99JLeeoRERE/pjGjBnDZ599xr/+9S+2bdsGwG+//cYXX3xBjx492LFjB08++aTL7Wv6jYiHWvnpYaAeVTPSqJGWyrYatfkmKwi7w8Tqobc2RUSk4quIW1UWRe/evfnvf//Lo48+yrx58wD461//immahISE8Oabb9KlSxeX21dSL+Khsg6eZsrGDQxb/wXeDjt7K1flr395EIujKVj0py8iIlLW/va3vzFgwAA+//xz9uzZg8PhoHHjxvTs2VNPlBWRwoWkZzJi3cr848bJJ/l3wlJsrz6DdznGJSIi8kfx1FNPMXjwYG688cb8ssDAQPr371/ifWlOvYiHuuHk8QJlHQ/t0y95ERGRMvLyyy/nz58HOH36NFarlS+//LLE+1JSL+Khsr0Kpu+/VK+FoxxiERERKSrTMIr8qojMUtpjWkm9iIf6LSiYD6+PyD9O8/VjZMxdWB1K60VERDyN7sSLeKhV17Xi8+a3Ebs1kZYnjjKvfTdOBYdgt1qxlndwIiIiUqKU1It4qAMhlZn/+mv8c9NXAPzfhk+4874nMM3rgIp5y1JERDxfRZ1WcyUHDhxg8+bNAKSm5j0vZvfu3YSFhRVaPyIiotDyqzHMa5zYk5CQwMSJE5k7dy6RkZEudSoipe+x4d8zffpkp7LNtRrQ6tAUvK2aeSciIu7p37cUfRHp4xtuK8VIis9isWBc9iPFNM0CZZeW2+12l/pyi5H6zMxMFi9ezI4dO9i1axcnTpwgIiIif2P+S6WlpbFixQrWr1/PgQMHSElJoXr16rRp04YHHniAGjVqlMM7EHE/7Y7sLVAWcewAUDoLdERERMTZG2+8UWZ9uUVSn5KSwrx586hSpQrNmzfn9OnTV6y7bds2pk+fTtu2bRk4cCBhYWHs3buXDz74gFWrVvH666/TqFGjMoxexD1tqtOIuy8r21KrATdgaJ96ERFxW540/ebvf/97mfXlFkl9eHg4K1asoHr16gB07tz5inUbNGjA8uXLqVOnjlN5p06dGDp0KHPnzmXy5MlXuFrkj2NF8wiCu/+Zn2vW40hoFW7fs40vG7Vkw/nzZ3NMvK3gY3WfD08z/Rz4+2B4WTF/TcIxdjn8moTR5TqMx3tg1AzLu9Hg75NXPzMbLBYMP28wTUjNxLRaINcGIQEYXloSLCIifwwlltQvXLiQOXPmMGjQIEaOHEm7du2IiYmhd+/ezJkzh927dxMUFER0dDRDhgwhICAg/1ofH5/8hP5qatWqVWh5+/btCQ0NZe/eglMOfs/Zs2e55557OHfuHO+88w6VK1fOPzdr1izeeOMNxo0bR79+/a6pXZHyZ/Bc9J/zjxLrNgYTUrLhgU9tJOwxCfSBkW0tPNOpfJNf8/Bp+NtcWLsTwoMxR/fBHPM2FltWXoWt2zFmfghYwduKeXcnzBwvzPcSwcuCcUdLjB93wb4zgDVvglGAP7zyF4xH3Hu+pYiISEko9mo5u93OSy+9xJw5c4iLi2PUqFFYLHnN7ty5k5EjR9KqVSsee+wxWrduzdKlSxkxYgSOEt4rOyMjg7Nnz1KlSpVrui4wMJAXX3yRtLQ0JkyYkP9AgI0bN7Jo0SJ69OihhF4qJLOwAXgDRn5p56M9JiaQkQMTvnHwv1/Lee/6++fnJfQAp9LhiTex2LIwIP+Vv2NPrh1j0Vp452uw2SErB+ODdecTei/AyPu/zCzMfy3C3Hyg7N+PiIhIGStWUp+VlcXo0aOJj49nwoQJ3HfffU7n9+zZw3PPPceIESMYOHAgkyZNYvDgwWzatIlVq1YVp+sCFi5ciM1mo0+fPtd8bcuWLRk6dCgbNmxg8eLFJCcnM27cOGrWrMlTTz1VonGKlJkrzKr5dF/Bsk/2lV9Sb+bYYPUvl5UWtvLfeYGvge38P9kwMKHQ3fdN+HRr8YMUEZEy4+lPlC0tLif1aWlpDB06lI0bNzJt2jRiYmIK1Klfvz5RUVFOZRcS/zVr1rjadQFffPEFixcv5pZbbuHOO+90qY177rmHW2+9lVmzZvHYY4+RmprKCy+8QFBQUInFWVzJyclkZ2fnH2dkZJCenp5/nJOTU2CR8fHjx3/3OCkpyelxxerD8/q4XN3A3ELKLibRZf4+vK2YdSpdFlFhH02XbQmWX8dyPt2/wg+ThlXL5n2oD/WhPtRHBe9DKjaX96kPDAwkMzOT+fPn07p16wL1IiMjiYqKYurUqQXOdevWjbp16/Lmm28W2kfnzp1p0aJFoVtaXm79+vU88cQTNG3alNmzZxcrCU9JSaF///6kp6czZMgQ/vGPf7jclkh5azo/lz0pXBzgNvL++bOBBrEfmGSdH+huVhm+/asXlf3Lb8TDfHtD3px6x/lgW9aEnfsx8qfpmeQl+nmJvBkagMPuCxl5P1CMADtGZibgy4Xk3wSIbIyxfiyGr/b7ERGpKKZ2WlPkuiPXR5VaHBWNywtlo6OjSUhIYMGCBUydOhU/P7+SjKtINmzYwKhRo2jUqBEzZ84s9qj65s2b83/F/vrrryURokj5s1xM1i0OO7fX82bXgwYf/uqgkp/Bn68zCPAu31uYxt23YEY0gBU/Qr0qENsGjiZjPvMeJJ8FLwPDdECLOlCvKsbADljsJub7ieDjhTGwLcZP+zE/+xEOngHDgnFHaxjUDsPbLTb5EhGRItK0Gte4/G3Xq1cv2rZty/jx4xk+fDjTpk0rkNjv37+/wHWnTp0iPT2d2rVru9o1kJfQjxw5kgYNGjB79mxCQkKK1V5SUhLPP/88jRs3pkOHDixZsoQPP/yQ/v37F6tdkfLS5NQJXlryLitbXI+33Ya3zeTmo4cwnvgX9UIMHo10r+0ejea1oPklu1s1qAaLhl65PmAMvf1iQdfrMbpeX3oBioiIuLFiDWH17NkTq9XK008/zbBhw5g+fbrTVpUHDx5kzZo1TvPqFy1aBEDXrl1d7ve7777jiSeeoH79+syePZvQ0FCX24K8HXzGjh1LdnY2L730EvXq1ePnn3/mlVdeoXXr1jRs2LBY7YuUh1FfreCWnRv58y/rAbAbBobpA+bDFL6oVERERCqqYt+X7t69O15eXowZM4a4uDhmzJiRPw2mSZMmjBs3jtjYWOrVq0diYiKrV68mIiKCHj16OLXz7rvv5k99sdlsJCUlsWDBAgCaNWtGly5dANi+fTsjRozANE369u3Lhg0buNwdd9xxTe9h3rx5/PTTT4wdOzb/abTPP/88d999N0899RSLFi3Cx8fn2v7FiJSzG04cZE3jFkzoMZAjoZW5c/sPjPryf9S7plU0IiIiZcu0aPqNK0pksmlUVBRTpkxh1KhRxMXFMXPmTACaN2/O8OHDmT17Nh988AGBgYEMGjSIoUOH5u9lf8HixYudVnIfO3aMuXPnAhATE5Of1O/duzd/Nfe///3vQuO5lqQ+MTGRN954g+joaKepNrVq1WLs2LGMGTOG6dOnM2rUqCK3KeIO1jZqzt3tBpLrlfdnPvuWnqT7+rEIZfUiIiKe5pp3vymqyMhIYmJimDBhQmk0LyJX0WvSEVZaaziVedltnHvCBy9LsZ87JyIiUiomd11X5Lqj1nYpxUgqFm0LIeKhMnz88p7hdMnvdtPIe9qqiIiIeBaPTeqzsrLIyMi4ar3w8PAyiEak7PXfupHNTbpyzvviepDev/yExREBFo/90xcRkQpOW1q6xmO/2VetWsXEiROvWi8xMbEMohEpe342u1NCD3AyKARTY/UiIiIep9SS+vJOljt27MisWbPKNQaR8rS+4XUFyr6v3xhT8+lFREQ8jseO1IeHh2tqjfyh7atVC9KcyyqfzcA0Q0Fj9SIi4qY0/cY1GrIT8VARjXzxtuXmH1sdds4EBmHR/r8iIiIeR0m9iId6sr0Xho93/rHdYuWvLQ0sGgERERHxOErqRTxU/VCDLwdBK69D1LYkM64DLOhtLe+wREREpBR47Jx6EYF2NSEuaDUA93e8H2+rRulFRMS9aU69azRSLyIiIiJSwSmpFxERERGp4DT9RkRERETchqbfuEYj9SIiIiIiFZySehERERGRCk7Tb0RERETEbWj6jWs0Ui8iIiIiUsFppF7EgxmJe4ies5nAM1lYjoXA2D+Dt/7sRUREPI2+3UU81aGTGN1eoHa2D+CNOfETzKNnMOb/q7wjExERkRKmpF7EQ5mvfkZmdhUyCcHEghfZBL/+A76vOcCimXciIuKeNKfeNfpmF/FQ2d8e5yxhmOf/zG34kuGogukwyzkyERERKWlK6kU8VE6WT4GyXHxBIyAiIiIeR9NvRDyUYeYUKLNgK4dIREREis7U2JNLNFIv4qG8rRl4c+6SEpNgTqLPShEREc+jpF7EQ22u05jKHCSUIwSTRDj7OFw5GNCcehEREU+j6TciHupoSDUchom/mZZf9ltQKI0w9IcvIiLiYfTdLuKhuu/5AavpPCp/66FfMEwHukknIiLuSltauuaav9kTEhKIjIwkMTGxNOIRkRISlpVRoMzAxNCsehEREY/jFiP1mZmZLF68mB07drBr1y5OnDhBREQE8+bNK7T+qlWr2LBhAzt37mTfvn3Y7XY++ugjatWqVcaRi7gx01FIoYFyehEREc/jFvfgU1JSmDdvHtu3b6dp06ZYrdbfrf/ee+/x+eef4+vrS506dcooSpGKJcPbj7w/cQt5mbwVQ4tkRUTEzZmGUeSXXOQWI/Xh4eGsWLGC6tWrA9C5c+ffrf/ss88SHh6Ol5cXkyZN4uDBg2URpkiFsr3qdbTnF+DCj2Qb6d7+BGIp8q/57K/2c+61RDBN/B+OxPe2RqUUrYiIiBRHiSX1CxcuZM6cOQwaNIiRI0fSrl07YmJi6N27N3PmzGH37t0EBQURHR3NkCFDCAgIyL/Wx8cnP6Eviho1apRU2EydOpWlS5fywQcfUK9ePadzp06dok+fPtxxxx0888wzJdanSFk4FFKXGwglkFQAHFjYFXIDdTq/TtDO3fh652KJbo7lhf4Y9cOx7Usm4+kvyf0xCZ9b6+J9e0PS7l6evwNm1rJtBPmmYdapivWftxDw42bYehA6t8D2zz6kT9vEuS8PctbmTUbjetQZ05qqsfUBsO07Q+rTX5H742/43FIHW9frOLRgH7a0XGre05B6j1+PYSl8xGXdYZMXvndwLMOkfxODpzta+PEETNzg4Pj+c2RmOjjj7UVEiJ2F9wRQK8zKr7uz+F98CsnJNiJuDqB/bCW8vTWiIyIinqvYSb3dbmfy5MksX76cuLg47rvvvvxzO3fuZPXq1cTGxtKnTx8SExNZunQpe/fuZdasWVgs5T/7JzY2lqVLl/LRRx8RFxfndO7jjz/GbrcTGxtbPsGJFEPjE7/xdrPbmHRrR44HB9Nzz14mrP2akG8T8eX802aXfIdj436MnyaSfNsiHAdTADi34yTn3vzxsi3tDc5l+xO+dydnxqRgcAp/UjF3HCV50W/Ys/OW4AYB1tMZ/DwgmZu/7EXYrdU4efti7Afy2rbtOMW5hdtJIe/H+e4fk3HkmjQc06rAe/g12aTH+3ay7XnH206ZHE538N6vJkZ6LhhWMgL8APjsHES9ns36v3nz8qQkcnLygj9yJJX0DAcP3B9eov9+RUSkdDg0rcYlxcqqs7KyGD16NPHx8UyYMMEpoQfYs2cPzz33HCNGjGDgwIFMmjSJwYMHs2nTJlatWlWcrktMkyZNuPHGG/MT+Et99NFHNGzYkJtuuqmcohNx3cZa1Xk4pg97q1Qh09eXD1u04LGe0fhcSOgv2P0bOTPX5yf0Fxg5tgJtmuen8viTzjkqAZBDEPZs5w9gf3LwMXM4vmgP2WsO5if0l573vSSO42/sKfQ9LN1p5if0F7y90+RsLlQ/e44MX2/nt+LwIeHLjPyE/oL16zNwOLSeQEREPJfLSX1aWhpDhw5l48aNTJs2jZiYmAJ16tevT1RUlFPZhcR/zZo1rnZd4vr378+pU6f45ptv8ss2b97MoUOH6NevXzlG5iw5OZns7Oz844yMDNLT0/OPc3JyOH36tNM1x48f/93jpKQkzEv2MlcfntPH0utbYvp6g79P/uurRg0LHQGx+Re8aWdgL1BmJRfg/MaYF+IsbJedvDpWPyuGX+E3BB2XbMNj+FkKfR+FXepjudh+Yfx9CpZ7exvk5nr+f3P1oT7Uh/ooTh9SsRmmaV7T8FVCQgITJ04kMDCQzMxM5s+fT+vWrQvUi4yMJCoqiqlTpxY4161bN+rWrcubb75ZaB+dO3emRYsWV9zS8lKTJk3ivffeK9aWlllZWfTq1Ys2bdrwyiuvAPDMM8/w+eef88knn1CpUiWX2hUpT21ezWBz8mU7SdkdpL74JIFm5sWyW5tg+fpJTrebhy3xWH6xV9NKsPs37OdH572wE0AKvmSQTC2COYYvZzGB02GtyU25+FGSjj/H/GoQ+X0Mga0qcaL96+Ruuth2hiWAI46L02FavnErte5rUuA9HM8wabXIzulzF8ue7mDw+jaT02fsBOXkcjrQL//cLX7ZfHqvH08+dYS0tIs/NvrHhvGnAfo7FhGpCJ7pvanIdSd+2rYUI6lYXJ5THx0dTUJCAgsWLGDq1Kn4+fld/SI35efnR+/evfnggw84ffo0vr6+rF69mi5duiihlwqrRlY6EOZcaLWQdX8PjMSd+AY48OrTEmNYdwzDoPKqe8mc8X3eQtlb6hIQ145z8zaRM+MbOJeNT7ADi93K2WaRhAy9FZ+NP8LWgxidWlD5nm6cfW0zZ1fu52ymFXvr+rR59HqCbqwMQNVV95Dx6kZyfkzCt2MdQqOaYi7Ygy0thxr3NKJqTN1C30PNIION91h5dbODYxnQv6nB3S0sPHSjyfQfDPYdMUlNOksqFjrXNXj5TwH4eVuY+EwtPluZRvIZG20iAuh0a3Cp/rsWEZGSc6U7sfL7XE7qe/XqRdu2bRk/fjzDhw9n2rRpBRL7/fv3F7ju1KlTpKenU7t2bVe7LhUDBgzgvffe4+OPPyYoKIisrCy3mnojcq0iTybxSWCYU1lYdg7V5vUBa98C9S1h/gSNj3IqCxh2CwHDbnEq873wD3c0v3gtEDy+K8HjuxYaiyXUj5DxXZzKWrStWpS3QaMwg1dvc77jUDfE4JVuVvK26yw4oFC1qjd/+2uVIrUvIiLiCYq1ULZnz5688MILbNmyhWHDhpGZmel0/uDBgwXmzi9atAiArl0L//IvL02bNuX666/no48+Ij4+nho1atChQ4fyDkvEZa1OnGLAjo35x2HnzvL4d6uwa1cBERERj1PsLS27d++Ol5cXY8aMIS4ujhkzZhAUFATk7Swzbtw4YmNjqVevHomJiaxevZqIiAh69Ojh1M67776bv4DDZrORlJTEggULAGjWrBldulwc5du8eTObN28GYMeOHQAsW7Ysv99//vOfLr2X/v378/zzzwPw4IMPusWWmyKu6rT/R/68/lt+ql6PIyGV6XpgB14OE4vZn4sPpBIREXEvelKsa0rk4VNRUVFMmTKFUaNGERcXx8yZMwFo3rw5w4cPZ/bs2XzwwQcEBgYyaNAghg4dWiBhXrx4sdNK7mPHjjF37lwAYmJinJL6TZs2MX/+/ALXX+BqUt+zZ0+mTZvGuXPnuPPOO11qQ8RdVDmb99Cpm347xE2/HQLAjgXj2tbGi4iISAVwzUl937596du34HzcTp06sWHDhgLl7du3p3379ldtNyEhocgxPPzwwzz88MNFrl9UVqsVq9VKu3btqFmzZom3L1KW1te8nshf9hGck5Vf9mGztvwJQ0uQREREPEyJjNR7ik8//ZS0tDT69+9f3qGIFNvnza5jRI0beWrDR9RNO018szZM6XAHWRaLJt+IiIjb0vQb13hsUp+ZmVlg4e7lrFYrlSpVYt26dRw/fpx58+bRqFGjAg/MEqmIrBaTLTUbMPBPw/LLgnJysJoONKdeRETEs3hsUv/WW28VmHd/uZo1a5KQkMCUKVM4efIkLVq04Omnn8ZqVcIjFV/Nszm0P3OYh3/4gjrpZ0hochNrm7XDbmikXkRExNOUWlKfmJhYWk0XSZ8+fQp90u2lfH3zdty+lvn8IhWF6TBYtWQKwTl5j2ON3r+D5ccOYzH/BZpVLyIi4lE8dqS+Tp061KlTp7zDECk3Ean78xP6C3r9moiJUnoREXFfmlPvGm3ELuKhml8XUKDM2zCx6LNSRETE4yipF/FQlR/qhC3Qz6nMeDAK9FA1ERERj6NvdxFPVacK5ldPsTeyKkmNQ7C/dBfe0/9W3lGJiIj8LtMo+ksu8tg59SICtK7P6gevB+D+++/A6qV9b0RERDyRRupFRERERCo4JfUiIiIiIhWcpt+IiIiIiNtwaEtLl2ikXkRERESkglNSLyIiIiJSwWn6jYiIiIi4DT1R1jUaqRcRERERqeA0Ui/iwY6nm3x0phVnbAFU3mHnzzd6l3dIIiIiUgqU1It4qDPnTG79z1mOZN0AwIZ3cnn5lMno2/zLOTIREZEr0/Qb12j6jYiHevurMxzJcv7dPnnl2XKKRkREREqTknoRD3Xkm4MFytJNKw6bvRyiERERkdKkpF7EQ928Zw8+tlynskE7Nuq2poiIiAdSUi/ioWqdySH+/Ve55chu6qWe4v8SP2fKyhX6oxcREbfmMIwiv+QiLZQV8VC10s4QeiCdtQemYsFBDgH8EtScmuUdmIiIiJQ4DdqJeKgvr2tMqHEcL+xYMPHjLKer2XCYZnmHJiIiIiVMI/UiHqpxynG8TIdTWdeDv4DuVoqIiBsz9T3lEo3Ui3io1kcPFyizOkwsGqkXERHxONec1CckJBAZGUliYmJpxCMiJcSw+ZLuE+BUdiC0Iaah3/IiIiKexi2m32RmZrJ48WJ27NjBrl27OHHiBBEREcybN++K16xfv57XX3+dX3/9FR8fH9q2bcuwYcOoXbt2GUYu4r5+rtuERQ1uJ+LgZqqeTWVTnRYQUIPJ5R2YiIiIlDi3SOpTUlKYN28eVapUoXnz5pw+ffp363/55ZeMHj2apk2b8uijj5KRkcE777zDAw88wFtvvUXVqlXLKHIR97WrSlXeqNSYhY2a5Je1SD/LSyZYyzEuERGR32Nq8ZdL3CKpDw8PZ8WKFVSvXh2Azp07X7GuzWZjypQpVK9enQULFhAQkDe94JZbbuFvf/sb8+bNY+zYsWUSt4g7W1e9Jo5c5w/GXUEBgInteAbn/rcLS6gf/v2bYfH3Lp8gRUREpESUWFK/cOFC5syZw6BBgxg5ciTt2rUjJiaG3r17M2fOHHbv3k1QUBDR0dEMGTIkPxkH8PHxyU/or+aHH37g5MmTPPLII05tXHfddbRp04bPP/+c0aNH4+VVtLf2+OOP8/3337Ny5UqCgoKczv3yyy/8/e9/5+GHH+bBBx8sUnsi7uKXatXhqPPuNw7D4NzXRzjdaynk2AEwQnyo9EJXAu+/icxFW8n54Tg+9QMJPHMYw26He7tCZONix5OTa7Jy/Vn27M8mMCuXANNBg6b+tO8Wirf3xXn+q/faeXurnf0nbIScPEdtHxPfun6c8PNlXzokZ0HnugavdrdyNgfmbrRxOM1BTDMrfZtbWfazjVV77DQLt/BQW2/C/DXiIyIinq/YSb3dbmfy5MksX76cuLg47rvvvvxzO3fuZPXq1cTGxtKnTx8SExNZunQpe/fuZdasWVgs175gb/v27QC0atWqwLkbbriBTZs2cfDgQRo3LloS0r9/f9atW8fKlSv505/+5HQuPj4ei8XCnXfeec1xipQ7Xys+jlxyLBcn21i8DM7ctTw/oQcw03I4838rSX95A46j6QBkAlmkEs5BmP05fPoURN9YrHAmzjzFlu3Z1Mg4R5DNBsDGNan88kMGD4+pC8Drm2088L/c81cY+Nr9iDqQgv/OcyTWCOFIaN4P+V1nTFbtz8U4Z+dASt5uPvMT7XSuZ/D1/ovv7a0tNn4Y6o+PlxJ7EZGKQk+KdU2xtsHIyspi9OjRxMfHM2HCBKeEHmDPnj0899xzjBgxgoEDBzJp0iQGDx7Mpk2bWLVqlUt9njx5EoBq1aoVOHeh7EKdorjllluoXr068fHxTuVZWVmsXLmSDh06FPkugog76X5wBzvfmMizGxJ4aOt6Vnw4m5lrl+E4ea7Q+hcS+guyCCUXX7A7YHJ8odcU1e6DOWzZno233Z6f0F/wy+YMjh3MAuCldc7nsq0WDgb6AtAsOdPp3MFkR35Cf8HXh5zvTGz7zUHCTjsiIiKezuWkPi0tjaFDh7Jx40amTZtGTExMgTr169cnKirKqexC4r9mzRqX+s3Kyvvy9/YuOAfYx8fHqU5RWK1W7rzzTrZv386ePXvyy7/44gvOnj1Lv379XIqzNCQnJ5OdnZ1/nJGRQXr6xUQsJyenwCLj48eP/+5xUlIS5iX7lqsPz+lj2LeraJh2mnHff8Zrq9/hjgO/8NCmtVhxTpx/j+P8klrbqbRivY/jSakAWK+wR35aajanT58mJavg+dzzd/S8Hc4JO4U1VUjZhTbL+7+H+lAf6kN9uHsfUrEZpnltT6JJSEhg4sSJBAYGkpmZyfz582ndunWBepGRkURFRTF16tQC57p160bdunV58803C+2jc+fOtGjRotAtLSdPnsyyZct47733aNiwodO59957j0mTJjFz5kw6dOhQ5PeUlJREv379GDRoECNGjADgoYce4sCBA3zyySdFnp8v4k5S2o4nLHGPU5mJyanG7cjam4Hj/G96A7BggrcFci8mzlayqcGuvD0I/n0vDC/4w72ocm0m/xiTxOkzNuqnn8XbcfFjp3JVb8b9pzFWq8GwFTn85/tLRtZNk64nUqmUa2N3pQB+qRaSf8oHE87ZLp1JRPVA+C3t4nsI9IF9IwOoFqS9+UVEKopH/7y9yHVffb9lKUZSsbj8TRcdHY3FYmHBggXXNDJeXBe2qzxx4kSBcxfKrnVLyxo1atCxY0c++eQTcnNzOXToEJs3b6ZPnz5K6KXC2htW8O/AgUHoyvsIjm2Cb5gFr8o+eFXxw//PLQhf+Rf87miCpXogfjeGUbXhWYyG1eD5wfDoHcWKxdvL4IXh4US28iejeiA+VXwIDLFyfZsg/jW2LlZr3vzJyT28efwWL6oHQrDh4MbUDEJwcKZ6AEdrBOJryfvQqhMEX93jRcJffWlfx0LNYIOHIr3Y8KAff7vZixrBBp0bWFh5v78SehER+UNwOWPt1asXbdu2Zfz48QwfPpxp06bh5+fnVGf//v0Frjt16hTp6ekuPySqZcu8X2Q///wz7du3dzq3bds2AgMDqV+//jW3279/f9avX8+aNWvYtWsXgFtNvRG5Vmf8gwuUWQFrg1B8PvxLodf4dWtYaHlJqFfLm2cfDf/dOn7eBq/08uaVXhem1wVetd0eTZx33X9zoN8VaoqIiHiuYg1h9ezZkxdeeIEtW7YwbNgwMjMvW8h28GCBufOLFi0CoGvXri712aZNG8LDw/nf//7n1N+vv/7KDz/8QPfu3V0aXe/UqRNVq1blgw8+4OOPP+amm26iQYMGLsUo4g78z1nIm1xz8ZWF/zXMqBcREZGKothzSy4k0WPGjCEuLo4ZM2bk7/fepEkTxo0bR2xsLPXq1SMxMZHVq1cTERFBjx49nNp599138xdw2Gw2kpKSWLBgAQDNmjWjS5cueQF7eTFy5EjGjBnDP//5T/r378/Zs2d5++23qVSpEg8//LBL7+PCgtmFCxcCMHToUJfaEXEXNVNtZBBGIKcxMLHhQyrVqXpNq2hERETKlqktLV1SIhPGo6KimDJlCqNGjSIuLo6ZM2cC0Lx5c4YPH87s2bP54IMPCAwMZNCgQQwdOrTAHvWLFy92Wsl97Ngx5s6dC0BMTEx+Ug95PyR8fX1ZuHAh06dPx8fHh7Zt2zJs2LBCt7osqtjYWN544w38/f3p3r27y+2IuINK51LxIh2DHACs2LCSg1HotjEiIiJSkV1zUt+3b1/69u1boLxTp05s2LChQHn79u0LzH0vTEJCwjXF0blzZzp37nxN11yNt7c3hmHQo0cP/P39S7RtkbLmZ6bgRwZ5M+kNDBxU4hBoBERERMTjaGuXS7z//vvY7XYGDBhQ3qGIFJuPcQ7wxszblBIDC1bsFL7Bu4iIiHtwaOzJJR6b1GdkZFx1q01vb29CQ0NZuXIlSUlJvPXWW3Ts2JEWLVqUUZQipcdimNjxxY4vYMHAhpWzWJTTi4iIeByPTeqnTp3Kxx9//Lt1IiIimDdvHmPHjsXX15fWrVszbty4MopQpHQ58MLOxWlkJl7YCch70JSIiIh4lFJL6hMTE0ur6SK599576d279+/WCQnJezpleccqUhr2V6pOPZKdyhx4YxoWdGdTRETclXa/cY3HjtQ3atSIRo0alXcYIuVmW/Xa1GOHU1mKvz/hhoH1CteIiIhIxaTnp4t4qMYZv2E4PWrKxN+WjtXU9BsRERFP47Ej9SJ/dNfX8cYgHRNvTCxYyMXLpoReRETEE2mkXsRDWR6PAYuBhVysZGPgwNI3Aqz6sxcREfflwCjySy7St7uIp2peG/vyxzlVJ4isQG8c/4iCt/6vvKMSERGRUqDpNyIezOwTwQcnOgBw//33Y/H2LueIREREpDQoqRcRERERt6EtLV2j6TciIiIiIhWcknoRERERkQpOSb2IiIiISAWnOfUiIiIi4jYcmlLvEo3Ui4iIiIhUcBqpF/Fw9rPeOM55Ybc50I6WIiIinkkj9SIeyjRNPp9xgDMfNyN1dWNeu3crx3dllHdYIiIiv8thGEV+yUVK6kU81N6NZ/jpk5Nw/jHaZ5NziZ+0p3yDEhERkVKhpF7EQ23+8kyBsuSDmTjsZjlEIyIiIqVJc+pFPNQ2mzd+l5WdCvC9MHAvIiLilvREWddopF7EQ53xtXM4NDj/ONdiYVXTumicXkRExPNopF7EQ7U4dZK1IdU56++Pt93OWR9fGqecxWqGo+F6ERERz6KkXsRDGfgDkO3tTfb5vSx9HXm7BegWnYiIiGfRd7uIhwrMKbh9ZZ0zxzX9RkRE3JrDKPpLLlJSL+KhmpzcTfddGzBMB5gmYZmpDPnmHaymo7xDExERkRKmpF7EQ+2uXI00vyAsgBWTXC9vttRsiN3Qn72IiIinueZv94SEBCIjI0lMTCyNeESkhOT4hPJDvRvyj7O8/VhxQ3eN1IuIiFszMYr8kovcYqFsZmYmixcvZseOHezatYsTJ04QERHBvHnzinT9mDFjWLVqFY0aNWLZsmWlHK1IxRCWnVugLNsnEIdh0S06ERERD+MW3+0pKSnMmzeP7du307RpU6xWa5Gv/frrr1m9ejW+vr6lGKFIxVM9/XSBsjpnkrBcOlK/7hdY9BUcLVi3yDbtgf9+CXuTnMuTzsCbX8FXP4Op5bkiIiKlyS1G6sPDw1mxYgXVq1cHoHPnzkW6LjMzk5dffpmBAweybt260gxRxEm2zWTFPpOzuSZWAzAMYhoZhPi6z63AVN/KhJ7JItXfFwwDL7udoGw7DixYzqTD7RNhy/68ylYL3BkJHZpBz9bwy2EI8IU7IsAnbztMHA74ZDOs/BHqhkOIP3y0CT7dfLHT/h3gsT6QkAjTEsB+/gdEy7rw9nC4qUHhwR4+BV/8BA2rQ9QNhdcREZE/BIeeKOuSEkvqFy5cyJw5cxg0aBAjR46kXbt2xMTE0Lt3b+bMmcPu3bsJCgoiOjqaIUOGEBAQkH+tj49PfkJ/LWbPno3D4eBf//qXy0n9kiVLmDZtGjNnzqRDhw5O53JycujduzdNmzZl7ty5LrUvnue3syadl9rZfebSUpNwf/hqkJUbqrrHh9Gx0BpUOXqWsHNZ2C0G3nYHOV4B8PMB6DwWMrLhwgaXdjt8+H3ea/RbFxtpXhu+fgGC/KDreNi4+/yJwkbeDfjwu7zX5bYfhtaPw/N3w9g/O597bwPcPQ1s9rzjmEiIfxIsbnEjUUREpEIo9rem3W7npZdeYs6cOcTFxTFq1Cgs57+Md+7cyciRI2nVqhWPPfYYrVu3ZunSpYwYMQKHo3iL9bZt28ayZct4/PHHCQoKcrmdPn364OPjw0cffVTg3FdffUVqaiqxsbHFiFQ8zbQfHJcl9HlOnYPxG9xnEerRAD8ArKaJj92BAST7eGOMewcysorWyM6j8J9P4O2vL0noweUn0k5cBr+lXDx2OGD46xcTeoCPE/PuCIiIiEiRFSupz8rKYvTo0cTHxzNhwgTuu+8+p/N79uzhueeeY8SIEQwcOJBJkyYxePBgNm3axKpVq1zu12az8fzzz9OhQweio6OL8xYICwujW7durFmzhtTUVKdz8fHxhISE0K1bt2L1UVKSk5PJzs7OP87IyCA9PT3/OCcnh9OnnedGHz9+/HePk5KSMC+Z76w+rt7Hjt+Zfv7LyYvJaXm/jxRfH9L8fPLH1HMtFlIC/LBvO3jlN1AI+y+HOLd5z1VqFTHJz7XB3qSL7yP9HBxNLlhvxxG3+m+uPtSH+lAff4Q+pGIzTPPaVrAlJCQwceJEJk+ezJIlS9i9ezeTJk2iY8eOTvUiIyOpX78+y5cvdyo/deoUvXr1Ijo6mpdeeqnQPjp37kyLFi2uuPvNG2+8wYIFC3j33XepU6cOAH379sXf39+l3W8SExN55JFHGDlyJIMHDwbg2LFj9OvXj4EDBzJq1KhrblM814zNDh79svAR+SGtDWZ1L/pC79I048mf2XLEH8NhYjFN7Na83/ALA7/AMu/zojc052FoUA16P3/Zics/OoxCyi5TKQiOzgf/Sxa2txkJm/c51/thCkQ0LnqMIiLiMf567/4i1138ZsNSjKRicXmkfuLEiWzdupUZM2YUSOgvaNiw4L/o8PBwgoODOXr0qEv9Hj58mAULFvCPf/wjP6EvrsjISOrVq+c0BSchIQHTNDX1Rgr4100G97Y08hbIXqJnA4MXOrnPPPDuuzcCYFqM/IS+RspvWJ4fDN1vdK586aIk3/MLY60WeOB2eLA79LoZRvfPK8trNe//eVkLlnlf4UdNiD8sfdw5oQd4cxi0OP+3HOQHU/+uhF5EROQaubxQNjo6moSEBBYsWMDUqVPx8/MrybiuaNq0aflTYg4fPpxfbrfbsdlsHD58GH9/f8LDw6+p3f79+/Pqq6+yY8cOrrvuOhISEmjZsiXNmjUr6bcgFZy31WDRHVb+3c0kxw4+VsixQ80g91gge4FpelMtOYWTYSGYFgt+2TnUOpUKlYNh1QQ4lgzZuXlJeOVgOHgiL6FvWB2On8n75yrBFxt8+a/w1ADY9xvUCIMcG4QF5l2/NymvvtUCdarAwZMwbGHeTjkWA/pGwpLHIKCQz4nr68H2GXDgBFQNgcCy+SwRERHxJC4n9b169aJt27aMHz+e4cOHM23atAKJ/f79BW+fnDp1ivT0dGrXru1Sv0lJSZw8eZJBgwYVer5///506tSJ6dOnX1O7ffv2Zfbs2cTHx9O1a1eSkpIKrBEQuVQVf/dK4i+3K7wxgftzsaamY7dY8M3N5axvUN6WlgC1Kjtf0KLuxX++/NwFIQHQupBbnTfUdz5uWgs+HQcnUsBqdf5xcCUNql29joiIeDyHe3+9uq1ibWnZs2dPrFYrTz/9NMOGDWP69OlOW1UePHiQNWvWEBUVlV+2aNEiALp27epSn48++qjTQo8LJk2ahI+PD8OHD7/mUXrIWzAbFRXFZ599xm+//Yafnx+9evVyKUYRd3AypDLpATmY56fWnLVacFgMlzeucUm1sDLsTERE5I+r2PvUd+/eHS8vL8aMGUNcXBwzZszI32KySZMmjBs3jtjYWOrVq0diYiKrV68mIiKCHj16OLXz7rvv5ifrNpuNpKQkFixYAECzZs3o0qULAO3bty80jldffRV/f3+6d+/u8nvp378/q1at4uuvvyYmJqZYW2WKlDe7xYoBWM6vhTeBbG+fq65lFRERkYqnRB4+FRUVxZQpUxg1ahRxcXHMnDkTgObNmzN8+HBmz57NBx98QGBgIIMGDWLo0KH5e9lfsHjxYqftmY4dO5b/wKeYmJj8pL40tW3blrp163L48GH69etX6v2JlCqr4TQor7uZIiIinuuak/q+ffvSt2/fAuWdOnViw4YNBcrbt29/xdH1SyUkJFxrKCV6PYBhGHh7e1O/fn1uvvnmYrcnUp4sjoJD8oaG6UVExM05NAzlEvfZf88NbNq0iX379tG/f//yDkWk2MIzCj5UxCgk0RcREZGKr0Sm37ijrKwsMjIyrlovPDycTZs2ceTIEf773/9SqVIl7U0vHiEwJxMcftisVrxMkxyLQWBuLhYcgHs8IEtERERKhscm9atWrWLixIlXrZeYmMj8+fP56aefaNiwIRMmTNACWfEIBytV5/U69Tkd4IfVYWKzWui+59jFLS1FRETckGlo+o0rSi2pT0xMLK2mi6Rjx47MmjWrSHXnzZtXytGIlL3NtWpwyuYPgO38428Ta4VpxayIiIgH8tiR+vDwcJf2qxfxFJVzksES5lSW5uenpbIiIiIeSHfhRTzUX3IOYjgcTmV9d2zBaiqtFxER9+Uwiv6Si5TUi3iom+5sxqJlr1E/+SRedhsDft7IgrObwKo/exEREU/jsdNvRP7wbqzPXx69kX6PjyEwJQujX1ssrz1U3lGJiIhIKVBSL+LBzMG3sPTcLgDuv/9+LN7e5RyRiIiIlAYl9SIiIiLiNhza0tIlmlwrIiIiIlLBKakXEREREangNP1GRERERNyGQ09JdIlG6kVEREREKjgl9SIiIiIiFZym34h4uEpHzxJ0JhsysqCStrQUERHxRErqRTyVw4Fl4Ez+FL8FMOD14fDpSOjcvLwjExERuSK7ptS7RNNvRDyU+c63EL8VEy9MrJhnHTgGzSrvsERERKQUKKkX8VDm/LVw2Q4CZlIG2B3lE5CIiIiUGk2/EfFQjsMpBTYFMzEwHQ4Mq37Pi4iIe9ITZV2jb3YRD2U3DcAkB1+yCMCBBRMD9GEpIiLicTRSL+KhcqzeZFCNHALOlzgI5QRemOUal4iIiJQ8JfUiHuqMd2W8Sb+kxEI6VfDDomf1iYiI23LoS8olmn4j4qkcBX+zO/AGjdSLiIh4HI3Ui3go02onxdefnZWqk+bvT8Mzp2machxMJfUiIiKeRkm9iIf65Lrm7KgexqYm9cj18qJaajr3fruBgVZreYcmIiIiJaxUp98kJCQQGRlJYmJiaXYjIoX4pWp9NjRvRK5X3m/3E6HBvN22PaZDI/UiIuK+HBhFfslFFXKkPicnh9dff51PPvmEkydPUq1aNfr27ct9992Hl1eFfEsiJc7h7QOXPWfqWJWwy59HJSIiIh6gQmbAY8aMYe3atdx5553ceOONbN26lblz53LkyBEmTJhQ3uGJuIWqWengE+xUFpSVrdXxIiIiHqjCJfXr169n7dq13HPPPQwfPhyA2NhYgoODWbJkCf379+emm24q5yhFyt+gHzeQWvlGaianU+VsKj/VakDU0R8xHA+Cmz1RNjfXJOlELoGhXvx2DppVMbBaDDJTczmXYaNKbX9OJtsBk6qV8z620s/k8tl/j7H512xq1vLhrnurU72+PwAHU02sFpOMHIMagRDm53x7wm4zOXU8m0pVvfHx0xoDERF3YtdDEl1SLkn9woULmTNnDoMGDWLkyJG0a9eOmJgYevfuzZw5c9i9ezdBQUFER0czZMgQAgIC8q9duXIlAH/5y1+c2vzLX/7CkiVL+PTTT4uc1CcnJ3PHHXfQvXt3nn/++QLnJ02axPvvv098fDy1atUqxjsWKXtedjv3Ja6iVcoOrKaDM/tC2B3SDCzuldBv3JzJ3DdOk57hIMdi8EPlYCw1/JiYe5xja0+S64CD9atx3PQBoG0rX556qDJzXzzAf3yrcrhxEIZp8sZraSSM9Oa+LwxWHzIBExzga8C4WyyMvTUved+zNZ2l/z5E+hkbvgEWYu6vRbseVcrx34CIiEjxlWlSb7fbmTx5MsuXLycuLo777rsv/9zOnTtZvXo1sbGx9OnTh8TERJYuXcrevXuZNWsWlvOJyC+//EK1atWoUaOGU9s1atSgatWqbN++vcjxVK5cmS5duvDVV1+Rnp5OcPDFqQrZ2dl89tlntGvXTgm9VEjHgkPodmZt/nGlnDTqZRzEbrrPLbpz5xzMnH+Kc1l5i3d9HCZtT6exJ/McR3afAOBoaEh+Qg+w6eds3liWwtv2UA6HBQFgGgY/Vg5lwPs2NqVdeHcGWCDbbvL0OgfRDQ3aVDPyE3qA7EwHH845QrObgwmrerEPERGRiqbMhuyysrIYPXo08fHxTJgwwSmhB9izZw/PPfccI0aMYODAgUyaNInBgwezadMmVq1alV/v1KlTVK1atdA+qlatyokTJ64prgEDBuQn8Jf68ssvSU9PJzY29praE3EXwbmpBcpqZJ3Eevnq2XK072BOfkJ/gZcJDdLP5R+n+vkWuG7XoVwOhQUWKN+ZWchUmvN3cdceMjl5LDs/ob/A4YADO866EL2IiJQGh1H0l1xUJkl9WloaQ4cOZePGjUybNo2YmJgCderXr09UVJRT2YXEf82aNfllWVlZ+PgUPqLm6+tLVlbWNcXWvn17ateuTXx8vFN5fHw8oaGhBWIqT8nJyWRnZ+cfZ2RkkJ6enn+ck5PD6dOnna45fvz47x4nJSVhXvIwIvXhOX342XK43DmLH8d+O+k276NWDS8u3zbfAZz0v/g3HpCTW+B9NKrvQ0PfguX1QgrZrvN8UbMwOw5LOj5+BT/2qtfzK9b7uKC8/5urD/WhPtRHcfqQis0wzdJ7vGRCQgITJ04kMDCQzMxM5s+fT+vWrQvUi4yMJCoqiqlTpxY4161bN+rWrcubb74JQJcuXWjYsCGLFi0qUPfee+/lxIkTBUbdr+b1119n9uzZLFmyhOuuu44jR47Qv39/Bg8ezIgRI66pLRF3cbrFeEJ27cbbzEvuHRiY+GPkvIHF210m4MAHH6ey9IOU/Afdbg8JYG9oAM8m7Sf7QAbZVivbalYjy5oXc7UqVqY+Ec5vNgtRb9tItucl6TdUhjfusNDvfw6OZZxv3DTBBgOuM3ivvxWLYfDdZ6f532tHMM/fsLilTxX6PVSnjN+1iIhcye0PHyty3dWvaYr0BWXyzR4dHU1CQgILFixg6tSp+Pn5udxWeHg4J0+eLPTchT3rr9Wdd97Ja6+9Rnx8PKNGjeKjjz7CNE1NvZEKLcXPlzAzADs+GDgwz/+5Wyzudb9yQEwoHSID2Ls/m0x/b05ZrHStb6V2yPUc+DGNzDQb9W4K4ZeDNkwT2lzvh4+3QTXg0FBvPjtgEugN3esbeFkM9jxg8NkBk7O54LCbNK1k0LHOxdH5Dr2q0OzmYA7uOEv1en7UauRffm9eRESkhJRJUt+rVy/atm3L+PHjGT58ONOmTSuQ2O/fv7/AdadOnSI9PZ3atWvnl11//fV8+umnJCUlOS2WTUpK4uTJk3Tp0uWa4wsPD6dLly589tln/N///R8ff/wxN9xwA40bN77mtkTcxabwhjRgN+B1fgaKyQl/H6o5KDDlpbzVquFNrRreBcob3hya/88dwgqeD/Qx+FMz5x8p/t4G/Zv+/g+XytV9qFxdC2NFRNyRXU9JdEmZLZTt2bMnL7zwAlu2bGHYsGFkZmY6nT948KDT3Hkgf4pN165dndoBeOedd5zqXjju3bu3S/HFxsaSlpbGiy++yIkTJzRKLxVewxQ7axvdAJzDIItUPwvrGnVyu5F6ERERKb4ynVjbvXt3vLy8GDNmDHFxccyYMYOgoLwt6Zo0acK4ceOIjY2lXr16JCYmsnr1aiIiIujRo0d+G506daJz584sWbKEjIwMWrVqxc8//0x8fDy9e/cudM5+UXTs2JGaNWvy6aefEhAQ4NSnSEX0W3hlmh7+BSt5u70E55icCQ3E4TDdbqReREREiqfMn0ITFRXFlClT2LlzJ3FxcWRk5K1oa968OVOnTmXr1q1Mnz6dLVu2MGjQIKZNm5a/R/0FL7/8Mv/4xz/YuHEjkyZNIjExkUceeYRnnnnG5bgsFgv9+vUD8n58XPrAK5GKqF7aQVr8ti//2Nth488/fYYe1CciIu7MbhT9JReV6kh937596du3b4HyTp06sWHDhgLl7du3p3379ldt19fXlyFDhjBkyJASifMCb++8ObuaeiOeoPmJfQXKws+eodS2uxIREZFy417Piy9HNpuNDz74gCZNmnDjjTeWdzgixeZdyD71JkDp7WIrIiIi5cR9NqsuYadOnbpqnaCgIE6fPs3PP//M2rVrOXr0KC+88EIZRCdS+q40zcbQQlkRERGP47FJfa9eva5a58Ic/IkTJxIWFsaDDz6Yv7uOSEVnNy0YGJj4YGJgYAeywWFiaKGsiIi4KYcWf7nELZL6xMTEEm9z1qxZV63TuHFjwsPDC533L1LR2Q1fLPhzYZbdhYdPGfqwFBER8ThukdSXhqIsuBXxZCY+XL5sxsQXE/RYDxEREQ+jhbIiHsoeHlqgzMTQQlkREXFrdsMo8ksuUlIv4qnu6oDjsjH5cwGVsXh77A06ERGRPywl9SIeKmBIe840bUUmgWTjSyqVsc76a3mHJSIiIqVAQ3YiHsri701Y4kN8/ugC/M7YuWXcIALa1C7vsERERH6XrbwDqKCU1It4MMPfm2Md/QDoemO1co5GRERESoum34iIiIiIVHBK6kVEREREKjhNvxERERERt6GtKl2jkXoRERERkQpOSb2IiIiISAWn6TciHs40AYduZYqISMVg01eWSzRSL+LBtn5ygtTlTTmzrDnvj95Bxumc8g5JRERESoFG6kU81LEdaayd+iutkg4QlJ3J/pRafHw2l8GvtSnv0ERERKSEKakX8VC/ztvJoB++ICTrLDarFxGHf+WrszfjsEdgserepoiIuCcb+o5yhZJ6EQ9V89tt7Ktam2+a3EiWjy91kn/j9u2bMDBBH5giIiIeRXPqRTyU3eFgdcu2ZPn4AnCkcnW+ah6J6XCUc2QiIiJS0pTUi3io/VVqFyg7VKU6pqE/exEREU+j6TciHirwXA74X1aWlY1FM29ERMSN5ep7yiUashPxUE2PHyQ8JS3/2HCYRO7arek3IiIiHkgj9SIeys/MJub779hbrTaZfr7UPXmSmpknMTQCIiIi4nGU1It4qKMBlalh7ufG3/bgwIIVO1n4gebUi4iIG8vV6JNLSvXbPSEhgcjISBITE0uzGxEpxOKINqQRQg4+OLBwlkDW122EwyzvyERERKSkVbiR+p9//pm33nqLX3/9leTkZABq1KhB9+7dufvuuwkKCirnCEXcw7dN6vCwVzaZtgDAwItcDtXww9QAiIiIiMepcEn9wYMHycrKonfv3oSHh2OaJr/88guvv/46q1evZtGiRfj5+ZV3mCLl7oHE76hpO4EDAxMDCw4e+uEE0L+8QxMREZESVuGS+piYGGJiYpzK/vznP9OwYUNmzJjB119/TXR0dDlFJ+I+bvt1L2BiJW++jQn4OHKxmAXn3zgyc0mZuYWs747jG1GdsGE3Yw3xLduARUREgNzyDqCCKpekfuHChcyZM4dBgwYxcuRI2rVrR0xMDL1792bOnDns3r2boKAgoqOjGTJkCAEBAVdts2bNmgCkpaVdpaazv/zlL6SlpZGQkIDF4rzE4IsvvuDJJ59kwoQJBX5IiAdKTodHX4ePNoLDzMuCu14PMx6AxjWK3s6+JBi2EL7ZCTfWh1fug8gmpRX1FQVnn+NQaHV+qHkdZ338qZeaRPvD2wkoZAHSsT7vY1uzDxteZH64i9TpG2l4fCiGtzW/jukwOfnc9yTP/wXDy6BK3E2Ej2xTavHvS3bw6Ce5rD3kwNvPSq5h0Lqawb9vs3DolJ1nVmZxJNXEL9BKpr8Pfzt4gPab92GxOWg2oB5tHm2Jxaq5RiIi8sdQpkm93W5n8uTJLF++nLi4OO677778czt37mT16tXExsbSp08fEhMTWbp0KXv37mXWrFkFEu6srKz8144dO/jPf/6Dt7c37du3v6aYYmNjmTJlCt9//z0dO3Z0OhcfH09QUBDdu3d3+T1LBXL/TPhok3PZJz/Avt9g+6sUaS9I04S+L8H2w3nH67ZDr+fg4GsQWLbTwjL9/Pii0U35T5DdXaUedsNKb9Pk0neSveM0jjV7yOVifPbT2fx27yfUeKdvftnpGT9yYsL3+cdJT6zHWi2ASve2KPHYTdPkzrdz+OWECf7W/CeRfH3EpPuSXDJOZGG/sN3+ORttTiZx07fbyDpf9OPcX/EO9KL1w9eVeGwiIiLuqMz2tsvKymL06NHEx8czYcIEp4QeYM+ePTz33HOMGDGCgQMHMmnSJAYPHsymTZtYtWpVgfbmzp1L9+7diYmJ4YknnsDPz49p06ZRp06da4rrjjvuwNfXl/j4eKfypKQkvv/+e3r16qU5+n8Emdnw8Q+Fn9t5FLYeLFo72w5dTOgvOJ0Oq7cWLz4X7AurlZ/QX7C/Uk0un31j35eMAyuXy1y53+k4ddnuAnXSlv1a/EAL8csJMy+hN+DyR+CmptkuJvTnRR44XqCNfZ8cLZXYRESkdGUaRpFfclGZJPVpaWkMHTqUjRs3Mm3atEKnstSvX5+oqCinsguJ/5o1awrUHzBgALNmzeLll1/mnnvuwcfHh5SUlGuOLTg4mOjoaNauXet0fUJCAg6Hg379+l1zm6UlOTmZ7Ozs/OOMjAzS09Pzj3Nycjh9+rTTNcePH//d46SkJMxLsrw/bB8+XjiCrzCH3DCgSnCR+sjwASyF/FmFh5TN+7ikTe/LM1/A15bLiRO/OfWR2TwAg4Lz7K3VApz68KpS8MettYp/qbyPyv4GFuP89Zf/CinkQzzD16dAmVeItfz/d6U+1If6UB8VqA+p2AzTLGTVXAlJSEhg4sSJBAYGkpmZyfz582ndunWBepGRkURFRTF16tQC57p160bdunV58803f7evb7/9lv/7v//j+eefp1evXtcU508//cQDDzzA448/zt13341pmvTr14+goCDefvvta2pLKrDJH8LotwqW3387vD606O38cxYsXH3x+LZWsHpi8eO7Rsevm85n3g3I8PXPL2tz+Fc6HBuCxct5ZD558Pskv7uPSyfm1PxfLEH9muYfn11/lAO3f4iZYwfAEuhNw28G4n9T1VKJ/8H4HBb8YAcfC3hf/KHUuTYcPniOA2cufnTVMHMY89l3+Ofa8mLzNug1/xZq31KtVGITEZHSE/Zo0X9spLxapRQjqVjKZE59dHQ0CQkJLFiwgKlTp5bKdJaOHTtSpUoV3n///WtO6m+66SYaN25MfHw8d999Nxs3buTYsWOMGjWqxOMUNzaqf97C1o82wck0CA3MS8gH33pt7cz7F9x+I6zfATc1gHujSiPaq8rx8qHHzi3sDa/BOW9faqeepnr6GQoZlKfSO3/C57bNpC3YihHsS9jEzvh3qutUJ7BTbRpv/gspb+7A8LIQdn9LfJuElVr8r/X15vZGFtYdcJBrgNXLIKKGhXtvMMjIDmLh97kcSnEQEGQl0xJEWEwUzX88hJnjoEm/elRpHlpqsYmISOk5p1k1LimTpL5Xr160bduW8ePHM3z4cKZNm1Ygsd+/f3+B606dOkV6ejq1a9cuUj/Z2dnXvPvNBf3792fq1Kls27aN+Ph4fH196d27t0ttSQXWKyLvVRwWC/ylc96rHB0LqkxT+1H8bJmcCbRSKTMdB1ZMa8HpQYZhEPRQG4Ie+v3dbPyur0KNSZ1KK2QnFovB4FZeDG5VSBxeBqNvu3y6VDB0u75MYhMREXE3ZbZQtmfPnrzwwgts2bKFYcOGkZmZ6XT+4MGDBebOL1q0CICuXbvml506darQ9j/++GMyMjK44YYbXIrvwoLZt956izVr1nDbbbcRHBzsUlsi7sCRY/DowDtp/+SjxP7rH9w89nG+r1cHw1Fwrr2IiIhUbGW6pWX37t3x8vJizJgxxMXFMWPGDIKCggBo0qQJ48aNIzY2lnr16pGYmMjq1auJiIigR48e+W08+uijhIaGcuONN1KjRg0yMjL48ccfWbt2LdWrV+ehhx5yKbaQkBBuu+02Pv30UwC3WiAr4ord9cN4u93FkfeTwUGM69+LmFJbRSMiIiLlpcxG6i+IiopiypQp7Ny5k7i4ODIyMgBo3rw5U6dOZevWrUyfPp0tW7YwaNAgpk2b5rRHff/+eY+4/9///sfLL7/M3LlzOXLkCH//+99ZsmQJNWpcw0OCLjNgwAAA6tatS5s2pfdQHZGysK1ewQWsW+vULnT6jYiIiLvIwSjySy4q1ZH6vn370rdv3wLlnTp1YsOGDQXK27dvf9WHR/35z3/mz3/+c4nFeClvb28A7rzzTgztfSoVXHh6aoGyG48eAXtdsBTcl15EREQqLg3ZXWLZsmV4eXkV+kNEpKKplprC3zZ+l39cNT2du7//7vJnOYmIiIgHKNM59WUpNTWV3Nzc363j5+eH1Wpl3bp17Nu3j08//ZT+/fsTHh5eRlGKlJ6Io8f4tlIgK6fNxO7w5kywhR3VqhT68CYRERG3oa8pl3hsUv/EE0+wefPm360TExPDQw89xNixYwkICOD2229n2LBhZRShSOnaUakRd6/ZTbatMgZQ6ZTJXXv24jBNNPlGRETEs7hFUp+YmFjibQ4fPvyqe9ZXrVqVWrVqlUr/IuXtREAYlWwXt2U1TIPD3jVpoSEQERERj+MWSX1paNGiRXmHIFKuWh87wbnLygy7RXPqRUREPJAWyop4qIbX+RQoCyCrHCIRERG5BoZR9JfkU1Iv4qFqjW5DNVLAzHvalI+ZS5PoYAztUy8iIuJx9O0u4qG8WlbjuqXdqF/tCI29D3PzPSHUWNq/vMMSERGRUuCxc+pFBHz6Nefr5G8BuP/+WCznH7AmIiIinkUj9SIiIiIiFZySehERERGRCk7Tb0RERETEfWhXG5dopF5EREREpIJTUi8iIiIiUsEpqRcRERERqeA0p15ERERE3Iem1LtESb2IB/vyEPw7pSdnHIFs+8rk5W4mAd76tBQREfE0SupFPNSeMyZ3vm8nx6gFFvjPj5B+IpU3/hpW3qGJiIhICdOcehEPtSThKDmG1als8RE/HKZZThGJiIgUhXENL7lASb2Ih/rhiL1Amc2wYNgLlouIiEjFpqRexEPt8w6By0fl7SY2Q3/2IiIinkZz6kU8VIaPP77JOQzY8TO1U1P45LqWbK9WQzcrRUTEvemLyiVK6kU8VKujh3h78Ye0Pn4UgPGrPuOxvrGYZtdyjkxERERKmu7Di3iocWs/y0/oAaymyaRPE/BCC2VFREQ8jZJ6EQ+V4h9coMwv14ajHGIRERGR0qWkXsRDvXdTRIGyz5u3wDQ0WVFERNyYdrR0yTUn9QkJCURGRpKYmFga8YhICTlYuRJx/f7EicAgHIbBqqbNGBr7ZwztUy8iIuJx3GKhbGZmJosXL2bHjh3s2rWLEydOEBERwbx584p0/ZgxY1i1ahWNGjVi2bJlpRytSMXwW2AIqyI78N/Idvg4HGRb8v7cNVIvIiLiedwiqU9JSWHevHlUqVKF5s2bc/r06SJf+/XXX7N69Wp8fX1LMUKRiifFxx8cFkyLlWzI27M+VzPqRUTE3WnwyRVukdSHh4ezYsUKqlevDkDnzp2LdF1mZiYvv/wyAwcOZN26daUZokiFY1qNvM/FS6fbeFXwZTSZ2fDxFjAMiLkZNu2BPUnQ/UaoF17e0YmIiJSbEvuGX7hwIZGRkUyePBmHw0FkZCQTJkzg+++/57777uPWW2+lZ8+eTJ06lczMTKdrfXx88hP6azF79mwcDgf/+te/XI777NmzxMbG0rNnT5KTk53OzZo1i8jISOLj411uX6TcGAaYOL8q0OCH/Y0N5PadTe6Di3HsTIIvfsZeJY6su/5L1qA3yA0dgr3ry+Q+sBhbg5GY81cD4NhxnNwHF5Pbdzb2Rd9euYP4jTBgEvztVdi4u4zelYiISOko9ki93W5n8uTJLF++nLi4OO677778czt37mT16tXExsbSp08fEhMTWbp0KXv37mXWrFlYLK7/pti2bRvLli3jhRdeICgoyOV2AgMDefHFF3nggQeYMGECr776KoZhsHHjRhYtWkSPHj3o16+fy+2LlBcv00GB3+0mFWKXettzn2Afn5B/7Fj2A9azKWTbg8n/ZZJrYJ7/CDNNMIcsw3pbK3I7ToHUc3nXffwz5pEUvMb2du7grTVw74yLx8u+gW9fgojGpfemRERESlGxRuqzsrIYPXo08fHxTJgwwSmhB9izZw/PPfccI0aMYODAgUyaNInBgwezadMmVq1a5XK/NpuN559/ng4dOhAdHV2ctwBAy5YtGTp0KBs2bGDx4sUkJyczbtw4atasyVNPPVXs9kXKQ+3UM4WWV4TBevuMr5wL0rLItftzMXoHlst+npg2A/szH+cn9Plt/WdNwQ5mrHA+zrHB3M+LE7KIiJQUbWnpEpeT+rS0NIYOHcrGjRuZNm0aMTExBerUr1+fqKgop7ILif+aNWtc7Zq33nqLw4cPM2rUKJfbuNw999zDrbfeyqxZs3jsscdITU0t9l2AkpacnEx2dnb+cUZGBunp6fnHOTk5BRYZHz9+/HePk5KSMC+Zc60+PKeP+qdOcbmArCx+O14B3keuvUDsReEo7D5Ejq1gH4W1n2ur8P/N1Yf6UB/qozh9SMVmmOa1bVqdkJDAxIkTCQwMJDMzk/nz59O6desC9SIjI4mKimLq1KkFznXr1o26devy5ptvFtpH586dadGiRaFbWh4+fJjBgwfzj3/8gwceeCC/vG/fvvj7+xdrS8uUlBT69+9Peno6Q4YM4R//+IfLbYmUtwn3foFxLJlJUXdwzseXm44d4pFvvuSf3z2Al9W9F8zaRi7H/soXFwt8vbDYMsixh+QXWclxHq1vUBnrJ/+HLeIlyMq9WO+JaLwmD3Du4D8rYNjCi8cWC6x5Fjq3LOm3IiIi18gYnVbkuuakkKtX+oNweU59dHQ0CQkJLFiwgKlTp+Ln51eScV3RtGnTCAkJoVu3bhw+fDi/3G63Y7PZOHz4MP7+/oSHX/tOGJs3b87/Ffvrr7+WWMwi5aHToT38lmonNPsc2T7e1E85TeyOLVgdDnDzpN76cixUCcTxwY8YNUKwjumJxbBhDHuH3J0pEBaE5fHbsGw/ivntPoz2DbFO7ItRpxLG6kexv7QS87c0LANuxvpEIVP0/q8P+HjBojUQ6AvD+yqhFxFxG5pX4wqXk/pevXrRtm1bxo8fz/Dhw5k2bVqBxH7//v0Frjt16hTp6enUrl3bpX6TkpI4efIkgwYNKvR8//796dSpE9OnT7/mdp9//nkaN25Mhw4dWLJkCR9++CH9+/d3KU6R8vZj7bo80adH3i44wEc3RHA8OIwNFot77GX7OwwvK15jesGYXk7lXpsmXDV2yy2NsSQMuXonD/fMe4mIiHiAYn239+zZE6vVytNPP82wYcOYPn06AQEB+ecPHjzImjVrnObVL1q0CICuXbu61Oejjz7qNCfsgkmTJuHj48Pw4cOveZTebrczduxYsrOzeemll6hXrx4///wzr7zyCq1bt6Zhw4YuxSpSnuKvb5Of0F+wqV5D533rRURExCMUe8Cue/fueHl5MWbMGOLi4pgxY0b+4tImTZowbtw4YmNjqVevHomJiaxevZqIiAh69Ojh1M67776bn6zbbDaSkpJYsGABAM2aNaNLly4AtG/fvtA4Xn31Vfz9/enevfs1v4d58+bx008/MXbsWBo1agTA888/z913381TTz3FokWL8PHxueZ2RcpTUnAoZBdywtBtTRERcWP6mnJJiUysjYqKYsqUKezcuZO4uDgyMjIAaN68OVOnTmXr1q1Mnz6dLVu2MGjQIKZNm1Zgj/rFixczd+5c5s6dS25uLseOHcs//vLLL0sizEIlJibyxhtvEB0d7TTVplatWowdO5bdu3df81QeEXeQbVjBcdmovN2sEPvUi4iIyLW55t1viioyMpKYmBgmTJhQGs2LyFXUn5lNky3b+apxS0yrheqpZ6iansaPrzbGatEwiIiIuCfjyYLTrK/EfDm4FCOpWNx9vZyIuKjf9s3MeH0GSUGhHA8O5cakw2ytURfH9Jew6t6miIiIR/HYpD4rKyt/GtDvcWXrS5GKIGbnFgBqZKRSIyMVgJuPHyrPkERERK5O404u8dikftWqVUycOPGq9RITE8sgGpGy1/D0bwXKsq0WvB0OLG6+T72IiIhcm1JL6ss7We7YsSOzZs0q1xhEylNQbi4b6jamw5F9WEyTEwHBnPH34TrNpxcREfE4HjtSHx4erqk18oeWWKcJd3a5h0bJJ6iddobv6zTipqRDfO8wMazlHZ2IiMiVaPDJFR6b1Iv80W3qGAnAvsrV2Fe5Wl5ZncY4rFaU04uIiHgWTawV8VARdzYuUNbKTNN2liIiIh5ISb2Ih7ozIoCBDXLzj8MsNmb9vUo5RiQiIiKlRdNvRDyUxTBYcpcvzef/jzP2AJ79RzSVAvU7XkRE3JxuKLtESb2Ih6vjdYY6XmcI8tGnpIiIiKfSsJ2IiIiISAWnkXoRERERcR+G7iy7QiP1IiIiIiIVnJJ6EREREZEKTkm9iIiIiEgFp6ReRERERKSC00JZEU92OoObPjtE4JlsjLrboPfN5R2RiIiIlAIl9SKeKi0TrzZjaX8sJe94zRSYeg+M6FOuYYmIiEjJ0/QbEU814zOMCwn9eebYZeUTi4iISFEZ1/CSfErqRTxU6me/ACZgA3IBO2Z2LuTayjcwERERKXFK6kU81CdVm2GeT+bBAdjYW6kKdov+7EVERDyN5tSLeCiLaWJgOpVVzUzRk/pERMTN6XvKFUrqRTxU3bQ0zlr9+SXsOs56BVI/4zD1Mo9gcTjAYi3v8ERERKQEKakX8VA7qjblQN1AMr0CANgb3JDaOcfogYFSehEREc+ipF7EQyVbg6l0PqG/4JBfbUzd1RQREXem7ymXaMWciIfKtBYyHm+CYRYsFhERkYpNSb2Ih9pbrTKOy0Y7tteoDBYNgYiIiHiaa07qExISiIyMJDExsTTiEZES0jTtN+44sooa55IIyUnjhjPbiT2wChwaqhcREfE0bjGnPjMzk8WLF7Njxw527drFiRMniIiIYN68eYXWf+ihh9i8eXOh5958801atmxZmuGKVAh/2foVdc4lUedoUn6Z/bQXhulAN+lERMRt6YayS9wiqU9JSWHevHlUqVKF5s2bc/r06ateExYWxuOPP16gvHbt2qURokiFUy0ttUCZFZv7T785dBKOJUObxuDtFh9RIiIibs8tvjHDw8NZsWIF1atXB6Bz585Xvcbf35877rijtEMTqbCOBoQTcllZDn5kZTr44qdsftmZRdqpHMJq+tD2xgCOJNloXNOLlo28Sfgxh1wb9L3ZBx8vg4TN2dgd0DfCl+qhFnJsJst/zmXfaQc9r/Mism4JfJSYJgyZh/na5ximydnqlfFKGINvjVB452vYdRSqh8GdbSE9C777Fdo0gt4ReqCWiIj84ZVYUr9w4ULmzJnDoEGDGDlyJO3atSMmJobevXszZ84cdu/eTVBQENHR0QwZMoSAgItb7fn4+OQn9NfC4XCQmZlJYGAghotf6kuWLGHatGnMnDmTDh06OJ3Lycmhd+/eNG3alLlz57rUvkh5ORMQSCZhBJCCCZhYOOZXh0cnp3D0tAPI2wkn/NcMEr7Phf9v787DY7r+P4C/70z2SSIhIYgslkhoEE0Ta9AKaW1Ji1a1IrUWRRo/SouoErRKtdai9lJLhVoq1N5aYu23aG1JbUFkkX2ZOb8/0hnGTCIZsky8X8+Thzlz7j2fO2du8plzzz0DIB9Akrkc2cqCfXy5IwMWJhLSsgrm4c/dlYl1I2wxbFs2jsYVVPpsNzA/xBLDWps/W8A7TwGLftVcdVXcTf1NsHIAADWxSURBVMK14LlwT02ElJHzqF7UFmhdmw1tD6z46NnaJiKiCoQDNYZ45qReqVRi1qxZ2Lx5M0aMGIH+/ftrnrt06RL27duH4OBgdOnSBbGxsVi/fj2uXr2K+fPnQyYzfF7vvXv30LZtW+Tk5MDCwgItW7bE8OHD4ebmVqL9dOnSBfPnz8e2bdt0kvr9+/cjNTUVwcHBBsdJVF5yFAr8WdMTv9fzRYa5BVwT7+CBZY4moQcAIUlINDfTfBnVQ5mkSegBICcPyMt7dGNtWrbApC0ZOHpTu62Jv2ZjUAszmMoN/0Us/vhH59d43du3nr7hygPAuBDAy9ngtomIiIzdM90tl52djXHjxiE6OhqRkZFaCT0AXLlyBVOnTkVERAR69eqFmTNn4p133sHJkycRExNjcLu1a9dGv379MHnyZMyYMQO9evXC77//jtDQUFy5cqVE+7Kzs0OHDh1w4MABpKZqz0GOjo6Gra0tOnToYHCsz1NSUhJych6NWKanpyMtLU3zODc3V+d+hDt37hT5OCEhAUI8StrYRuVp498qrtjTuC3SLa0gZDLEVa+N4y5N8STx2FUuZTFGRxJSVDplSZkCGbmP4jbkOJLqOersN8vE9KnxAABuJFb4/mAbbINtsI2K3gYZN0k8/g4ohu3bt2PKlCmYNWsW1q5di8uXL2PmzJlo2bKlVj1fX1+4urpi8+bNWuWJiYkICgpCYGAgoqKi9LbRtm1beHl5Fbr6jT5nzpzBkCFD4OvriwULFpTkkBAbG4uhQ4dizJgxeOeddwAAt2/fRo8ePdCrVy+MHTu2RPsjqghWvn0U/ybLoT7BJQAJVpY4XstJq56JSgX8d9UsXZKQJH/0WV8G4MmvsArrYIGpv+drrYzZ2k2OIyNsni1glQq/BczBq0ePAgAeWFnjF6/mCD11SE/lxz582FsDNxYDCotna5+IiCoEaVJWseuKzy1LMRLjYvBI/ZQpU3D+/HnMmzdPJ6FXc3d31ylzcHCAjY0Nbt0qxmX1EvDx8YGPjw9OnTqF7OzsEm3r6+sLFxcXbNu2TVO2fft2CCE49YaMlqRSQSnJkGtiWvAjN0Gd1FQM766AwhyAEKiWnYPa6ZmwsixIkhtWk6FHUzNYmQHmJsDbLczQP8AClmaAuSnwXhsLfNpdgdV9rOBcpWCbDvVMsPZdxbMHLJOh4a6PMfir2QgaOAF+0xdCtngoMOA1wET+6GbYpm6A53+rXDVyBraOZUJPRFSZSCX4IQ2D59QHBgZi+/btWLp0Kb766itYWJT/H9VatWrh1KlTSEtLK3E8ISEh+Oabb3Dx4kU0bNgQ27dvR6NGjeDh4VFK0RKVLpcHt/GnwgOXbKyRbiKHe0YWmqUno99rlgjtpIBSBeTnqWBiJoOpXEJOnoC5acFvyHylgAA0c+Qnhii0Hr/b3Ax9fEyRqwTMTZ7fb9XaNhKWRLgjJ98NZnIU3AC/dDiwcEjBL+98FWBhVlA5O/fR/4mIiF5wBo/UBwUF4fPPP8fJkycRHh6ud3T8+vXrOmWJiYlIS0srlfXk//33X8jlctjaPrmQ39N169YNpqamiI6OxvHjx5GQkIDu3bs/9xiJysrVGjWw0bkmDjtWxRn7Ktji7ITfnF0BSYJMJsHURIKlpVyTqKsTegAwkUtaN70++RgoSLifZ0L/OHMTSXtFK1MTwMREO4lnQk9ERKTxTDfKdu7cGdOmTcOZM2cwcuRIZGZmaj0fHx+PAwcOaJWtXLkSANCuXTuD2kxPT4dSqdQpP3LkCM6dOwd/f3+Ym5d8aT07Ozu0b98eu3fvxk8//QQLCwsEBQUZFCNRRfBbHVekmGnfaHqiapWK/+VTREREVGLPvKRlx44dYWJigvHjx2PEiBGYN28erK2tAQD169fHxIkTERwcDBcXF8TGxmLfvn1o3rw5OnXqpLWfDRs2aO7Kzs/PR0JCApYuXQoA8PDwQEBAAICCm1rnzJmDtm3bonbt2pDL5fjrr7+wa9cu2NnZISIiwuBjCQkJQUxMDA4fPoyuXbtqjoPIGNlmJgFy7atW2TIZoFIBsidvfyUiIiJj9ly+fKp9+/b48ssvMXbsWIwYMQLfffcdAMDT0xPh4eFYsGABtmzZAoVCgd69e2P48OE6a9SvWbNGa3mm27dva77wqWvXrpqk3tXVFV5eXjh8+DCSkpKQn5+P6tWr46233kJYWBiqV69u8HG88sorqFOnDm7cuIEePXoYvB+iisAl8wFkCheoHjvXgq6fB6SKsUQrERERPT8lXtKyuHx9fdG1a1dERkaWxu5LTe/evaFUKnWW4iQyNqET4xC0aTNmvxKE29b2eOPaObRJuIn3Tw+EnFNwiIiogpIiS7CkZSSXtFR7LiP1lcXJkydx7do1jB49urxDIXpmLvczocp1wv+dPoU8UzNYZmTiUhU3CJXgvHoiIqJKptIm9dnZ2UhPT39qPQcHB5w8eRI3b97EihUrYG9vz7XpqVLw/jceF+rWh9L00Wlul5jMZX2JiIgqoUqb1MfExGDKlClPrRcbG4vvv/8e586dg7u7OyIjI3mDLFUKFjKVVkIPAGl2NpAzqyciIqp0Si2pj42NLa1dF0vLli0xf/78YtVdsmRJKUdDVPYUqgydMiGToBLi2dayJSIiKk0SR58MUWlH6h0cHODg4FDeYRCVm4YiGYeFEsrHlq986c5FSHi5HKMiIiKi0sABO6JKquqbPnjn1BY4p9yCTXYa/OJP4dXbFyGZcI16IiKiyqbSjtQTvegs+78MxxWn8e7vOyFHHrJN7GH18+DyDouIiIhKAZN6okpKMpXDZv8H+GXsYlgkK/Hq1FBYuNiXd1hERERUCpjUE1VikiQhsZE5AEBek6s6ERERVVZM6omIiIio4uDiNwbhjbJEREREREaOST0RERERkZFjUk9EREREZOQ4p56IiIiIKhBOqjcER+qJiIiIiIwcR+qJKjm7O5lQJOcAmTlAFdPyDoeIiIhKAZN6okpKqFSQhS5Brx9PFTxeGQGxIwJSK49yjoyIiKgInH1jEE6/IaqstsTi7i8XMalTMD7o9QGiazcE3l1Q3lERERFRKeBIPVEllfxjLPw/moSbdlUBACteaYuonRsxTqmCJOfneSIiosqEf9mJKqklzt6ahF5tZvs3eFWTiIioEmJST1RJbfdqVvAfITQ/qRaWyGdWT0REVOkwqSeqpOolJEJSqgABzU/TG7cL/k9ERESVCpN6okrKLSkFQtIels8wN4O8nOIhIiKi0sMbZYkqqVQLS52yy9UdoZIkJvZERFRxcZqoQThST1RJ1UhN1ylrcvMOJJWqHKIhIiKi0sSknqiSSlWYAwAkUTCJXqZSIVcug+AICBERUaVTqkn99u3b4evri9jY2NJshoj0yDQzBWQShEwCJEAll+HvWjUgeF2TiIio0jG6OfWXLl3C7t27cfLkSdy+fRsAUKdOHXTr1g0hISEwMTG6QyIqFXZZWQVLWT7GKfUh5LAvp4iIiIiotBjd9JuVK1di+/bt8PT0xPDhwzF06FBUqVIFM2fOxOjRoyEE1+sjAoAmCTcgf2L+fOM7d6CS9I/UK1UC9zIEzyEiIiIjZHTD2m+//TYiIyNhbm6uVTZx4kTs2rULR44cQdu2bcsxQqKK4WydmlDKtD+3H3N3xYW7SqTky9CytgQTmYTETIGFZ1T4LlaFe1mAoxWwoJOEqpYyWJkAZ+8JVLcSsDGX4O0gg5O1/g8FZ+8KZOYLtKglQSZJ+N99geRsoWkHAJRXEiFupEDe0hWShWnRBxB7BVCqAL8GwGMfRMTdh1D97w5kPs6Qqiqe7UUiIiKqJMolqV+2bBkWLlyI3r17Y8yYMfDz80PXrl3x+uuvY+HChbh8+TKsra0RGBiIYcOGwcrKSrNts2bN9O4zMDAQu3btwtWrV0uU1B85cgTh4eHo1q0bJk2apCnPzMzEe++9h/T0dKxbtw4ODg4GHy9R+dC9EJcnk6PJagFACVdbIMxbwvQ/BHLzUPDbwETC/RyBXtEFdbRIAqYyFaICZIjwe7QoZkauQNfNShy4UTDC72EP1LEB9v1b8LyrLbC7pxwun2xG3rITBbtyVMAquj9MWrrphp2cDrw+FTh+ueBxUzfg10lADTvkzd2PvLHbgDwlYGEKs0W9YRLq/ywvEhERVTSFXFGmopXp9BulUomoqCgsXLgQI0aMwNixYyH7byTx0qVLGDNmDLy9vTF69Gg0a9YM69evR0REBFTFWILv3r17AICqVauWKKY2bdqgT58+2LZtG3799VdN+YwZM3Djxg1ERkYyoSejlGViCkVOjlaZa1Ky5v/xD4HPjwrkKgHIUfBLVAigiNMtTwWMO6jCvw8fTdH59rRKk9ADwD/JjxJ6dTurv76gSegBQNzPQNbQLfobmbX1UUIPAOfigM9/gupmMvLGRBck9ACQnYfc4RshUrMKD5iIiOgFUWZJfXZ2NsaNG4fo6GhERkaif//+Ws9fuXIFU6dORUREBHr16oWZM2finXfewcmTJxETE1PkvjMzM7F69WpYW1ujXbt2JY7to48+gpeXF6ZPn46bN29ix44d2LlzJ/r27YtWrVqVeH+lJSkpCTmPJWnp6elIS0vTPM7NzcWDBw+0trlz506RjxMSErTmULONytOGS2Iati36Ad3P/4VX4m9g4s4Y/Lx4hVZdTf5egkERpQD2XkzSPD6Z8PQ5+OZnbuiUqc7fgfgvQdc6jpNXdHcQexUP9v1ZMB3ncRm5UF1MAFDx+4NtsA22wTYqehtk3CRRinfFbd++HVOmTMGsWbOwdu1aXL58GTNnzkTLli216vn6+sLV1RWbN2/WKk9MTERQUBACAwMRFRWltw2lUomxY8fi4MGD+OKLLxAUFGRQrDdv3kTfvn1Rq1Yt3Lp1C25ubli+fDlX0yGjda7tatQ+ckmrTABwipoE1X9XyGR4LLGXPWWk/r/EXy4B14eYoI5tQcHM40p8crDoq2kTUv/B2OkrtMpkTWvC5uzHeiqvAaKeGMUf/jpU43sh2y0SyH+sLYUZLG9NhVRF99tziYjIOEnTc4tdV0wwK8VIjEuZjNRPmTIF58+fx7x583QSejV3d3edMgcHB9jY2ODWrVt6t1GpVPj8889x8OBBDBs2zOCEHgCcnZ0RHh6Oy5cvQ6lUYtq0aUzoyahlmuneiKqEXLNOvVsVILKNDObq6fFCFEzBKeK3gqkM+LK9TJPQA8AIHxledXn0uGFVIND10TZuVYB+4V4wHeinmScpVbeG5aK39DcyNgRo4fHocTN3YFIvyGrbwfSrYMD0v4AtTWG2oDcTeiIiIpTRjbKBgYHYvn07li5diq+++goWFhbPvE+VSoWpU6dix44dGDRoED744INn3uehQ4cAADk5OYiPj0edOnWeeZ9E5cVSlYEcmMEMuZAAKCGDhDz82V+GlHwZ/GsVrErzYTMZ/rwvYGcusCdOQGEmoWs9GeJSUbD6zV2BGtYCNmYSGjvIUEOhPVdHYSZh3zsmOHdPIDNPwP+/1W8uJBasfqNuB9/3gvKTDhA3UyFv4QrJvJBfP3YK4I8ZwOmrBdNtfOtrPgyYjmoPk3eaQ3UhAbJmzpDsrfTvg4iI6AVTJkl9UFAQXnnlFUyaNAnh4eGYM2eOTmJ//fp1ne0SExORlpaG2rVra5WrE/rt27djwIABGDJkyDPHuH79ehw6dAj9+/fHb7/9hsjISKxfv543yZLRqp2aDEskIhX2UMIElsiENZJR3VEGSf5oON7BSkIH14Kk2cfp0fZuVQr+9atVvPaaVpfw+OT8Rg7ajwFAXs8BqFfMc6p5Pb3FUg1byGvYFm8fREREL4gyu1G2c+fOmDZtGs6cOYORI0ciMzNT6/n4+HgcOHBAq2zlypUAoHXzqxACX3zxBbZv346wsDB8+OGHzxzbP//8g3nz5sHX1xfDhg3D9OnTkZGRgUmTJhVr5R2iiuhAvfq4VVWBGriFWoiHPe7jJ28/SOCXSxEREVU2ZTppvGPHjjAxMcH48eMxYsQIzJs3D9bW1gCA+vXrY+LEiQgODoaLiwtiY2Oxb98+NG/eHJ06ddLs45tvvsG2bdvg4eEBd3d37Ny5U6sNZ2dnNGnSpNgxZWVlYcKECVAoFJg6dSpkMhk8PT3x0Ucf4euvv8bKlSsRFhb2fF4AojK0vFVL/N7kNfQ6FwtFTjZi67jhhGtd9IVkfN86R0REREUq87/t7du3x5dffomxY8dixIgR+O677wAAnp6eCA8Px4IFC7BlyxYoFAr07t0bw4cP16xlDwAXLlwAUDC6/viXRal17dq1REn9rFmzEB8fjzlz5sDR0VFT3qdPH5w4cQKLFi3CK6+8gpdeesnQQyYqF67JD7HbphqW+T/6MjZJqDhST0REVAmV6pKWxeXr64uuXbsiMjKyvEMhqjTm9z+MEY21V5uyzs5G6nhLyEzkhWxFRERUvqSoEixpOZ5LWqqV6TfKElHZiWnkoVOWbmEBIeNpT0REVNlU2qm1qampyMvLK7KOhYWFZk4/UWWTI5cDKsBEmQ9Fbg5SLRXlHRIRERGVkkqb1P/f//0fTp8+XWQdTvmhyqzB/fuof+kPTNnzE6pmZeCguxfGvNEPkqo+IOP0GyIiqqikp1chHRViTn1puHjxIh4+fFhkHUdHR9StW7eMIiIqW8eClqPFr79old20dkTNlAWQy5nUExFRxSRFFT3T4nFivO63p7+oKu1IvZeXV3mHQFSurJTpOmW10hN5Iw0REVElxL/vRJXUZR9PnbJ/7RyglHjaExERVTb8605USVmEBuBYnfqax/kyGRa80xdyGecqEhFRBSaV4Ic0Ku2ceqIXnUoIfLA1G+mbY+Gc+gB/NG2OuR86o2VtfpYnIqKKS5pRgjn1n3BOvVqlnVNP9KKTSRK+72qCqIRbSFYpEBNWE7ZWTOiJiIgqIyb1RJWck/whnOQPYcnBDCIiokqLw3ZEREREREaOST0RERERkZHj9BsiIiIiqji4qo1BOFJPRERERGTkmNQTERERERk5JvVEREREREaOST0RERERkZFjUk9EREREZOSY1BMRERERGTkuaUlEREREFQeXtDQIR+qJiIiIiIwck3oiIiIiIiPHpJ6IiIiIyMgxqSciIiIiMnJM6omIiIiIjByTeiIiIiIiI8clLYmIiIio4pC4pqUhOFJPRERERJVKZGQkrK2tyzuMMsWknoiIiIjIyHH6DRERERFVHJx9YxCO1BMRERHRC+XPP/9E586doVAoUKVKFfTs2RP//vuv5vkBAwagbdu2mseJiYmQyWR45ZVXNGXp6ekwNTXFxo0byzT2wjCpJyIiIqIXxo0bNxAQEIAHDx5gzZo1WLRoEU6fPo127dohLS0NABAQEICTJ08iOzsbAHDo0CGYm5vjzJkzmjq///478vPzERAQUG7H8jhOvzESQgjNm4iouPLy8pCVlQUAePjwIUxNTcs5IiIiqshsbGwgVfLVZ+bMmYO8vDzs2bMHVatWBQD4+PigUaNGWLFiBT766CMEBAQgJycHx48fR7t27XDo0CGEhIRgz549OHr0KIKCgnDo0CF4eHigRo0a5XxEBZjUG4m0tDRUqVKlvMMgIzZ69OjyDoGIiCq41NRU2NralmsMYkzppqeHDx/Gq6++qknoAcDT0xNNmzbFkSNH8NFHH8Hd3R3Ozs44dOiQJqkfOnQosrKycPDgQU1SX1FG6QEm9UbDxsYGqamp5dJ2eno6unTpgh07drxwy0NVBuw/48c+NG7sP+P3IvWhjY1NeYdQ6pKTk9GsWTOd8ho1aiApKUnzWJ3MP3z4EOfOnUNAQAAyMjKwadMm5OTk4MSJExg0aFAZRl40JvVGQpKkcvvkLJPJIJfLYWtrW+l/mVVG7D/jxz40buw/48c+rFyqVq2Ke/fu6ZTfvXsXHh4emscBAQH4+OOPceDAATg4OMDT0xMZGRkYN24c9u/fj5ycHK2bacsbb5QlIiIiohdGmzZtsG/fPiQnJ2vK/v77b5w/fx5t2rTRlKlH5r/++mvNNJtmzZrB0tISM2bMQJ06deDm5lbW4ReKI/VEREREVOkolUps2rRJp3zUqFH44Ycf0KlTJ3z66afIzs7GZ599BhcXF/Tv319Tz9PTE9WrV8fBgwcxb948AIBcLkfr1q2xa9cu9O3bt6wOpViY1NNTmZmZYdCgQTAzMyvvUMgA7D/jxz40buw/48c+NE7Z2dno1auXTvnq1atx8OBBjBkzBn379oVcLkdgYCC+/vprnXsKAgICsGnTJq0bYtu1a4ddu3ZVqJtkAUASQojyDoKIiIiIiAzHOfVEREREREaOST0RERERkZHjnHrS69ChQ1i4cCHi4+Ph5OSE/v37o3v37kVu89dff2HTpk04c+YM7t+/j+rVq+O1117DgAEDYGlpWUaRv1ji4uIwa9YsnD9/HgqFAm+88QaGDRv21G+OFUJg5cqV2LhxI1JSUuDh4YGPP/4Y3t7eZRQ5qRnSh4mJiVi7di2OHz+OmzdvwtraGj4+PhgxYgRq1qxZhtGToefg49atW4evv/4abdq0wdy5c0svWNLrWfrw3r17mD9/Po4ePYqsrCzUrFkTAwYMwOuvv14GkRNpY1JPOs6ePYv/+7//Q48ePRAREYGTJ09i6tSpsLKyQseOHQvdLiYmBjdu3EC/fv3g4uKCa9euYfHixfjf//6HRYsWleERvBgePnyIoUOHwsXFBV9++SXu3buHOXPmIDs7G+PGjSty25UrV2Lx4sUYMWIEGjRogI0bN2LEiBFYu3YtnJ2dy+gIyNA+vHjxIvbv34/u3bvD29sbKSkpWLp0KUJDQ7FhwwbY29uX4VG8uJ7lHFRLTEzE999/r/XNllR2nqUPExMTERYWBldXV3z66adQKBS4du0acnNzyyh6oicIoicMHz5chIWFaZVNmDBB9OzZs8jtkpKSdMp27dolXn75ZXHhwoXnGiMJsXz5ctGmTRuRkpKiKdu8ebPw8/MT9+7dK3S77OxsERAQIL777jtNWW5urujatauIiooq1ZhJm6F9+PDhQ5GXl6dVlpCQIHx9fcXq1atLLV7SZmj/PW7ixIli0qRJYtCgQWLUqFGlFCkV5ln68LPPPhNhYWEiPz+/tMMkKhbOqSctubm5iI2N1RmR79SpE65fv47bt28Xuq2+0cGGDRsCAO7fv/98AyX8/vvv8PPzQ5UqVTRlgYGBUKlUOHbsWKHbnT9/HhkZGVp9bGpqig4dOuDo0aOlGjNpM7QPbWxsYGKifaG1Ro0asLe357lWhgztP7WzZ8/i4MGD+Oijj0ozTCqCoX2Ynp6OvXv3olevXpDL5WURKtFTMaknLTdv3kR+fr7ON6S5u7sDKJh7WBJnz54FgAr1jWuVRVxcnM7ramNjAwcHhyL7Sf2cvj5OSEhAdnb28w2UCmVoH+oTHx+PpKQkzblKpe9Z+k+pVGLWrFkICwuDg4ND6QVJRTK0Dy9duoS8vDyYmJhg8ODB8Pf3R+fOnTFv3jzk5+eXbtBEhWBST1oePnwIADpfvmBra6v1fHGkpKRgyZIlaNeuHVxcXJ5fkASgoC+e7CegoO+K6qeHDx/CzMwM5ubmOtsJIZCWlvbcYyX9DO3DJwkh8NVXX8HR0RGdO3d+niFSEZ6l/zZu3IisrKwK942ULxpD+/DBgwcAgC+++AJeXl6YP38++vTpgx9//JH3kFG54Y2yL4D09HQkJiY+tV7t2rWfW5v5+fmYMGECAGD8+PHPbb9EpGvJkiU4ceIEvv32W640ZQSSkpKwePFiTJkypUSr5FDFIf773k4/Pz+Eh4cDAHx9fZGZmYk1a9Zg4MCBsLCwKM8Q6QXEpP4FsHfvXnzxxRdPrbdp0ybNiHx6errWc+oRC/XzRRFCYMqUKfjrr7/w/fff89JyKbG1tdXpJwBIS0srsp9sbW2Rm5uLnJwcrdH6tLQ0SJKkd9SKSoehffi4n3/+Gd9//z0mTpwIPz+/5x0iFcHQ/lu0aBEaNGgAHx8fzZUxpVIJpVKJtLQ0WFpa6twzQaXD0D5U/5709fXVKvfz88Py5ctx8+ZN1K9f//kGS/QU/K3xAggODkZwcHCx6ubm5sLExARxcXFo2bKlprywedj6zJ07F3v37sU333wDDw8PAyKm4nBzc9OZ86m+KlNUP6mfi4+P1+qfuLg4ODk5cXSpDBnah2r79+/HjBkzMHToUPTo0aN0gqRCGdp/cXFxOH36NDp06KDzXIcOHTBv3jy0atXqOUdL+hjah3Xr1i1yvzk5Oc8hOqKS4Zx60mJmZgZfX1/s27dPqzwmJgbu7u6oVatWkduvWLEC69atw+TJkzlqWMpatWqFEydOaM2B37t3L2QyGVq0aFHodk2aNIFCocDevXs1Zfn5+di/fz9at25dqjGTNkP7EABiY2Px6aefIjg4GAMHDiztUEkPQ/svIiICixYt0vrx8PCAt7c3Fi1ahMaNG5dF+ATD+7BmzZqoX78+Tpw4oVV+/PhxmJubPzXpJyoNHKknHQMHDsSQIUMwY8YMdOzYEadOncLu3bsRFRWlVc/f3x9dunTBpEmTAAC7d+/Gd999h9dffx21a9fGn3/+qanr7OzML8R5zt566y1s2LABERER+OCDD3Dv3j188803ePPNN+Ho6Kip9+GHH+LOnTvYunUrAMDc3BxhYWFYsmQJ7O3tUb9+fWzcuBGpqal47733yuloXkyG9uH169cxZswY1KlTB2+88YbWuWZvb88vECsjhvafeqnfx1lbW8PKykpnOgeVLkP7EACGDRuGiIgIzJ49G61bt8aFCxewevVq9OvXj/e2ULlgUk86mjVrhlmzZmHhwoWIjo6Gk5MTPvvsM52165VKJVQqleaxek3fXbt2YdeuXVp1J0+ejG7dupV+8C8QW1tbLFy4EF9++SUiIiKgUCgQHByMYcOGadVTz9V9XGhoKIQQWLNmDZKTk+Hh4YFvv/2WyWAZM7QP//e//yE9PR3p6ekYMGCAVt2uXbsiMjKyLMJ/4T3LOUgVw7P0YUBAAKZNm4alS5di06ZNcHBwwJAhQ9C/f/8yPAKiRyShvoWbiIiIiIiMEufUExEREREZOSb1RERERERGjkk9EREREZGRY1JPRERERGTkmNQTERERERk5JvVEREREREaOST0RERERkZFjUk9EREREZOSY1BNRmejfvz8kSSrvMAAUfCOriYkJYmJiNGUHDhyAJElYsWJF+QVGFcKKFSsgSRIOHDhg0PZ8L+l39uxZyGQyHDx4sLxDIaqUmNQTPYNr165h8ODB8PT0hJWVFezt7eHl5YXQ0FDs379fq66bmxteeumlQvelTnoTExP1Pn/x4kVIkgRJknD48OFC96Ouo/6xsLBAgwYN8PHHHyMpKcmwA61kPv74Y7Ru3RqBgYHlHUqZiIuLQ2RkJM6ePVveoVAZSUlJQWRkpMEfTAxV1HutWbNmCA4ORkREBPhl9kTPn0l5B0BkrGJjY9GuXTuYmpqiX79+aNy4MbKysnD58mXs2bMHNjY26NChw3Nrb9myZbCxsYGlpSWWL1+Otm3bFlq3WbNmiIiIAAAkJSVh586dmDNnDmJiYnDq1CmYmZk9t7iMzR9//IGYmBhs3bpVqzwgIABZWVkwNTUtn8BKUVxcHKZMmQI3Nzc0a9asvMOhMpCSkoIpU6YAANq3b19m7T7tvTZ69Gi0a9cOO3fuRJcuXcosLqIXAZN6IgNNmTIFmZmZOHv2LJo2barzfEJCwnNrKy8vD6tXr0avXr1QpUoVLFmyBPPmzYONjY3e+rVr18Z7772neTxy5Eh069YNv/zyC6Kjo9GrV6/nFpuxWbBgARwcHPDGG29olctkMlhYWJRTVEQvhrZt28LNzQ2LFi1iUk/0nHH6DZGBLl++jGrVqulN6AHAycnpubW1fft23Lt3D6Ghoejfvz8yMjKwYcOGEu2jc+fOAIArV64UWmfhwoWQJAnbtm3TeU6lUsHZ2Vlr9G3Pnj14++23UbduXVhaWsLOzg6dOnUq9pzZ9u3bw83NTac8Li4OkiQhMjJSq1wIgYULF+Lll1+GlZUVrK2t0aFDB52pToXJz8/H1q1b0bFjR50ReX3zoB8vW7BgARo2bAgLCwt4e3vjl19+AQD8+eefCAoKgq2tLapVq4aRI0ciLy9P73Feu3YNPXr0QJUqVWBra4uQkBBcu3ZNq65KpcK0adMQEBAAJycnmJmZwcXFBR9++CEePHig97g2b96M9u3bw87ODlZWVmjYsCFGjhyJ3NxcrFixQnPFKCwsTDMtqzijt3FxcXj//fdRo0YNmJubo169epgwYQIyMzO16kVGRkKSJPz999+YMGECnJ2dYW5ujqZNm2Lnzp1PbQd4NI993759+Pzzz+Hq6gpLS0v4+/vj2LFjAICDBw+iTZs2UCgUqFmzJqZOnap3X1u3bkXr1q2hUChgbW2N1q1bIzo6Wm/d77//Hp6enjA3N0f9+vUxd+7cQqeGpKamYty4cahfvz7Mzc3h6OiIPn366PRhSRX3dS7qvhRJktC/f38ABe9bd3d3AAWDD+o+V59rj59fP/74I5o0aQILCwu4uLggMjIS+fn5Wvsu7nlanPeaJEno3Lkzdu/ejfT09BK+UkRUFI7UExmoXr16+Pvvv7Flyxa8+eabxdpGqVQWOmc+Jyen0O2WLVsGd3d3tG3bFpIkwcfHB8uXL8fAgQOLHe/ly5cBAA4ODoXWeeeddxAeHo5Vq1ahe/fuWs/t27cPt27d0kzrAQr+iCclJaFfv35wdnbGrVu3sHTpUrz22mvYv39/kVOEDPH+++/jxx9/RM+ePREWFoacnBysXbsWgYGB2LJli07MTzp16hTS09Ph5+dXonbnz5+P5ORkDBw4EBYWFpg3bx5CQkKwceNGDBo0CH369EFwcDD27NmDb7/9FtWrV8dnn32mtY+MjAy0b98e/v7+iIqKwuXLl7FgwQIcO3YMZ86c0XwIzM3NxZdffom33noLPXr0gEKhwMmTJ7Fs2TIcOXJEZ/rUp59+iunTp6NRo0YIDw9HzZo1cfXqVWzevBmff/45AgICMGHCBEyfPh2DBw/W9EmNGjWKPOb4+Hj4+fkhNTUVw4YNQ4MGDXDgwAFERUXh6NGj2LdvH0xMtP+EhIaGwtTUFGPGjEFubi7mzp2L4OBg/PPPP3qTQn0++eQTKJVKjBo1Crm5uZg9ezY6deqEVatWYcCAARg8eDD69u2Ln376CZMmTYK7u7vWVakFCxZg+PDh8PT0xKRJkwAUvE+Dg4OxePFiDB48WFN37ty5CA8PR9OmTTF9+nRkZmbiq6++QvXq1XXiSk1NRatWrfDvv//igw8+QOPGjXHnzh0sWLAA/v7+iI2Nhaura7GO8Vlf56fx8vLCnDlzEB4ejpCQEM3vJ2tra61627Ztw7Vr1zB8+HA4OTlh27ZtmDJlCuLj4/HDDz+U+FiK+15r2bIlFi9ejCNHjiAoKKjE7RBRIQQRGeT3338XpqamAoBo0KCBCAsLEwsWLBAXLlzQW9/V1VUAeOrP/fv3tba7deuWkMvlYvLkyZqyuXPnCgB62wIgOnXqJO7fvy/u378v/vnnH/H1118LU1NTUaVKFXH37t0ij6tnz57C3NxcJCUlaZW/9957wsTERGv79PR0ne0TEhJEtWrVxOuvv65VHhoaKp78ldOuXTvh6uqqs4/r168LAFrHvGXLFgFALF68WKtuXl6eePnll4Wbm5tQqVRFHtvy5csFABEdHa3z3P79+wUA8cMPP+iU1apVS6SkpGjKz507JwAISZLE5s2btfbTvHlz4eTkpHOcAMSoUaO0ytXHNGTIEE2ZSqUSmZmZOvEtXbpUABAbNmzQlB0/flwAEB06dBBZWVla9VUqleb10HdsT/Puu+8KAGLHjh1a5WPGjBEAxNKlSzVlkydPFgBEly5dtPrgxIkTAoD45JNPntreDz/8IAAIHx8fkZOToymPjo4WAISJiYk4efKkpjwnJ0c4OTmJFi1aaMqSkpKEQqEQ9erVE6mpqZry1NRUUbduXWFtbS2Sk5OFEEIkJycLKysr4eXlJTIyMjR1b9y4IRQKhQAg9u/frykfOXKksLCwEGfPntWKOy4uTtjY2IjQ0FBNWUle75K8zvrOITUAWjHoO4eefE4mk4lTp05pylUqlQgODhYAxB9//KEpL8l5WpxjP3z4sAAgvvrqq0LrEFHJcfoNkYFatmyJU6dOITQ0FKmpqfjhhx8wbNgwNGrUCAEBAXovybu5uSEmJkbvT6dOnfS2s2LFCqhUKvTr109T1rdvX5iammL58uV6t9mzZw8cHR3h6OgIDw8PfPzxx2jUqBH27NmjdxTycaGhocjJydGa3pOeno6ff/4ZQUFBWtsrFAqtOg8ePIBcLoe/vz+OHz9eZDsltWbNGtjY2CA4OBiJiYman5SUFHTr1g1xcXGaqxGFuX//PgCgatWqJWq7f//+qFKliuZxkyZNYGtri1q1aulcpWnTpg0SEhL0Ti345JNPtB6HhISgYcOGWjftSpIES0tLAAVXdlJSUpCYmIhXX30VALRe17Vr1wIAoqKidO4HUE99MIRKpcK2bdvg4+Ojc+/B+PHjIZPJ8PPPP+tsN2rUKK02X3nlFVhbWz+1Xx734Ycfal2JUI/2+vv7w9fXV1NuZmYGPz8/rX3HxMQgIyMDI0eOhK2trabc1tYWI0eORHp6Ovbu3Qug4BzJzMzE8OHDYWVlpanr7OyMvn37asUkhMDatWsREBCA2rVra73/FAoFWrRogT179hT7GNUMfZ2fl8DAQDRv3lzzWJIkjB07FgBKtd1q1aoBAO7du1dqbRC9iDj9hugZeHt7a+Zgx8fH4+DBg1i6dCkOHz6MHj166EyVUCgU6Nixo959rVmzRqdMCIHly5ejSZMmUKlUWvPhW7dujdWrVyMqKkrn8ry/vz+++OILAIC5uTlcXV3h4uJSrGNSJ+6rVq3C0KFDARTM2c7IyND6YAEAV69exaeffopff/0VKSkpWs897zXpL168iLS0tCKnjdy9exceHh6FPq+OSZRwOb26devqlNnb26NOnTp6ywHgwYMHWtMd7Ozs9N5n4eXlha1btyIjI0PzIemnn37C7NmzcebMGZ35+cnJyZr/X758GZIkFXpfh6Hu37+P9PR0NG7cWOe5qlWrombNmno/tOp7napVq1bovQD6PLkP9eupniP+5HOP7/v69esAoDdudZk6bvW/np6eOnUbNWqk9fj+/ft48OCB5sOyPjJZycfIDH2dnxcvLy+dMvWxl2a76vOvonxvBVFlwaSe6DlxdXVFv3798P7776Nt27Y4evQoTpw4gTZt2hi8z4MHD+Lq1asAgAYNGuit88svvyA4OFirzMHBodAPD09jYmKCd999F3PnzsWVK1dQv359rFq1Cvb29lpz1tPT0xEQEICMjAyMHj0a3t7esLGxgUwmQ1RUFH777bentlXYH/Unb9QDChIBR0dHrFu3rtD9FfU9AAA0CVlJ1+uXy+UlKgdK/sFBbcuWLXj77bfh5+eHb775BnXq1IGFhQWUSiWCgoKgUqm06j/LiPzzVtjrUZLXwpDXurSp4+/YsSPGjRtXbnGU5HypyO2qz7/CPiARkWGY1BM9Z5Ikwd/fH0ePHsWtW7eeaV/Lly+Hubk5Vq1apXckcMiQIVi2bJlOUv+sQkNDMXfuXKxatQqDBg3CgQMHMHjwYJibm2vq7Nu3D7dv38by5csRFhamtf2TN4kWpmrVqjh16pROub5RwgYNGuCff/5BixYtdG74Ky510l+S6SDPS0pKChISEnRG6y9evIjq1atrRulXr14NCwsL7N+/X2tayKVLl3T26eHhgV27duHcuXNF3vxb0qTf0dERNjY2+Ouvv3SeS05Oxp07dyrkevfqUf6//voLr732mtZzFy5c0Kqj/vfSpUuF1lVzdHSEnZ0dHj58aPCHZX1K+jqrp40lJSVpTSHTd74Up88vXryoU/bk66Rut7jnaXHaVV9xfNqHcCIqGc6pJzJQTEyM3pGqrKwszfzaJy/jl0Rqaio2bdqETp06oXfv3ujZs6fOT/fu3bFr1y7cuXPH4Hb0adasGZo0aYI1a9Zg9erVUKlUCA0N1aqjHjl9chR2z549xZ5P7+HhgbS0NJw4cUJTplKpMGfOHJ26/fr1g0qlwvjx4/Xu6+7du09tz8fHB7a2tpolEsvajBkztB7//PPP+Pvvv7U+lMnlckiSpDUiL4TQTKd63LvvvgsAmDBhAnJzc3WeV/eN+kNQca9QyGQydOvWDWfOnMHu3bt1jkGlUiEkJKRY+ypLgYGBUCgU+Pbbb5GWlqYpT0tLw7fffgtra2vNtwgHBgbC0tIS8+fP11o68ubNmzpXg2QyGfr27YsTJ05g06ZNets2ZH54SV9n9dQy9X0BarNnz9bZd3H6PCYmBqdPn9Y8FkJg1qxZAKD1nizJeVqcdo8dOwYTExO0bt260DpEVHIcqScyUHh4OB48eIDu3bvD29sbVlZWuHHjBtatW4d//vkH/fr1g7e3t8H7//HHH5GVlYW33nqr0DpvvfUWVqxYgZUrV+rchPmsQkNDERERgZkzZ8LDwwMtWrTQer5NmzZwcnJCREQE4uLi4OzsjLNnz2L16tXw9vbGn3/++dQ2Bg8ejNmzZyMkJASjRo2CmZkZNm3apPfDknoZy++++w6nT59G165d4eDggJs3b+KPP/7AlStXnjoPWC6X480338TWrVuRk5OjdeWhtDk4OGDLli24ffs22rdvr1nSskaNGlrr8ffs2RObN2/Gq6++in79+iEvLw9bt27VWbMcAPz8/DBu3DjMnDkTzZs3x9tvvw0nJydcv34dmzZtwokTJ2BnZ4dGjRrBxsYGCxYsgJWVFezs7FC9enXNzbf6TJ8+HTExMQgODsawYcNQv359HDp0CBs2bEBAQIDOh7yKwM7ODrNmzcLw4cPh7++vWbd9xYoVuHLlChYvXqy54dne3h5Tp07FmDFj0KpVK/Tr1w+ZmZlYtGgRGjRogDNnzmjte9q0aTh69Ch69+6N3r17o0WLFjAzM0N8fDx27tyJl19+Wes7DoqrJK9znz59MGHCBAwePBiXLl1C1apVsXv3br3L5FarVg3169fH+vXrUa9ePdSoUQMKhQLdunXT1GnatCleffVVDB8+HDVr1kR0dDT27t2L999/Hy1bttTUK8l5+rT3mhACu3fvRlBQkMFX3IioEOWy5g5RJfDrr7+KYcOGiSZNmohq1aoJuVwuqlatKtq3by+WLVsmlEqlVn1XV1fRuHHjQvenXq5OvaSlr6+vMDEx0Vla8nHZ2dnCxsZGeHh4aMrw39KCzyohIUGYmJgIAOKLL77QW+fcuXOic+fOws7OTlhbW4t27dqJQ4cO6V16r7Dl+Hbs2CGaNm0qzMzMRM2aNcXYsWPFpUuXCl2Ob9WqVaJNmzbCxsZGmJubC1dXVxESEiLWr19frONSLwO5adMmrfKilrTUtzyfq6uraNeunU65ennH69eva8rUSwJevXpVdO/eXdjY2Ahra2vRvXt3cfnyZZ19LFmyRHh5eQlzc3Ph5OQkBg0aJB48eKCzbKHaunXrRKtWrYS1tbWwsrISDRs2FKNGjdJaGnLHjh3Cx8dHmJubCwB6Y3/StWvXxHvvvSccHR2FqampcHd3F+PHj9daArKwY37a6/Qk9ZKWjy8jqVbYcRf2ntqyZYto2bKlsLKyElZWVqJly5bi559/1tvuokWLhIeHhzAzMxP16tUTc+bM0Sx9+mQsGRkZ4vPPPxcvvfSSsLCwENbW1sLT01MMHDhQHDt2TFOvpEuIFvd1FkKIY8eOiVatWglzc3NRrVo1MWjQIJGcnKz3NTp+/Lho1aqVsLKyEgA0y1I+vhTlunXrhLe3tzAzMxPOzs5i4sSJIjc3V6fdkpynRb3XDhw4IACIX375pVivDREVnySEgXdzEREZqaCgIGRkZODw4cNl0l779u0RFxeHuLi4MmmPqChxcXFwd3fH5MmTdb61ubSFhITgxo0bOHnyZIW5wZuosuCceiJ64cyePRt//PGHQWuLE5Fhzpw5g+joaMyePZsJPVEp4Jx6InrhNG7cuNSXASQibT4+PjpLshLR88OReiIiIiIiI8c59URERERERo4j9URERERERo5JPRERERGRkWNST0RERERk5JjUExEREREZOSb1RERERERGjkk9EREREZGRY1JPRERERGTkmNQTERERERk5JvVEREREREbu/wE1ORQBqn5AGQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(shap_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRxpZD8o7rzn",
        "outputId": "0b2baadd-d79e-4c69-dcfd-a911d6495b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.10669628 0.         0.         ... 0.         0.         0.        ]\n",
            " [0.0839669  0.         0.         ... 0.         0.         0.        ]\n",
            " [0.09487342 0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.14707117 0.         0.         ... 0.         0.         0.        ]\n",
            " [0.09261362 0.         0.         ... 0.07822836 0.         0.        ]\n",
            " [0.15915441 0.         0.         ... 0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model.save('/content/drive/MyDrive/svm_model.h')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "CB6x3MaR7gF8",
        "outputId": "0233a23b-c81f-444e-99a0-31ed932c91a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'SVC' object has no attribute 'save'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-472401041d60>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/svm_model.h'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'save'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ikC3Up691FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 6- CNN"
      ],
      "metadata": {
        "id": "hYHDQDaeEEF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load your keypoints CSV\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/merged_with_forward_labels_with_tasks.csv\")\n",
        "df=df[df[\"task\"]=='p']\n",
        "print(\"Data loaded successfully.\")\n",
        "print(\"Shape of the dataframe:\", df.shape)\n",
        "# Set output directory\n",
        "output_dir = \"/content/drive/MyDrive/pose_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Parameters\n",
        "image_size = 64\n",
        "num_keypoints = 17\n",
        "\n",
        "# Create pose images\n",
        "def keypoints_to_image(row):\n",
        "    img = np.zeros((image_size, image_size), dtype=np.uint8)\n",
        "    for i in range(num_keypoints):\n",
        "        x = row.get(f\"kp{i}_x\", np.nan)\n",
        "        y = row.get(f\"kp{i}_y\", np.nan)\n",
        "        if not np.isnan(x) and not np.isnan(y):\n",
        "            x = int(np.clip(x / 640 * image_size, 0, image_size - 1))\n",
        "            y = int(np.clip(y / 480 * image_size, 0, image_size - 1))\n",
        "            cv2.circle(img, (x, y), radius=2, color=255, thickness=-1)\n",
        "    return img\n",
        "\n",
        "# Generate and save images\n",
        "image_paths = []\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    img = keypoints_to_image(row)\n",
        "    path = os.path.join(output_dir, f\"pose_{idx}.png\")\n",
        "    cv2.imwrite(path, img)\n",
        "    image_paths.append(path)\n",
        "\n",
        "# Save new CSV\n",
        "df[\"pose_image_path\"] = image_paths\n",
        "df.to_csv(\"/content/drive/MyDrive/keypoints_with_pose_images.csv\", index=False)\n",
        "print(\"✅ Done. CSV saved as keypoints_with_pose_images.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tcQzV13EFkf",
        "outputId": "7a271d2b-3a0f-442c-d944-d08bb53d4f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-41d425fea50b>:8: DtypeWarning: Columns (38,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"/content/drive/MyDrive/merged_with_forward_labels_with_tasks.csv\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Shape of the dataframe: (47208, 44)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 47208/47208 [10:10<00:00, 77.37it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Done. CSV saved as keypoints_with_pose_images.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# --- 1. Load and clean the CSV ---\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/keypoints_with_pose_images.csv\")\n",
        "df = df.dropna(subset=['pose_image_path', 'playfully_engaged'])\n",
        "\n",
        "# Convert label to int if needed\n",
        "if df['playfully_engaged'].dtype != 'int':\n",
        "    le = LabelEncoder()\n",
        "    df['playfully_engaged'] = le.fit_transform(df['playfully_engaged'])\n",
        "\n",
        "# --- 2. Train/Test split by video ---\n",
        "unique_videos = df['source_video'].unique()\n",
        "train_videos, test_videos = train_test_split(unique_videos, test_size=0.2, random_state=42)\n",
        "\n",
        "train_df = df[df['source_video'].isin(train_videos)].reset_index(drop=True)\n",
        "test_df = df[df['source_video'].isin(test_videos)].reset_index(drop=True)\n",
        "\n",
        "# --- 3. Dataset Class ---\n",
        "class PoseImageDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.df = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.df.loc[idx, 'pose_image_path']\n",
        "        label = int(self.df.loc[idx, 'playfully_engaged'])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# --- 4. Image Transform ---\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# --- 5. Dataloaders ---\n",
        "train_dataset = PoseImageDataset(train_df, transform)\n",
        "test_dataset = PoseImageDataset(test_df, transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# --- 6. Simple CNN Model ---\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 8 * 8, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "# --- 7. Train the CNN ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    acc = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {running_loss:.4f}, Accuracy: {acc:.2f}%\")\n",
        "\n",
        "# --- 8. Evaluate the CNN ---\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "print(f\"\\nTest Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYKlPqrlEg3v",
        "outputId": "e9c8c44a-4e75-4287-f418-10b7a194db44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Loss: 2148.7150, Accuracy: 77.53%\n",
            "Epoch 2/5 - Loss: 1925.9674, Accuracy: 80.54%\n",
            "Epoch 3/5 - Loss: 1845.4110, Accuracy: 81.38%\n",
            "Epoch 4/5 - Loss: 1780.8398, Accuracy: 82.29%\n",
            "Epoch 5/5 - Loss: 1733.9332, Accuracy: 82.87%\n",
            "\n",
            "Test Accuracy: 51.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_Lh5C4NHH5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 7"
      ],
      "metadata": {
        "id": "D40PgbECYEIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "8I8IF3icYHpN",
        "outputId": "ef620da2-d90d-4b56-8558-4971b3051a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        frame     sec  tracking_id  kp0_x  kp0_y  kp1_x  kp1_y  kp2_x  kp2_y  \\\n",
              "0           2    0.08          164    348    796    348    782    337    792   \n",
              "1           3    0.12          164    348    797    351    779    337    793   \n",
              "2           4    0.16          164    350    796    350    781    338    796   \n",
              "3           5    0.20          164    350    798    350    781    337    792   \n",
              "4           6    0.24          164    351    799    351    787    338    793   \n",
              "...       ...     ...          ...    ...    ...    ...    ...    ...    ...   \n",
              "520982  15101  604.04           68    472    737    486    716    449    723   \n",
              "520983  15102  604.08           68    473    737    487    716    450    723   \n",
              "520984  15103  604.12           68    473    737    487    716    450    723   \n",
              "520985  15104  604.16           68    474    738    488    716    451    723   \n",
              "520986  15105  604.20           68    474    738    488    709    451    723   \n",
              "\n",
              "        kp3_x  ...  kp15_y  kp16_x  kp16_y  source_video      time  watching  \\\n",
              "0         291  ...     868     405     868          Fp17  00:00:22       1.0   \n",
              "1         340  ...     853     407     877          Fp17  00:00:22       1.0   \n",
              "2         342  ...     879     398     879          Fp17  00:00:22       1.0   \n",
              "3         342  ...     876     346     927          Fp17  00:00:22       1.0   \n",
              "4         297  ...     875     383     875          Fp17  00:00:22       1.0   \n",
              "...       ...  ...     ...     ...     ...           ...       ...       ...   \n",
              "520982    505  ...     845     528     924           P16       NaN       NaN   \n",
              "520983    505  ...     845     529     910           P16       NaN       NaN   \n",
              "520984    505  ...     844     529     923           P16       NaN       NaN   \n",
              "520985    502  ...     845     530     923           P16       NaN       NaN   \n",
              "520986    502  ...     845     530     923           P16       NaN       NaN   \n",
              "\n",
              "        playing_engaged  playfully_engaged  angrily_engaged  task  \n",
              "0                   2.0                0.0              0.0     p  \n",
              "1                   2.0                0.0              0.0     p  \n",
              "2                   2.0                0.0              0.0     p  \n",
              "3                   2.0                0.0              0.0     p  \n",
              "4                   2.0                0.0              0.0     p  \n",
              "...                 ...                ...              ...   ...  \n",
              "520982              NaN                NaN              NaN   NaN  \n",
              "520983              NaN                NaN              NaN   NaN  \n",
              "520984              NaN                NaN              NaN   NaN  \n",
              "520985              NaN                NaN              NaN   NaN  \n",
              "520986              NaN                NaN              NaN   NaN  \n",
              "\n",
              "[520987 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4165f446-17d6-419c-b4ac-f890ebe1265c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frame</th>\n",
              "      <th>sec</th>\n",
              "      <th>tracking_id</th>\n",
              "      <th>kp0_x</th>\n",
              "      <th>kp0_y</th>\n",
              "      <th>kp1_x</th>\n",
              "      <th>kp1_y</th>\n",
              "      <th>kp2_x</th>\n",
              "      <th>kp2_y</th>\n",
              "      <th>kp3_x</th>\n",
              "      <th>...</th>\n",
              "      <th>kp15_y</th>\n",
              "      <th>kp16_x</th>\n",
              "      <th>kp16_y</th>\n",
              "      <th>source_video</th>\n",
              "      <th>time</th>\n",
              "      <th>watching</th>\n",
              "      <th>playing_engaged</th>\n",
              "      <th>playfully_engaged</th>\n",
              "      <th>angrily_engaged</th>\n",
              "      <th>task</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0.08</td>\n",
              "      <td>164</td>\n",
              "      <td>348</td>\n",
              "      <td>796</td>\n",
              "      <td>348</td>\n",
              "      <td>782</td>\n",
              "      <td>337</td>\n",
              "      <td>792</td>\n",
              "      <td>291</td>\n",
              "      <td>...</td>\n",
              "      <td>868</td>\n",
              "      <td>405</td>\n",
              "      <td>868</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0.12</td>\n",
              "      <td>164</td>\n",
              "      <td>348</td>\n",
              "      <td>797</td>\n",
              "      <td>351</td>\n",
              "      <td>779</td>\n",
              "      <td>337</td>\n",
              "      <td>793</td>\n",
              "      <td>340</td>\n",
              "      <td>...</td>\n",
              "      <td>853</td>\n",
              "      <td>407</td>\n",
              "      <td>877</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0.16</td>\n",
              "      <td>164</td>\n",
              "      <td>350</td>\n",
              "      <td>796</td>\n",
              "      <td>350</td>\n",
              "      <td>781</td>\n",
              "      <td>338</td>\n",
              "      <td>796</td>\n",
              "      <td>342</td>\n",
              "      <td>...</td>\n",
              "      <td>879</td>\n",
              "      <td>398</td>\n",
              "      <td>879</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>0.20</td>\n",
              "      <td>164</td>\n",
              "      <td>350</td>\n",
              "      <td>798</td>\n",
              "      <td>350</td>\n",
              "      <td>781</td>\n",
              "      <td>337</td>\n",
              "      <td>792</td>\n",
              "      <td>342</td>\n",
              "      <td>...</td>\n",
              "      <td>876</td>\n",
              "      <td>346</td>\n",
              "      <td>927</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>0.24</td>\n",
              "      <td>164</td>\n",
              "      <td>351</td>\n",
              "      <td>799</td>\n",
              "      <td>351</td>\n",
              "      <td>787</td>\n",
              "      <td>338</td>\n",
              "      <td>793</td>\n",
              "      <td>297</td>\n",
              "      <td>...</td>\n",
              "      <td>875</td>\n",
              "      <td>383</td>\n",
              "      <td>875</td>\n",
              "      <td>Fp17</td>\n",
              "      <td>00:00:22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520982</th>\n",
              "      <td>15101</td>\n",
              "      <td>604.04</td>\n",
              "      <td>68</td>\n",
              "      <td>472</td>\n",
              "      <td>737</td>\n",
              "      <td>486</td>\n",
              "      <td>716</td>\n",
              "      <td>449</td>\n",
              "      <td>723</td>\n",
              "      <td>505</td>\n",
              "      <td>...</td>\n",
              "      <td>845</td>\n",
              "      <td>528</td>\n",
              "      <td>924</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520983</th>\n",
              "      <td>15102</td>\n",
              "      <td>604.08</td>\n",
              "      <td>68</td>\n",
              "      <td>473</td>\n",
              "      <td>737</td>\n",
              "      <td>487</td>\n",
              "      <td>716</td>\n",
              "      <td>450</td>\n",
              "      <td>723</td>\n",
              "      <td>505</td>\n",
              "      <td>...</td>\n",
              "      <td>845</td>\n",
              "      <td>529</td>\n",
              "      <td>910</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520984</th>\n",
              "      <td>15103</td>\n",
              "      <td>604.12</td>\n",
              "      <td>68</td>\n",
              "      <td>473</td>\n",
              "      <td>737</td>\n",
              "      <td>487</td>\n",
              "      <td>716</td>\n",
              "      <td>450</td>\n",
              "      <td>723</td>\n",
              "      <td>505</td>\n",
              "      <td>...</td>\n",
              "      <td>844</td>\n",
              "      <td>529</td>\n",
              "      <td>923</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520985</th>\n",
              "      <td>15104</td>\n",
              "      <td>604.16</td>\n",
              "      <td>68</td>\n",
              "      <td>474</td>\n",
              "      <td>738</td>\n",
              "      <td>488</td>\n",
              "      <td>716</td>\n",
              "      <td>451</td>\n",
              "      <td>723</td>\n",
              "      <td>502</td>\n",
              "      <td>...</td>\n",
              "      <td>845</td>\n",
              "      <td>530</td>\n",
              "      <td>923</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520986</th>\n",
              "      <td>15105</td>\n",
              "      <td>604.20</td>\n",
              "      <td>68</td>\n",
              "      <td>474</td>\n",
              "      <td>738</td>\n",
              "      <td>488</td>\n",
              "      <td>709</td>\n",
              "      <td>451</td>\n",
              "      <td>723</td>\n",
              "      <td>502</td>\n",
              "      <td>...</td>\n",
              "      <td>845</td>\n",
              "      <td>530</td>\n",
              "      <td>923</td>\n",
              "      <td>P16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>520987 rows × 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4165f446-17d6-419c-b4ac-f890ebe1265c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4165f446-17d6-419c-b4ac-f890ebe1265c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4165f446-17d6-419c-b4ac-f890ebe1265c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b2cb661d-1453-4280-929d-3c12bf4c6762\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2cb661d-1453-4280-929d-3c12bf4c6762')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b2cb661d-1453-4280-929d-3c12bf4c6762 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0d48eec7-29e2-4ab7-b9f1-1ce09a4104fb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0d48eec7-29e2-4ab7-b9f1-1ce09a4104fb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df[\"task\"]=='e']\n",
        "print(\"Data loaded successfully.\")\n",
        "print(\"Shape of the dataframe:\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq8IpD0NYFix",
        "outputId": "ceb6a01d-09d2-4edf-9473-6e1556f8afe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Shape of the dataframe: (44600, 44)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- 2. Define Target (y) and Prepare for Feature (X) Selection ---\n",
        "target_column = 'playfully_engaged'\n",
        "video_id_column = 'source_video' # IMPORTANT: Verify this is the correct column name for video IDs in your CSV\n",
        "\n",
        "if target_column not in df.columns:\n",
        "    print(f\"Error: Target column '{target_column}' not found in the dataframe.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "if video_id_column not in df.columns:\n",
        "    print(f\"Error: Video ID column '{video_id_column}' for data splitting not found.\")\n",
        "    print(f\"Please ensure '{video_id_column}' exists or update the 'video_id_column' variable.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "# Drop rows where the target variable is NaN, as they cannot be used for training or evaluation.\n",
        "df.dropna(subset=[target_column], inplace=True)\n",
        "print(f\"\\nShape of dataframe after dropping NaNs in target column '{target_column}': {df.shape}\")\n",
        "\n",
        "# Convert target variable to numeric if it's not already\n",
        "if df[target_column].dtype == 'bool':\n",
        "    df[target_column] = df[target_column].astype(int)\n",
        "elif df[target_column].dtype == 'object':\n",
        "    print(f\"Target column '{target_column}' is of object type. Attempting to encode it.\")\n",
        "    le = LabelEncoder()\n",
        "    try:\n",
        "        df[target_column] = le.fit_transform(df[target_column])\n",
        "        print(f\"Target column '{target_column}' encoded. Classes: {le.classes_}\")\n",
        "        if len(le.classes_) > 2:\n",
        "            print(\"Warning: Target variable has more than two classes. This will be a multi-class SVM.\")\n",
        "        elif len(le.classes_) <= 1:\n",
        "            print(f\"Error: Target column '{target_column}' has only one class after encoding ({le.classes_}). Cannot train a classifier.\")\n",
        "            exit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error encoding target column '{target_column}': {e}\")\n",
        "        print(\"Please ensure the target column contains appropriate values for classification.\")\n",
        "        exit()\n",
        "\n",
        "# Define feature columns\n",
        "# Identify potential keypoint columns (typically floats or integers)\n",
        "potential_feature_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Columns to exclude from features (USER UPDATED LIST)\n",
        "# This list now means other engagement labels (like focused_engagement) MIGHT become features if numeric\n",
        "columns_to_exclude_from_features = [\n",
        "    target_column, video_id_column, # video_id_column is used for splitting, not as a feature\n",
        "    'video_id', # if 'video_id' is different from video_id_column and also an identifier\n",
        "    'sec', 'seconds', 'seconds_rounded', 'sec_rounded', 'merge_key',\n",
        "    'angrily_engaged', 'playing_engaged', 'time', 'watching', 'frame', 'tracking_id','task'\n",
        "]\n",
        "# Add any other known non-feature or identifier columns if necessary.\n",
        "\n",
        "# Filter out columns from the exclusion list that might not exist in the dataframe\n",
        "columns_to_exclude_from_features = [col for col in columns_to_exclude_from_features if col in df.columns]\n",
        "\n",
        "feature_cols = [col for col in potential_feature_cols if col not in columns_to_exclude_from_features]\n",
        "\n",
        "if not feature_cols:\n",
        "    print(\"Error: No feature columns were identified. Please check the column names, types, and exclusion list.\")\n",
        "    print(f\"Potential numeric columns found: {potential_feature_cols}\")\n",
        "    print(f\"Columns excluded: {columns_to_exclude_from_features}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\nIdentified {len(feature_cols)} feature columns: {feature_cols}\")\n",
        "print(f\"Target column: {target_column}\")\n",
        "print(f\"Video ID column for splitting: {video_id_column}\")\n",
        "\n",
        "# --- 3. Split Data into Training and Testing Sets based on Video IDs ---\n",
        "unique_videos = df[video_id_column].unique()\n",
        "print(f\"\\nFound {len(unique_videos)} unique videos for splitting.\")\n",
        "\n",
        "if len(unique_videos) < 2: # Need at least one video for train and one for test\n",
        "    print(\"Error: Not enough unique videos to perform a train/test split. Need at least 2.\")\n",
        "    exit()\n",
        "# Ensure test_size is not too large for the number of videos\n",
        "test_size_videos = 0.3\n",
        "if len(unique_videos) * test_size_videos < 1:\n",
        "    print(f\"Warning: Number of unique videos ({len(unique_videos)}) is small. Adjusting test_size for videos to ensure at least 1 test video.\")\n",
        "    # Ensure at least 1 video for testing, if possible.\n",
        "    # If only 2 videos, it will be 1 train, 1 test. If 3, 2 train, 1 test.\n",
        "    test_video_count = 1\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_video_count, random_state=2, shuffle=True)\n",
        "else:\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_size_videos, random_state=2, shuffle=True)\n",
        "\n",
        "\n",
        "print(f\"Number of videos in training set: {len(train_video_ids)}\")\n",
        "print(f\"Number of videos in testing set: {len(test_video_ids)}\")\n",
        "\n",
        "if len(train_video_ids) == 0 or len(test_video_ids) == 0:\n",
        "    print(\"Error: Splitting videos resulted in an empty training or testing set of videos.\")\n",
        "    exit()\n",
        "\n",
        "# Create training and testing dataframes\n",
        "train_df = df[df[video_id_column].isin(train_video_ids)].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "test_df = df[df[video_id_column].isin(test_video_ids)].copy()\n",
        "\n",
        "if train_df.empty or test_df.empty:\n",
        "    print(\"Error: Training or testing dataframe is empty after filtering by video IDs.\")\n",
        "    exit()\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[target_column]\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "print(\"\\nData split into training and testing sets based on video IDs.\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "if X_train.empty or X_test.empty:\n",
        "    print(\"Error: X_train or X_test is empty. Check feature selection and data splitting.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Distribution of target variable in training set:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"Distribution of target variable in test set:\\n\", y_test.value_counts(normalize=True))\n",
        "\n",
        "# --- 4. Handle Missing Values in Features (Post-Split) ---\n",
        "print(f\"\\nMissing values in X_train before imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test before imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test) # Use transform only on test data\n",
        "\n",
        "# Convert imputed arrays back to DataFrames with original column names\n",
        "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns, index=X_train.index)\n",
        "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(f\"Missing values in X_train after imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test after imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "# --- 5. Scale Numerical Features (Post-Split and Post-Imputation) ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test) # Use transform only on test data\n",
        "\n",
        "print(\"\\nFeatures scaled.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92OY338QYR-t",
        "outputId": "42ff8142-a2ae-493d-ee46-0022d54abf1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-b62fd39950f3>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.dropna(subset=[target_column], inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of dataframe after dropping NaNs in target column 'playfully_engaged': (44600, 44)\n",
            "\n",
            "Identified 34 feature columns: ['kp0_x', 'kp0_y', 'kp1_x', 'kp1_y', 'kp2_x', 'kp2_y', 'kp3_x', 'kp3_y', 'kp4_x', 'kp4_y', 'kp5_x', 'kp5_y', 'kp6_x', 'kp6_y', 'kp7_x', 'kp7_y', 'kp8_x', 'kp8_y', 'kp9_x', 'kp9_y', 'kp10_x', 'kp10_y', 'kp11_x', 'kp11_y', 'kp12_x', 'kp12_y', 'kp13_x', 'kp13_y', 'kp14_x', 'kp14_y', 'kp15_x', 'kp15_y', 'kp16_x', 'kp16_y']\n",
            "Target column: playfully_engaged\n",
            "Video ID column for splitting: source_video\n",
            "\n",
            "Found 19 unique videos for splitting.\n",
            "Number of videos in training set: 13\n",
            "Number of videos in testing set: 6\n",
            "\n",
            "Data split into training and testing sets based on video IDs.\n",
            "X_train shape: (28572, 34)\n",
            "X_test shape: (16028, 34)\n",
            "y_train shape: (28572,)\n",
            "y_test shape: (16028,)\n",
            "Distribution of target variable in training set:\n",
            " playfully_engaged\n",
            "1.0    0.540389\n",
            "0.0    0.459611\n",
            "Name: proportion, dtype: float64\n",
            "Distribution of target variable in test set:\n",
            " playfully_engaged\n",
            "0.0    0.668642\n",
            "1.0    0.331358\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Missing values in X_train before imputation: 0\n",
            "Missing values in X_test before imputation: 0\n",
            "Missing values in X_train after imputation: 0\n",
            "Missing values in X_test after imputation: 0\n",
            "\n",
            "Features scaled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example using loguniform (better for C and gamma)\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.datasets import make_classification # To generate sample data\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.stats import loguniform\n",
        "\n",
        "\n",
        "svm_model = SVC(random_state=21, class_weight='balanced', probability=True)\n",
        "param_dist = {\n",
        "    'C': loguniform(1e-2, 1e2), # Example range: 0.01 to 100\n",
        "    'gamma': loguniform(1e-4, 1e-1), # Example range: 0.0001 to 0.1\n",
        "    'kernel': ['rbf', 'linear']\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "   estimator=svm_model,\n",
        "   param_distributions=param_dist,\n",
        "   n_iter=25, # Try 100 random combinations\n",
        "   cv=2,\n",
        "   scoring='accuracy', # Or other relevant metric\n",
        "   n_jobs=-1,\n",
        "   verbose=2,\n",
        "   random_state=21\n",
        ")\n",
        "\n",
        "print(\"\\nStarting RandomizedSearchCV for SVM...\")\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "print(\"RandomizedSearchCV fitting complete.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"\\nBest Hyperparameters Found (RandomizedSearch):\")\n",
        "print(random_search.best_params_)\n",
        "print(\"\\nBest Cross-Validation Score (RandomizedSearch):\")\n",
        "print(random_search.best_score_)\n",
        "\n",
        "best_svm_model_random = random_search.best_estimator_\n",
        "y_pred_best_svm_random = best_svm_model_random.predict(X_test_scaled)\n",
        "print(\"\\nPerformance of the Best SVM Model from RandomizedSearch on the (Sample) Test Set:\")\n",
        "print(classification_report(y_test, y_pred_best_svm_random))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM7GUvqMYcNJ",
        "outputId": "b63bbecf-7fa4-47d6-8004-0ce8667ceb17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting RandomizedSearchCV for SVM...\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n",
            "RandomizedSearchCV fitting complete.\n",
            "------------------------------\n",
            "\n",
            "Best Hyperparameters Found (RandomizedSearch):\n",
            "{'C': np.float64(0.40288954161165436), 'gamma': np.float64(0.0004938976330078491), 'kernel': 'rbf'}\n",
            "\n",
            "Best Cross-Validation Score (RandomizedSearch):\n",
            "0.5196696066078679\n",
            "\n",
            "Performance of the Best SVM Model from RandomizedSearch on the (Sample) Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.72      0.87      0.79     10717\n",
            "         1.0       0.54      0.32      0.40      5311\n",
            "\n",
            "    accuracy                           0.68     16028\n",
            "   macro avg       0.63      0.59      0.59     16028\n",
            "weighted avg       0.66      0.68      0.66     16028\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 8"
      ],
      "metadata": {
        "id": "zSiOWa6Vl1nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/merged_with_forward_labels_with_tasks.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_08erHxl5HV",
        "outputId": "facff3ff-b83a-491f-f8b6-3d7810c8ba64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-1fcaa27fbc51>:2: DtypeWarning: Columns (38,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df=pd.read_csv('/content/drive/MyDrive/merged_with_forward_labels_with_tasks.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df[\"task\"]=='d']\n",
        "print(\"Data loaded successfully.\")\n",
        "print(\"Shape of the dataframe:\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl9Y55IumLAD",
        "outputId": "6416dc0d-adb4-469e-ac69-73fc45fb0e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Shape of the dataframe: (0, 44)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- 2. Define Target (y) and Prepare for Feature (X) Selection ---\n",
        "target_column = 'playfully_engaged'\n",
        "video_id_column = 'source_video' # IMPORTANT: Verify this is the correct column name for video IDs in your CSV\n",
        "\n",
        "if target_column not in df.columns:\n",
        "    print(f\"Error: Target column '{target_column}' not found in the dataframe.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "if video_id_column not in df.columns:\n",
        "    print(f\"Error: Video ID column '{video_id_column}' for data splitting not found.\")\n",
        "    print(f\"Please ensure '{video_id_column}' exists or update the 'video_id_column' variable.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "# Drop rows where the target variable is NaN, as they cannot be used for training or evaluation.\n",
        "df.dropna(subset=[target_column], inplace=True)\n",
        "print(f\"\\nShape of dataframe after dropping NaNs in target column '{target_column}': {df.shape}\")\n",
        "\n",
        "# Convert target variable to numeric if it's not already\n",
        "if df[target_column].dtype == 'bool':\n",
        "    df[target_column] = df[target_column].astype(int)\n",
        "elif df[target_column].dtype == 'object':\n",
        "    print(f\"Target column '{target_column}' is of object type. Attempting to encode it.\")\n",
        "    le = LabelEncoder()\n",
        "    try:\n",
        "        df[target_column] = le.fit_transform(df[target_column])\n",
        "        print(f\"Target column '{target_column}' encoded. Classes: {le.classes_}\")\n",
        "        if len(le.classes_) > 2:\n",
        "            print(\"Warning: Target variable has more than two classes. This will be a multi-class SVM.\")\n",
        "        elif len(le.classes_) <= 1:\n",
        "            print(f\"Error: Target column '{target_column}' has only one class after encoding ({le.classes_}). Cannot train a classifier.\")\n",
        "            exit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error encoding target column '{target_column}': {e}\")\n",
        "        print(\"Please ensure the target column contains appropriate values for classification.\")\n",
        "        exit()\n",
        "\n",
        "# Define feature columns\n",
        "# Identify potential keypoint columns (typically floats or integers)\n",
        "potential_feature_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Columns to exclude from features (USER UPDATED LIST)\n",
        "# This list now means other engagement labels (like focused_engagement) MIGHT become features if numeric\n",
        "columns_to_exclude_from_features = [\n",
        "    target_column, video_id_column, # video_id_column is used for splitting, not as a feature\n",
        "    'video_id', # if 'video_id' is different from video_id_column and also an identifier\n",
        "    'sec', 'seconds', 'seconds_rounded', 'sec_rounded', 'merge_key',\n",
        "    'angrily_engaged', 'playing_engaged', 'time', 'watching', 'frame', 'tracking_id','task'\n",
        "]\n",
        "# Add any other known non-feature or identifier columns if necessary.\n",
        "\n",
        "# Filter out columns from the exclusion list that might not exist in the dataframe\n",
        "columns_to_exclude_from_features = [col for col in columns_to_exclude_from_features if col in df.columns]\n",
        "\n",
        "feature_cols = [col for col in potential_feature_cols if col not in columns_to_exclude_from_features]\n",
        "\n",
        "if not feature_cols:\n",
        "    print(\"Error: No feature columns were identified. Please check the column names, types, and exclusion list.\")\n",
        "    print(f\"Potential numeric columns found: {potential_feature_cols}\")\n",
        "    print(f\"Columns excluded: {columns_to_exclude_from_features}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\nIdentified {len(feature_cols)} feature columns: {feature_cols}\")\n",
        "print(f\"Target column: {target_column}\")\n",
        "print(f\"Video ID column for splitting: {video_id_column}\")\n",
        "\n",
        "# --- 3. Split Data into Training and Testing Sets based on Video IDs ---\n",
        "unique_videos = df[video_id_column].unique()\n",
        "print(f\"\\nFound {len(unique_videos)} unique videos for splitting.\")\n",
        "\n",
        "if len(unique_videos) < 2: # Need at least one video for train and one for test\n",
        "    print(\"Error: Not enough unique videos to perform a train/test split. Need at least 2.\")\n",
        "    exit()\n",
        "# Ensure test_size is not too large for the number of videos\n",
        "test_size_videos = 0.3\n",
        "if len(unique_videos) * test_size_videos < 1:\n",
        "    print(f\"Warning: Number of unique videos ({len(unique_videos)}) is small. Adjusting test_size for videos to ensure at least 1 test video.\")\n",
        "    # Ensure at least 1 video for testing, if possible.\n",
        "    # If only 2 videos, it will be 1 train, 1 test. If 3, 2 train, 1 test.\n",
        "    test_video_count = 1\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_video_count, random_state=21, shuffle=True)\n",
        "else:\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_size_videos, random_state=21, shuffle=True)\n",
        "\n",
        "\n",
        "print(f\"Number of videos in training set: {len(train_video_ids)}\")\n",
        "print(f\"Number of videos in testing set: {len(test_video_ids)}\")\n",
        "\n",
        "if len(train_video_ids) == 0 or len(test_video_ids) == 0:\n",
        "    print(\"Error: Splitting videos resulted in an empty training or testing set of videos.\")\n",
        "    exit()\n",
        "\n",
        "# Create training and testing dataframes\n",
        "train_df = df[df[video_id_column].isin(train_video_ids)].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "test_df = df[df[video_id_column].isin(test_video_ids)].copy()\n",
        "\n",
        "if train_df.empty or test_df.empty:\n",
        "    print(\"Error: Training or testing dataframe is empty after filtering by video IDs.\")\n",
        "    exit()\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[target_column]\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "print(\"\\nData split into training and testing sets based on video IDs.\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "if X_train.empty or X_test.empty:\n",
        "    print(\"Error: X_train or X_test is empty. Check feature selection and data splitting.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Distribution of target variable in training set:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"Distribution of target variable in test set:\\n\", y_test.value_counts(normalize=True))\n",
        "\n",
        "# --- 4. Handle Missing Values in Features (Post-Split) ---\n",
        "print(f\"\\nMissing values in X_train before imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test before imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test) # Use transform only on test data\n",
        "\n",
        "# Convert imputed arrays back to DataFrames with original column names\n",
        "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns, index=X_train.index)\n",
        "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(f\"Missing values in X_train after imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test after imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "# --- 5. Scale Numerical Features (Post-Split and Post-Imputation) ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test) # Use transform only on test data\n",
        "\n",
        "print(\"\\nFeatures scaled.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K--akXMDmXN_",
        "outputId": "bb7e47a2-eb0c-49c1-f8a1-1aff9ee26a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of dataframe after dropping NaNs in target column 'playfully_engaged': (37938, 44)\n",
            "\n",
            "Identified 34 feature columns: ['kp0_x', 'kp0_y', 'kp1_x', 'kp1_y', 'kp2_x', 'kp2_y', 'kp3_x', 'kp3_y', 'kp4_x', 'kp4_y', 'kp5_x', 'kp5_y', 'kp6_x', 'kp6_y', 'kp7_x', 'kp7_y', 'kp8_x', 'kp8_y', 'kp9_x', 'kp9_y', 'kp10_x', 'kp10_y', 'kp11_x', 'kp11_y', 'kp12_x', 'kp12_y', 'kp13_x', 'kp13_y', 'kp14_x', 'kp14_y', 'kp15_x', 'kp15_y', 'kp16_x', 'kp16_y']\n",
            "Target column: playfully_engaged\n",
            "Video ID column for splitting: source_video\n",
            "\n",
            "Found 19 unique videos for splitting.\n",
            "Number of videos in training set: 13\n",
            "Number of videos in testing set: 6\n",
            "\n",
            "Data split into training and testing sets based on video IDs.\n",
            "X_train shape: (28618, 34)\n",
            "X_test shape: (9320, 34)\n",
            "y_train shape: (28618,)\n",
            "y_test shape: (9320,)\n",
            "Distribution of target variable in training set:\n",
            " playfully_engaged\n",
            "1.0    0.536236\n",
            "0.0    0.463764\n",
            "Name: proportion, dtype: float64\n",
            "Distribution of target variable in test set:\n",
            " playfully_engaged\n",
            "0.0    0.671137\n",
            "1.0    0.328863\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Missing values in X_train before imputation: 0\n",
            "Missing values in X_test before imputation: 0\n",
            "Missing values in X_train after imputation: 0\n",
            "Missing values in X_test after imputation: 0\n",
            "\n",
            "Features scaled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Train and Evaluate SVM Model ---\n",
        "print(\"\\n--- Training SVM Model ---\")\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, class_weight='balanced', probability=True) # Added class_weight and probability\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_svm = svm_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nSVM Model Evaluation:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIKk0TzVl3Dv",
        "outputId": "5b233f62-d36f-4bdc-9781-d2b7ec2fa73b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training SVM Model ---\n",
            "\n",
            "SVM Model Evaluation:\n",
            "Accuracy: 0.5401287553648069\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.46      0.57      6255\n",
            "         1.0       0.39      0.70      0.50      3065\n",
            "\n",
            "    accuracy                           0.54      9320\n",
            "   macro avg       0.57      0.58      0.54      9320\n",
            "weighted avg       0.64      0.54      0.55      9320\n",
            "\n",
            "Confusion Matrix:\n",
            " [[2888 3367]\n",
            " [ 919 2146]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CkLW2apHnZfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 9- LSTM"
      ],
      "metadata": {
        "id": "7Mmah1a2oLwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/merged_with_forward_labels_with_tasks.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeCQcrGLpCGy",
        "outputId": "db43ea21-27a5-4876-a73e-7bbb3c76921d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-1fcaa27fbc51>:2: DtypeWarning: Columns (38,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df=pd.read_csv('/content/drive/MyDrive/merged_with_forward_labels_with_tasks.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df[\"task\"]=='p']\n",
        "print(\"Data loaded successfully.\")\n",
        "print(\"Shape of the dataframe:\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6wDciQ9pE-8",
        "outputId": "765f0763-7a9c-4239-83b8-a15b8646c927"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Shape of the dataframe: (47208, 44)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdff = pd.DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(dff.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(dff.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = pd.concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "metadata": {
        "id": "l_C6WcF5ojLq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baby_df=df.copy()"
      ],
      "metadata": {
        "id": "rObq13Q2o1lY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# keypoint sütunları\n",
        "keypoint_cols = [col for col in df.columns if \"kp\" in col and (\"_x\" in col or \"_y\" in col)]\n",
        "target_column=\"playfully_engaged\"\n",
        "\n"
      ],
      "metadata": {
        "id": "V4e3HrHJpPa_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler # Import the scaler\n",
        "import numpy as np\n",
        "# Assuming baby_df, keypoint_cols, and target_column are defined\n",
        "# and series_to_supervised is a defined function.\n",
        "\n",
        "# Your existing code:\n",
        "all_sequences_X = []\n",
        "all_sequences_y = []\n",
        "all_video_ids = []\n",
        "\n",
        "# Tüm video id'leri topla\n",
        "unique_videos = baby_df['source_video'].unique()\n",
        "print(f\"Toplam video: {len(unique_videos)}\")\n",
        "\n",
        "# Train-test video bazlı split\n",
        "train_videos, test_videos = train_test_split(unique_videos, test_size=0.3, random_state=42)\n",
        "\n",
        "X_train_list, y_train_list = [], []\n",
        "X_test_list, y_test_list = [], []\n",
        "\n",
        "for video in unique_videos:\n",
        "    video_df = baby_df[baby_df['source_video'] == video]\n",
        "    for tid in video_df['tracking_id'].unique():\n",
        "        person_df = video_df[video_df['tracking_id'] == tid].copy()\n",
        "        person_df = person_df.sort_values('sec')\n",
        "\n",
        "        # Keypoint değerleri\n",
        "        kp_data = person_df[keypoint_cols].values\n",
        "        label_data = person_df[target_column].values\n",
        "\n",
        "        # Supervised format\n",
        "        # Assuming n_in = 30, n_out = 1 for series_to_supervised\n",
        "        # and series_to_supervised handles cases with insufficient data for a full sequence\n",
        "        if len(kp_data) > 30: # Ensure there's enough data for at least one sequence\n",
        "            supervised_kp = series_to_supervised(kp_data, n_in=30, n_out=1)\n",
        "            # Ensure supervised_kp is not empty and has the expected structure\n",
        "            if not supervised_kp.empty:\n",
        "                # The last kp_data.shape[1] columns in supervised_kp are the target if n_out > 0 and target is part of kp_data\n",
        "                # Based on X_seq = supervised_kp.iloc[:, :-kp_data.shape[1]].values,\n",
        "                # it implies the supervised function creates features and targets,\n",
        "                # and you are selecting only the input features for X_seq.\n",
        "                # And y_seq = label_data[30:] implies labels are taken directly from original label_data.\n",
        "\n",
        "                X_seq_input_features = supervised_kp.iloc[:, :30*kp_data.shape[1]].values # Adjust if series_to_supervised output differs\n",
        "\n",
        "                # Ensure y_seq aligns with X_seq\n",
        "                # If series_to_supervised creates sequences of length 30 input and 1 output step,\n",
        "                # and you take y_seq from label_data[30:], this should align if each row in supervised_kp\n",
        "                # corresponds to a starting point in label_data.\n",
        "                num_sequences = X_seq_input_features.shape[0]\n",
        "\n",
        "                if num_sequences > 0 and len(label_data) >= 30 + num_sequences -1 : # Check alignment\n",
        "                    # X_seq = X_seq_input_features.reshape((num_sequences, 30, kp_data.shape[1]))\n",
        "                    # y_seq_aligned = label_data[30 : 30 + num_sequences] # Align y_seq with X_seq\n",
        "\n",
        "                    # The original code for X_seq and y_seq generation:\n",
        "                    X_seq = supervised_kp.iloc[:, :-kp_data.shape[1]].values # Assumes last columns are target features to be dropped\n",
        "                    y_seq_current = label_data[30:] # This needs to align with the number of sequences in X_seq\n",
        "\n",
        "                    # Make sure X_seq and y_seq_current have the same number of samples\n",
        "                    # The number of samples from series_to_supervised is typically len(data) - n_in - n_out + 1\n",
        "                    # For X_seq, it would be len(kp_data) - 30 - 1 + 1 = len(kp_data) - 30\n",
        "                    # So y_seq should be label_data[30 : 30 + (len(kp_data) - 30)] = label_data[30 : len(kp_data)]\n",
        "\n",
        "                    # Adjusting y_seq to match the number of sequences generated by series_to_supervised more reliably\n",
        "                    # Assuming series_to_supervised(data, n_in, n_out) generates (len(data) - n_in - n_out + 1) samples.\n",
        "                    # Here, n_out=1, so it generates (len(kp_data) - 30) samples for X.\n",
        "                    num_generated_sequences = len(kp_data) - 30\n",
        "                    if num_generated_sequences > 0:\n",
        "                        X_seq = X_seq_input_features[:num_generated_sequences] # Take the generated sequences\n",
        "                        X_seq = X_seq.reshape((num_generated_sequences, 30, kp_data.shape[1]))\n",
        "                        y_seq = label_data[30 : 30 + num_generated_sequences]\n",
        "\n",
        "\n",
        "                        if video in train_videos:\n",
        "                            X_train_list.append(X_seq)\n",
        "                            y_train_list.append(y_seq)\n",
        "                        else:\n",
        "                            X_test_list.append(X_seq)\n",
        "                            y_test_list.append(y_seq)\n",
        "\n",
        "# Final train/test arrays\n",
        "if X_train_list: # Check if lists are not empty\n",
        "    X_train = np.concatenate(X_train_list, axis=0)\n",
        "    y_train = np.concatenate(y_train_list, axis=0)\n",
        "else:\n",
        "    X_train, y_train = np.array([]), np.array([]) # Or handle as an error/warning\n",
        "\n",
        "if X_test_list:\n",
        "    X_test = np.concatenate(X_test_list, axis=0)\n",
        "    y_test = np.concatenate(y_test_list, axis=0)\n",
        "else:\n",
        "    X_test, y_test = np.array([]), np.array([])\n",
        "\n",
        "print(\"✅ Train/test verisi hazır.\")\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)\n",
        "\n",
        "# --- SCALING THE DATA ---\n",
        "# Check if X_train is not empty before proceeding with scaling\n",
        "if X_train.size > 0 and X_test.size > 0 : # Ensure X_test also has data if you intend to scale it\n",
        "    # 1. Initialize the Scaler\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # 2. Reshape X_train for scaling\n",
        "    #    The scaler expects a 2D array (n_samples, n_features).\n",
        "    #    Your X_train is 3D (n_samples, n_timesteps, n_keypoint_features).\n",
        "    #    We reshape it to (n_samples * n_timesteps, n_keypoint_features),\n",
        "    #    fit the scaler, transform, and then reshape back.\n",
        "    original_shape_X_train = X_train.shape\n",
        "    X_train_reshaped = X_train.reshape(-1, original_shape_X_train[2])\n",
        "\n",
        "    # 3. Fit the scaler on the TRAINING data\n",
        "    scaler.fit(X_train_reshaped)\n",
        "\n",
        "    # 4. Transform the TRAINING data\n",
        "    X_train_scaled_reshaped = scaler.transform(X_train_reshaped)\n",
        "    # Reshape X_train back to its original 3D shape\n",
        "    X_train_scaled = X_train_scaled_reshaped.reshape(original_shape_X_train)\n",
        "\n",
        "    # 5. Reshape and Transform the TESTING data\n",
        "    original_shape_X_test = X_test.shape\n",
        "    X_test_reshaped = X_test.reshape(-1, original_shape_X_test[2])\n",
        "    X_test_scaled_reshaped = scaler.transform(X_test_reshaped)\n",
        "    # Reshape X_test back to its original 3D shape\n",
        "    X_test_scaled = X_test_scaled_reshaped.reshape(original_shape_X_test)\n",
        "\n",
        "    print(\"✅ Veri ölçeklendirildi.\")\n",
        "    print(\"X_train_scaled:\", X_train_scaled.shape)\n",
        "    print(\"X_test_scaled:\", X_test_scaled.shape)\n",
        "\n",
        "    # Now you would use X_train_scaled, y_train, X_test_scaled, and y_test for your model\n",
        "    # For example: model.fit(X_train_scaled, y_train)\n",
        "    #            model.evaluate(X_test_scaled, y_test)\n",
        "elif X_train.size == 0:\n",
        "    print(\"⚠️ X_train is empty. Scaling cannot be performed.\")\n",
        "    # Assign empty arrays or handle as appropriate for your workflow\n",
        "    X_train_scaled, X_test_scaled = np.array([]), np.array([])\n",
        "elif X_test.size == 0 and X_train.size > 0 : # X_train has data, but X_test is empty\n",
        "    scaler = StandardScaler()\n",
        "    original_shape_X_train = X_train.shape\n",
        "    X_train_reshaped = X_train.reshape(-1, original_shape_X_train[2])\n",
        "    scaler.fit(X_train_reshaped)\n",
        "    X_train_scaled_reshaped = scaler.transform(X_train_reshaped)\n",
        "    X_train_scaled = X_train_scaled_reshaped.reshape(original_shape_X_train)\n",
        "    X_test_scaled = np.array([]) # X_test remains empty\n",
        "    print(\"✅ X_train verisi ölçeklendirildi. X_test boş.\")\n",
        "    print(\"X_train_scaled:\", X_train_scaled.shape)\n",
        "\n",
        "\n",
        "# Note: You generally do NOT scale your target variables (y_train, y_test),\n",
        "# especially if they are categorical labels for classification.\n",
        "# If it's a regression task with a wide range of output values,\n",
        "# target scaling might sometimes be considered, but it's less common."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46__yz4poNYQ",
        "outputId": "51b9fea2-6bfb-4c23-dc52-a365f12dd683"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toplam video: 17\n",
            "✅ Train/test verisi hazır.\n",
            "X_train: (33936, 30, 34) y_train: (33936,)\n",
            "X_test: (11743, 30, 34) y_test: (11743,)\n",
            "✅ Veri ölçeklendirildi.\n",
            "X_train_scaled: (33936, 30, 34)\n",
            "X_test_scaled: (11743, 30, 34)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# ✅ LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ✅ Erken durdurma\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# ✅ Modeli eğit\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_scaled, y_test),\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9vBwu6epUGY",
        "outputId": "f31260e1-b728-4a4c-e633-b06aad7cf07a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1061/1061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.8314 - loss: 0.3492 - val_accuracy: 0.7046 - val_loss: 1.3035\n",
            "Epoch 2/30\n",
            "\u001b[1m1061/1061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9472 - loss: 0.1228 - val_accuracy: 0.5853 - val_loss: 1.6745\n",
            "Epoch 3/30\n",
            "\u001b[1m1061/1061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.9523 - loss: 0.1168 - val_accuracy: 0.6565 - val_loss: 2.0246\n",
            "Epoch 4/30\n",
            "\u001b[1m1061/1061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9685 - loss: 0.0731 - val_accuracy: 0.6596 - val_loss: 1.9337\n",
            "Epoch 5/30\n",
            "\u001b[1m1061/1061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.9705 - loss: 0.0699 - val_accuracy: 0.5888 - val_loss: 2.0707\n",
            "Epoch 6/30\n",
            "\u001b[1m1061/1061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9691 - loss: 0.0732 - val_accuracy: 0.6286 - val_loss: 2.3588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "2qVfWxYerogH",
        "outputId": "8e2e1975-df86-40ad-a897-5e2a04143c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'value_counts'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-4f766a7a170c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'value_counts'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- Provided series_to_supervised function ---\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    \"\"\"\n",
        "    Frame a time series as a supervised learning dataset.\n",
        "    Arguments:\n",
        "        data: Sequence of observations as a list or NumPy array.\n",
        "        n_in: Number of lag observations as input (X).\n",
        "        n_out: Number of observations as output (y).\n",
        "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
        "    Returns:\n",
        "        Pandas DataFrame of series framed for supervised learning.\n",
        "    \"\"\"\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    dff = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(dff.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(dff.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg\n",
        "\n",
        "# --- Configuration ---\n",
        "N_IN_TIMESTEPS = 20 # Number of input timesteps for the sequence\n",
        "N_OUT_TIMESTEPS = 1 # Corresponds to n_out in series_to_supervised, relevant for X_seq slicing\n",
        "\n",
        "\n",
        "\n",
        "# 1. Collect all unique video IDs\n",
        "unique_videos = baby_df['source_video'].unique()\n",
        "print(f\"Toplam video: {len(unique_videos)}\")\n",
        "\n",
        "# 2. Split videos into training and testing sets\n",
        "train_videos, test_videos = train_test_split(unique_videos, test_size=0.3, random_state=42)\n",
        "print(f\"Training videos: {len(train_videos)}, Test videos: {len(test_videos)}\")\n",
        "\n",
        "# 3. Fit the StandardScaler ONLY on the training data\n",
        "scaler = StandardScaler()\n",
        "all_train_kp_for_scaling = []\n",
        "\n",
        "print(\"Collecting data for scaler fitting (from training videos only)...\")\n",
        "for video_id in train_videos:\n",
        "    video_df = baby_df[baby_df['source_video'] == video_id]\n",
        "    for tid in video_df['tracking_id'].unique():\n",
        "        person_df = video_df[video_df['tracking_id'] == tid].copy()\n",
        "        # Ensure data is sorted by time for sequence generation\n",
        "        person_df = person_df.sort_values('sec')\n",
        "\n",
        "        # Need at least N_IN_TIMESTEPS + 1 rows to produce one sequence\n",
        "        if len(person_df) > N_IN_TIMESTEPS:\n",
        "            kp_data = person_df[keypoint_cols].values\n",
        "            all_train_kp_for_scaling.append(kp_data)\n",
        "\n",
        "if not all_train_kp_for_scaling:\n",
        "    # This can happen if training videos are too short or have no valid tracks\n",
        "    print(\"Warning: No data available from training videos to fit the scaler. Scaling will not be applied.\")\n",
        "    # Optionally, raise an error or handle as per your needs\n",
        "    # For this example, we'll proceed without a fitted scaler, which means kp_scaled will be same as kp_data\n",
        "    # A better approach might be to ensure sufficient training data or use a default scaler.\n",
        "    # For simplicity, we'll make scaler.transform do nothing if not fitted.\n",
        "    # A real `StandardScaler` would error if transform is called before fit.\n",
        "    # So, we create a dummy scaler if no data.\n",
        "    class DummyScaler:\n",
        "        def fit(self, data): pass\n",
        "        def transform(self, data): return data\n",
        "    scaler = DummyScaler()\n",
        "\n",
        "else:\n",
        "    concatenated_train_kp = np.concatenate(all_train_kp_for_scaling, axis=0)\n",
        "    if concatenated_train_kp.shape[0] > 0 : # Ensure there is data to fit\n",
        "        scaler.fit(concatenated_train_kp)\n",
        "        print(\"Scaler fitted on training data.\")\n",
        "    else: # Should be caught by all_train_kp_for_scaling check, but as a safeguard\n",
        "        print(\"Warning: Concatenated training keypoints resulted in empty data. Scaler not fitted.\")\n",
        "        class DummyScaler: # Define dummy scaler again if fitting fails\n",
        "            def fit(self, data): pass\n",
        "            def transform(self, data): return data\n",
        "        scaler = DummyScaler()\n",
        "\n",
        "\n",
        "# 4. Prepare sequences for training and testing sets\n",
        "X_train_list, y_train_list = [], []\n",
        "X_test_list, y_test_list = [], []\n",
        "\n",
        "NUM_KEYPOINT_FEATURES = len(keypoint_cols)\n",
        "\n",
        "print(\"Processing videos to create sequences...\")\n",
        "for video_id in unique_videos:\n",
        "    video_df = baby_df[baby_df['source_video'] == video_id]\n",
        "    for tid in video_df['tracking_id'].unique():\n",
        "        person_df = video_df[video_df['tracking_id'] == tid].copy()\n",
        "        person_df = person_df.sort_values('sec')\n",
        "\n",
        "        # Sequences can only be formed if there are more data points than N_IN_TIMESTEPS\n",
        "        if len(person_df) <= N_IN_TIMESTEPS:\n",
        "            # print(f\"Skipping track {tid} in video {video_id} due to insufficient data points ({len(person_df)}).\")\n",
        "            continue\n",
        "\n",
        "        kp_data = person_df[keypoint_cols].values\n",
        "        label_data = person_df[target_column].values.ravel() # .ravel() if target_column is a list of one item\n",
        "\n",
        "        # Apply the PRE-FITTED scaler\n",
        "        kp_scaled = scaler.transform(kp_data)\n",
        "\n",
        "        # Convert to supervised learning format\n",
        "        # n_out=1 means series_to_supervised will also create columns for var(t) using original data\n",
        "        supervised_kp_df = series_to_supervised(kp_scaled, n_in=N_IN_TIMESTEPS, n_out=N_OUT_TIMESTEPS)\n",
        "\n",
        "        if supervised_kp_df.empty:\n",
        "            # print(f\"Skipping track {tid} in video {video_id} as series_to_supervised resulted in empty dataframe.\")\n",
        "            continue\n",
        "\n",
        "        # The last 'NUM_KEYPOINT_FEATURES * N_OUT_TIMESTEPS' columns are the 'y' part from series_to_supervised\n",
        "        # We want only the input part (X)\n",
        "        X_seq = supervised_kp_df.iloc[:, :-(NUM_KEYPOINT_FEATURES * N_OUT_TIMESTEPS)].values\n",
        "\n",
        "        num_sequences = X_seq.shape[0]\n",
        "        if num_sequences == 0:\n",
        "            continue\n",
        "\n",
        "        # Labels correspond to the end of the input window (or start of output window)\n",
        "        # series_to_supervised drops the first N_IN_TIMESTEPS rows\n",
        "        # So, the first sequence's label corresponds to label_data[N_IN_TIMESTEPS]\n",
        "        y_seq = label_data[N_IN_TIMESTEPS : N_IN_TIMESTEPS + num_sequences]\n",
        "\n",
        "        # Ensure X_seq and y_seq have a consistent number of samples\n",
        "        if X_seq.shape[0] != len(y_seq):\n",
        "            print(f\"Warning: Mismatch in X and y sequence lengths for track {tid}, video {video_id}. Skipping.\")\n",
        "            print(f\"X_seq shape[0]: {X_seq.shape[0]}, y_seq len: {len(y_seq)}\")\n",
        "            continue\n",
        "\n",
        "        # Reshape X_seq to (samples, timesteps, features)\n",
        "        X_seq_reshaped = X_seq.reshape((num_sequences, N_IN_TIMESTEPS, NUM_KEYPOINT_FEATURES))\n",
        "\n",
        "        if video_id in train_videos:\n",
        "            X_train_list.append(X_seq_reshaped)\n",
        "            y_train_list.append(y_seq)\n",
        "        elif video_id in test_videos: # Make sure it's explicitly in test_videos\n",
        "            X_test_list.append(X_seq_reshaped)\n",
        "            y_test_list.append(y_seq)\n",
        "\n",
        "# 5. Final train/test arrays concatenation\n",
        "if X_train_list:\n",
        "    X_train = np.concatenate(X_train_list, axis=0)\n",
        "    y_train = np.concatenate(y_train_list, axis=0)\n",
        "else:\n",
        "    X_train = np.empty((0, N_IN_TIMESTEPS, NUM_KEYPOINT_FEATURES))\n",
        "    y_train = np.empty((0,))\n",
        "    print(\"Warning: Training data is empty after processing.\")\n",
        "\n",
        "if X_test_list:\n",
        "    X_test = np.concatenate(X_test_list, axis=0)\n",
        "    y_test = np.concatenate(y_test_list, axis=0)\n",
        "else:\n",
        "    X_test = np.empty((0, N_IN_TIMESTEPS, NUM_KEYPOINT_FEATURES))\n",
        "    y_test = np.empty((0,))\n",
        "    print(\"Warning: Test data is empty after processing.\")\n",
        "\n",
        "print(\"✅ Train/test verisi hazır.\")\n",
        "print(\"X_train shape:\", X_train.shape, \"| y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape, \"| y_test shape:\", y_test.shape)\n",
        "\n",
        "# Further checks\n",
        "if X_train.shape[0] == 0 and len(train_videos) > 0:\n",
        "    print(\"Note: X_train is empty. This might be due to all training video tracks being too short or other processing issues.\")\n",
        "if X_test.shape[0] == 0 and len(test_videos) > 0:\n",
        "     print(\"Note: X_test is empty. This might be due to all test video tracks being too short or other processing issues.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf5Bk5cCrv3w",
        "outputId": "d9e487d8-c62c-49a6-b295-53bf1dc070bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toplam video: 17\n",
            "Training videos: 11, Test videos: 6\n",
            "Collecting data for scaler fitting (from training videos only)...\n",
            "Scaler fitted on training data.\n",
            "Processing videos to create sequences...\n",
            "✅ Train/test verisi hazır.\n",
            "X_train shape: (34286, 20, 34) | y_train shape: (34286,)\n",
            "X_test shape: (11883, 20, 34) | y_test shape: (11883,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# ✅ LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ✅ Erken durdurma\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# ✅ Modeli eğit\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz3tyCS6zL3F",
        "outputId": "41cbaeee-4594-4013-ceae-228876026f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.8417 - loss: 0.3291 - val_accuracy: 0.7557 - val_loss: 1.0070\n",
            "Epoch 2/30\n",
            "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.9434 - loss: 0.1310 - val_accuracy: 0.7737 - val_loss: 1.0343\n",
            "Epoch 3/30\n",
            "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9553 - loss: 0.0986 - val_accuracy: 0.7055 - val_loss: 1.5394\n",
            "Epoch 4/30\n",
            "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.9468 - loss: 0.1157 - val_accuracy: 0.7183 - val_loss: 1.8345\n",
            "Epoch 5/30\n",
            "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9664 - loss: 0.0789 - val_accuracy: 0.7427 - val_loss: 1.4977\n",
            "Epoch 6/30\n",
            "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9708 - loss: 0.0682 - val_accuracy: 0.7260 - val_loss: 1.9094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ALEXNET"
      ],
      "metadata": {
        "id": "0UVNe3Oo-xye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "\n",
        "n_in_steps = 30  # Sequence length (will be Height for 2D CNN input)\n",
        "\n",
        "# --- 1. Determine number of features and padding ---\n",
        "num_original_features = len(keypoint_cols)\n",
        "\n",
        "# For 2D CNN, target_H and target_W are not used to reshape each timestep's features into a small image.\n",
        "# Instead, padded_feature_size will be the width of our input image, and n_in_steps the height.\n",
        "# We still might want to pad features to a consistent size, e.g., to make it a power of 2 or a round number.\n",
        "# Let's keep the original padding logic for `padded_feature_size`.\n",
        "# This means each of the `n_in_steps` rows in our 2D input will have `padded_feature_size` columns.\n",
        "target_H_orig_padding_logic = int(np.ceil(np.sqrt(num_original_features)))\n",
        "target_W_orig_padding_logic = target_H_orig_padding_logic\n",
        "padded_feature_size = target_H_orig_padding_logic * target_W_orig_padding_logic # This will be the WIDTH of our 2D input\n",
        "padding_needed = padded_feature_size - num_original_features\n",
        "\n",
        "print(f\"Original features per time step: {num_original_features}\")\n",
        "print(f\"Each time step will be padded to: {padded_feature_size} features (this will be the input WIDTH for 2D CNN).\")\n",
        "print(f\"Padding needed per time step: {padding_needed}\")\n",
        "print(f\"Input to 2D CNN will have H={n_in_steps}, W={padded_feature_size}\")\n",
        "\n",
        "# --- 2. Split video IDs for training and testing ---\n",
        "if 'source_video' not in baby_df.columns:\n",
        "    raise ValueError(\"DataFrame must contain 'source_video' column for splitting.\")\n",
        "unique_videos = baby_df['source_video'].unique()\n",
        "\n",
        "train_videos = np.array([])\n",
        "test_videos = np.array([])\n",
        "\n",
        "if len(unique_videos) < 2:\n",
        "    print(\"Warning: Too few unique videos for video-based train/test split.\")\n",
        "    if len(unique_videos) == 1:\n",
        "        print(\"Only one unique video found. Using all data for training and creating an empty test set.\")\n",
        "        train_videos = unique_videos\n",
        "    else:\n",
        "        print(\"Error: No unique videos found. Cannot proceed.\")\n",
        "        exit()\n",
        "else:\n",
        "    train_videos, test_videos = train_test_split(unique_videos, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Total unique videos: {len(unique_videos)}\")\n",
        "print(f\"Training videos: {list(train_videos)}, Count: {len(train_videos)}\")\n",
        "print(f\"Testing videos: {list(test_videos)}, Count: {len(test_videos)}\")\n",
        "\n",
        "\n",
        "# --- 3. Fit Scaler on Training Data ---\n",
        "print(\"Fitting scaler on training data...\")\n",
        "scaler = StandardScaler()\n",
        "scaler_fitted = False\n",
        "\n",
        "if len(train_videos) > 0:\n",
        "    training_kp_data_for_scaler = []\n",
        "    for video_id in train_videos:\n",
        "        video_df = baby_df[baby_df['source_video'] == video_id]\n",
        "        for tid in video_df['tracking_id'].unique():\n",
        "            person_df = video_df[(video_df['tracking_id'] == tid) & (video_df['source_video'] == video_id)].copy().sort_values('sec')\n",
        "            # Ensure there's enough data to form at least one sequence for scaling purposes as well\n",
        "            if not person_df.empty and len(person_df[keypoint_cols]) >= n_in_steps:\n",
        "                training_kp_data_for_scaler.append(person_df[keypoint_cols].values)\n",
        "\n",
        "    if training_kp_data_for_scaler:\n",
        "        all_train_kp_flat = np.concatenate(training_kp_data_for_scaler, axis=0)\n",
        "        if all_train_kp_flat.shape[0] > 0:\n",
        "            scaler.fit(all_train_kp_flat)\n",
        "            print(\"Scaler fitted.\")\n",
        "            scaler_fitted = True\n",
        "        else:\n",
        "            print(\"Warning: Concatenated training keypoint data is empty. Scaler will not be fitted.\")\n",
        "    else:\n",
        "        print(\"Warning: No keypoint data found for training videos to fit the scaler. Scaler will not be fitted.\")\n",
        "else:\n",
        "    print(\"Warning: No training videos available to fit scaler. Scaler will not be fitted.\")\n",
        "\n",
        "\n",
        "# --- 4. Prepare Sequences for 2D CNN ---\n",
        "X_train_list, y_train_list = [], []\n",
        "X_test_list, y_test_list = [], []\n",
        "\n",
        "# Determine which videos to process for sequence generation\n",
        "videos_to_assign_to_train = train_videos\n",
        "videos_to_assign_to_test = test_videos\n",
        "\n",
        "print(\"Preparing sequences for 2D CNN...\")\n",
        "for video_id in unique_videos:\n",
        "    video_df = baby_df[baby_df['source_video'] == video_id]\n",
        "    for tid in video_df['tracking_id'].unique():\n",
        "        person_df = video_df[(video_df['tracking_id'] == tid) & (video_df['source_video'] == video_id)].copy()\n",
        "        person_df = person_df.sort_values('sec')\n",
        "\n",
        "        if len(person_df) < n_in_steps:\n",
        "            continue\n",
        "\n",
        "        kp_data_original = person_df[keypoint_cols].values\n",
        "        if scaler_fitted:\n",
        "            kp_data_processed = scaler.transform(kp_data_original)\n",
        "        else:\n",
        "            kp_data_processed = kp_data_original\n",
        "\n",
        "        label_data = person_df[target_column].values\n",
        "\n",
        "        num_sequences_possible = len(kp_data_processed) - n_in_steps + 1\n",
        "        if num_sequences_possible <= 0:\n",
        "            continue\n",
        "\n",
        "        current_X_sequences_list_for_person = [] # Store sequences for current person\n",
        "        current_y_sequences_list_for_person = []\n",
        "\n",
        "        for i in range(num_sequences_possible):\n",
        "            # Get the window of n_in_steps for keypoint data\n",
        "            raw_feature_sequence = kp_data_processed[i : i + n_in_steps] # Shape: (n_in_steps, num_original_features)\n",
        "\n",
        "            # Create the 2D \"image\" for the sequence: (n_in_steps, padded_feature_size)\n",
        "            sequence_2d_image = np.zeros((n_in_steps, padded_feature_size), dtype=np.float32)\n",
        "\n",
        "            for t_idx in range(n_in_steps):\n",
        "                features_at_t = raw_feature_sequence[t_idx, :] # Features for one time step\n",
        "                if padding_needed > 0:\n",
        "                    padded_features_at_t = np.pad(features_at_t, (0, padding_needed), 'constant', constant_values=0.0)\n",
        "                else:\n",
        "                    padded_features_at_t = features_at_t\n",
        "                sequence_2d_image[t_idx, :] = padded_features_at_t\n",
        "\n",
        "            # Add channel dimension: (1, n_in_steps, padded_feature_size)\n",
        "            # This ensures each sequence has a channel dimension.\n",
        "            current_X_sequences_list_for_person.append(sequence_2d_image[np.newaxis, :, :])\n",
        "            current_y_sequences_list_for_person.append(label_data[i + n_in_steps - 1])\n",
        "\n",
        "        if not current_X_sequences_list_for_person:\n",
        "            continue\n",
        "\n",
        "        # Concatenate all sequences from this person\n",
        "        # Each item in list is (1, n_in_steps, padded_feature_size)\n",
        "        # Resulting shape: (num_person_sequences, 1, n_in_steps, padded_feature_size)\n",
        "        X_person_sequences = np.concatenate(current_X_sequences_list_for_person, axis=0)\n",
        "        y_person_sequences = np.array(current_y_sequences_list_for_person)\n",
        "\n",
        "        if video_id in videos_to_assign_to_train:\n",
        "            X_train_list.append(X_person_sequences)\n",
        "            y_train_list.append(y_person_sequences)\n",
        "        elif video_id in videos_to_assign_to_test:\n",
        "            X_test_list.append(X_person_sequences)\n",
        "            y_test_list.append(y_person_sequences)\n",
        "\n",
        "# --- 5. Final Train/Test Arrays ---\n",
        "# Input shape for 2D CNN: (N, C, H, W) where C=1, H=n_in_steps, W=padded_feature_size\n",
        "if X_train_list:\n",
        "    X_train = np.concatenate(X_train_list, axis=0)\n",
        "    y_train = np.concatenate(y_train_list, axis=0).astype(np.int64)\n",
        "else:\n",
        "    X_train = np.empty((0, 1, n_in_steps, padded_feature_size), dtype=np.float32)\n",
        "    y_train = np.array([], dtype=np.int64)\n",
        "\n",
        "if X_test_list:\n",
        "    X_test = np.concatenate(X_test_list, axis=0)\n",
        "    y_test = np.concatenate(y_test_list, axis=0).astype(np.int64)\n",
        "else:\n",
        "    X_test = np.empty((0, 1, n_in_steps, padded_feature_size), dtype=np.float32)\n",
        "    y_test = np.array([], dtype=np.int64)\n",
        "\n",
        "print(\"✅ Train/test data prepared for 2D CNN.\")\n",
        "# This print should now reflect the channel dimension if data preparation is correct\n",
        "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)\n",
        "\n",
        "num_classes = 0\n",
        "if y_train.size > 0:\n",
        "    unique_train_labels = np.unique(y_train)\n",
        "    num_classes = len(unique_train_labels)\n",
        "    print(f\"Number of unique classes in y_train: {num_classes}\")\n",
        "    print(f\"Unique y_train labels: {unique_train_labels}\")\n",
        "elif y_test.size > 0:\n",
        "    unique_test_labels = np.unique(y_test)\n",
        "    num_classes = len(unique_test_labels)\n",
        "    print(f\"Warning: y_train is empty. Using y_test to determine num_classes: {num_classes}\")\n",
        "    print(f\"Unique y_test labels: {unique_test_labels}\")\n",
        "else:\n",
        "    print(\"Error: Both y_train and y_test are empty. Cannot determine num_classes.\")\n",
        "    exit()\n",
        "\n",
        "if num_classes <= 1 and (X_train.size > 0 or X_test.size > 0) : # Check if data exists but not enough classes\n",
        "    print(f\"Error: num_classes is {num_classes}. Need at least 2 classes for classification.\")\n",
        "    exit()\n",
        "if num_classes == 0: # Should be caught by above, but as a safeguard\n",
        "    print(\"Error: num_classes is 0. No data available.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# --- 6. Define Adapted 2D CNN Model (Inspired by AlexNet structure) ---\n",
        "class AlexNet2D_Adapted(nn.Module):\n",
        "    def __init__(self, num_classes, input_channels=1, input_h=30, input_w=36): # input_h=n_in_steps, input_w=padded_feature_size\n",
        "        super(AlexNet2D_Adapted, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Input: (N, C_in, H_in, W_in) = (N, 1, n_in_steps, padded_feature_size)\n",
        "            # Example: (N, 1, 30, 36)\n",
        "            nn.Conv2d(input_channels, 32, kernel_size=3, padding=1), # (N, 32, 30, 36)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # (N, 32, 15, 18)\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # (N, 64, 15, 18)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # (N, 64, 7, 9)\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # (N, 128, 7, 9)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(128),\n",
        "            # Optional: Another MaxPool2d if dimensions are still large enough\n",
        "            # nn.MaxPool2d(kernel_size=2, stride=2), # Example: (N, 128, 3, 4) - check if H/W > 1 after this\n",
        "        )\n",
        "\n",
        "        # Calculate the size after conv features by doing a dummy pass\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, input_channels, input_h, input_w)\n",
        "            conv_out_shape = self.features(dummy_input).shape\n",
        "\n",
        "        # Adaptive pool to get a fixed size output (1,1) for each feature map\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1)) # Output: (N, 128, 1, 1)\n",
        "\n",
        "        num_features_after_pool = conv_out_shape[1] # Number of channels from last conv layer (e.g., 128)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features_after_pool, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x should be (N, C, H, W)\n",
        "        x = self.features(x)\n",
        "        x = self.adaptive_pool(x) # (N, num_channels_after_conv, 1, 1)\n",
        "        x = torch.flatten(x, 1)    # (N, num_channels_after_conv)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# --- 7. Prepare PyTorch DataLoaders ---\n",
        "if X_train.shape[0] == 0:\n",
        "    print(\"Error: Training data (X_train) is empty. Cannot create DataLoaders or train model.\")\n",
        "    exit()\n",
        "\n",
        "# Ensure X_train has 4 dimensions (N, C, H, W) before converting to tensor\n",
        "if X_train.ndim == 3: # If X_train is (N, H, W)\n",
        "    print(\"Reshaping X_train from (N, H, W) to (N, 1, H, W) for DataLoader.\")\n",
        "    X_train = X_train[:, np.newaxis, :, :] # Add channel dimension\n",
        "\n",
        "X_train_tensor = torch.from_numpy(X_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).long()\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "print(\"Training DataLoader created.\")\n",
        "\n",
        "test_loader = None\n",
        "if X_test.shape[0] > 0:\n",
        "    if X_test.ndim == 3: # If X_test is (N, H, W)\n",
        "        print(\"Reshaping X_test from (N, H, W) to (N, 1, H, W) for DataLoader.\")\n",
        "        X_test = X_test[:, np.newaxis, :, :] # Add channel dimension\n",
        "    X_test_tensor = torch.from_numpy(X_test).float()\n",
        "    y_test_tensor = torch.from_numpy(y_test).long()\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "    print(\"Test DataLoader created.\")\n",
        "else:\n",
        "    print(\"Test data is empty. No Test DataLoader will be created.\")\n",
        "\n",
        "\n",
        "# --- 8. Initialize Model, Loss, Optimizer ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = AlexNet2D_Adapted(\n",
        "    num_classes=num_classes,\n",
        "    input_channels=1, # Data prepared with 1 channel\n",
        "    input_h=n_in_steps,          # Height of the 2D input\n",
        "    input_w=padded_feature_size  # Width of the 2D input\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"2D Model, Loss, and Optimizer initialized.\")\n",
        "print(model)\n",
        "\n",
        "# --- 9. Training Loop ---\n",
        "num_epochs = 10  # Adjust as needed\n",
        "\n",
        "print(\"Starting 2D CNN training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "        inputs, labels = batch_data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Explicitly ensure inputs have 4 dimensions (B, C, H, W)\n",
        "        # This is a safeguard. Ideally, data prep (step 4 & 5) and DataLoader prep (step 7)\n",
        "        # should ensure inputs already have the correct shape (B, 1, H, W).\n",
        "        if inputs.ndim == 3:  # If inputs tensor is (B, H, W)\n",
        "            inputs = inputs.unsqueeze(1)  # Reshape to (B, 1, H, W)\n",
        "\n",
        "        # Verify input shape just before model call for debugging\n",
        "        # if i == 0 and epoch == 0:\n",
        "        #     print(f\"Shape of 'inputs' tensor going into model: {inputs.shape}\")\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if (i + 1) % 10 == 0: # Print every 10 mini-batches\n",
        "            if len(train_loader) > 0 : # Avoid division by zero if train_loader is small\n",
        "                 print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    if len(train_loader) > 0:\n",
        "        print(f'Epoch {epoch+1} average loss: {running_loss / len(train_loader):.4f}')\n",
        "    else:\n",
        "        print(f'Epoch {epoch+1} completed (no training data in loader).')\n",
        "\n",
        "    # --- 10. (Optional) Validation Loop ---\n",
        "    if test_loader:\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs_val, labels_val in test_loader:\n",
        "                inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
        "\n",
        "                # Explicitly ensure validation inputs also have 4 dimensions\n",
        "                if inputs_val.ndim == 3:\n",
        "                    inputs_val = inputs_val.unsqueeze(1)\n",
        "\n",
        "                outputs_val = model(inputs_val)\n",
        "                _, predicted = torch.max(outputs_val.data, 1)\n",
        "                total += labels_val.size(0)\n",
        "                correct += (predicted == labels_val).sum().item()\n",
        "\n",
        "        if total > 0:\n",
        "            accuracy = 100 * correct / total\n",
        "            print(f'Accuracy on test set after epoch {epoch+1}: {accuracy:.2f}%')\n",
        "        # else: # No print needed if test_loader was None or empty\n",
        "            # print(\"No test samples to evaluate or test_loader is empty.\")\n",
        "\n",
        "print('2D CNN Training finished!')\n",
        "\n",
        "# TODO: Save the model if needed\n",
        "# torch.save(model.state_dict(), 'alexnet2d_adapted_baby_action.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhDms5II5Fpq",
        "outputId": "2658c6d0-14cb-49e0-a6ca-b0e4f37d9996"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original features per time step: 34\n",
            "Each time step will be padded to: 36 features (this will be the input WIDTH for 2D CNN).\n",
            "Padding needed per time step: 2\n",
            "Input to 2D CNN will have H=30, W=36\n",
            "Total unique videos: 17\n",
            "Training videos: ['Fp29', 'Fp35', 'Fp19', 'Fp30', 'Fp40', 'Fp21', 'Fp28', 'Fp31', 'Fp34', 'Fp20', 'Fp27'], Count: 11\n",
            "Testing videos: ['Fp17', 'Fp18', 'Fp24', 'Fp39', 'Fp33', 'Fp38'], Count: 6\n",
            "Fitting scaler on training data...\n",
            "Scaler fitted.\n",
            "Preparing sequences for 2D CNN...\n",
            "✅ Train/test data prepared for 2D CNN.\n",
            "X_train shape: (33971, 30, 36) y_train shape: (33971,)\n",
            "X_test shape: (11757, 30, 36) y_test shape: (11757,)\n",
            "Number of unique classes in y_train: 2\n",
            "Unique y_train labels: [0 1]\n",
            "Reshaping X_train from (N, H, W) to (N, 1, H, W) for DataLoader.\n",
            "Training DataLoader created.\n",
            "Reshaping X_test from (N, H, W) to (N, 1, H, W) for DataLoader.\n",
            "Test DataLoader created.\n",
            "Using device: cuda\n",
            "2D Model, Loss, and Optimizer initialized.\n",
            "AlexNet2D_Adapted(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (adaptive_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=256, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "Starting 2D CNN training...\n",
            "Epoch [1/10], Step [10/1062], Loss: 0.5724\n",
            "Epoch [1/10], Step [20/1062], Loss: 0.5604\n",
            "Epoch [1/10], Step [30/1062], Loss: 0.3008\n",
            "Epoch [1/10], Step [40/1062], Loss: 0.5419\n",
            "Epoch [1/10], Step [50/1062], Loss: 0.4589\n",
            "Epoch [1/10], Step [60/1062], Loss: 0.3729\n",
            "Epoch [1/10], Step [70/1062], Loss: 0.3604\n",
            "Epoch [1/10], Step [80/1062], Loss: 0.3642\n",
            "Epoch [1/10], Step [90/1062], Loss: 0.3735\n",
            "Epoch [1/10], Step [100/1062], Loss: 0.3036\n",
            "Epoch [1/10], Step [110/1062], Loss: 0.4736\n",
            "Epoch [1/10], Step [120/1062], Loss: 0.2827\n",
            "Epoch [1/10], Step [130/1062], Loss: 0.2049\n",
            "Epoch [1/10], Step [140/1062], Loss: 0.3176\n",
            "Epoch [1/10], Step [150/1062], Loss: 0.2620\n",
            "Epoch [1/10], Step [160/1062], Loss: 0.2022\n",
            "Epoch [1/10], Step [170/1062], Loss: 0.2298\n",
            "Epoch [1/10], Step [180/1062], Loss: 0.1728\n",
            "Epoch [1/10], Step [190/1062], Loss: 0.1728\n",
            "Epoch [1/10], Step [200/1062], Loss: 0.3048\n",
            "Epoch [1/10], Step [210/1062], Loss: 0.2445\n",
            "Epoch [1/10], Step [220/1062], Loss: 0.1996\n",
            "Epoch [1/10], Step [230/1062], Loss: 0.5721\n",
            "Epoch [1/10], Step [240/1062], Loss: 0.2533\n",
            "Epoch [1/10], Step [250/1062], Loss: 0.1550\n",
            "Epoch [1/10], Step [260/1062], Loss: 0.3290\n",
            "Epoch [1/10], Step [270/1062], Loss: 0.2276\n",
            "Epoch [1/10], Step [280/1062], Loss: 0.2325\n",
            "Epoch [1/10], Step [290/1062], Loss: 0.1152\n",
            "Epoch [1/10], Step [300/1062], Loss: 0.0744\n",
            "Epoch [1/10], Step [310/1062], Loss: 0.1422\n",
            "Epoch [1/10], Step [320/1062], Loss: 0.1319\n",
            "Epoch [1/10], Step [330/1062], Loss: 0.2211\n",
            "Epoch [1/10], Step [340/1062], Loss: 0.0996\n",
            "Epoch [1/10], Step [350/1062], Loss: 0.2060\n",
            "Epoch [1/10], Step [360/1062], Loss: 0.3840\n",
            "Epoch [1/10], Step [370/1062], Loss: 0.2141\n",
            "Epoch [1/10], Step [380/1062], Loss: 0.2497\n",
            "Epoch [1/10], Step [390/1062], Loss: 0.2857\n",
            "Epoch [1/10], Step [400/1062], Loss: 0.3501\n",
            "Epoch [1/10], Step [410/1062], Loss: 0.3002\n",
            "Epoch [1/10], Step [420/1062], Loss: 0.2629\n",
            "Epoch [1/10], Step [430/1062], Loss: 0.2124\n",
            "Epoch [1/10], Step [440/1062], Loss: 0.2044\n",
            "Epoch [1/10], Step [450/1062], Loss: 0.0587\n",
            "Epoch [1/10], Step [460/1062], Loss: 0.2503\n",
            "Epoch [1/10], Step [470/1062], Loss: 0.2018\n",
            "Epoch [1/10], Step [480/1062], Loss: 0.2501\n",
            "Epoch [1/10], Step [490/1062], Loss: 0.1020\n",
            "Epoch [1/10], Step [500/1062], Loss: 0.0827\n",
            "Epoch [1/10], Step [510/1062], Loss: 0.0272\n",
            "Epoch [1/10], Step [520/1062], Loss: 0.2477\n",
            "Epoch [1/10], Step [530/1062], Loss: 0.2412\n",
            "Epoch [1/10], Step [540/1062], Loss: 0.0874\n",
            "Epoch [1/10], Step [550/1062], Loss: 0.1725\n",
            "Epoch [1/10], Step [560/1062], Loss: 0.2192\n",
            "Epoch [1/10], Step [570/1062], Loss: 0.3408\n",
            "Epoch [1/10], Step [580/1062], Loss: 0.2259\n",
            "Epoch [1/10], Step [590/1062], Loss: 0.2271\n",
            "Epoch [1/10], Step [600/1062], Loss: 0.0878\n",
            "Epoch [1/10], Step [610/1062], Loss: 0.1218\n",
            "Epoch [1/10], Step [620/1062], Loss: 0.0945\n",
            "Epoch [1/10], Step [630/1062], Loss: 0.1736\n",
            "Epoch [1/10], Step [640/1062], Loss: 0.1196\n",
            "Epoch [1/10], Step [650/1062], Loss: 0.1297\n",
            "Epoch [1/10], Step [660/1062], Loss: 0.1640\n",
            "Epoch [1/10], Step [670/1062], Loss: 0.1297\n",
            "Epoch [1/10], Step [680/1062], Loss: 0.1769\n",
            "Epoch [1/10], Step [690/1062], Loss: 0.1924\n",
            "Epoch [1/10], Step [700/1062], Loss: 0.2132\n",
            "Epoch [1/10], Step [710/1062], Loss: 0.0945\n",
            "Epoch [1/10], Step [720/1062], Loss: 0.1118\n",
            "Epoch [1/10], Step [730/1062], Loss: 0.1181\n",
            "Epoch [1/10], Step [740/1062], Loss: 0.1003\n",
            "Epoch [1/10], Step [750/1062], Loss: 0.0393\n",
            "Epoch [1/10], Step [760/1062], Loss: 0.1021\n",
            "Epoch [1/10], Step [770/1062], Loss: 0.1317\n",
            "Epoch [1/10], Step [780/1062], Loss: 0.1471\n",
            "Epoch [1/10], Step [790/1062], Loss: 0.0655\n",
            "Epoch [1/10], Step [800/1062], Loss: 0.0658\n",
            "Epoch [1/10], Step [810/1062], Loss: 0.0547\n",
            "Epoch [1/10], Step [820/1062], Loss: 0.0456\n",
            "Epoch [1/10], Step [830/1062], Loss: 0.1732\n",
            "Epoch [1/10], Step [840/1062], Loss: 0.0565\n",
            "Epoch [1/10], Step [850/1062], Loss: 0.1399\n",
            "Epoch [1/10], Step [860/1062], Loss: 0.1463\n",
            "Epoch [1/10], Step [870/1062], Loss: 0.1114\n",
            "Epoch [1/10], Step [880/1062], Loss: 0.0670\n",
            "Epoch [1/10], Step [890/1062], Loss: 0.1054\n",
            "Epoch [1/10], Step [900/1062], Loss: 0.2288\n",
            "Epoch [1/10], Step [910/1062], Loss: 0.1471\n",
            "Epoch [1/10], Step [920/1062], Loss: 0.0386\n",
            "Epoch [1/10], Step [930/1062], Loss: 0.0637\n",
            "Epoch [1/10], Step [940/1062], Loss: 0.1379\n",
            "Epoch [1/10], Step [950/1062], Loss: 0.1578\n",
            "Epoch [1/10], Step [960/1062], Loss: 0.4214\n",
            "Epoch [1/10], Step [970/1062], Loss: 0.1212\n",
            "Epoch [1/10], Step [980/1062], Loss: 0.1316\n",
            "Epoch [1/10], Step [990/1062], Loss: 0.1386\n",
            "Epoch [1/10], Step [1000/1062], Loss: 0.2366\n",
            "Epoch [1/10], Step [1010/1062], Loss: 0.0907\n",
            "Epoch [1/10], Step [1020/1062], Loss: 0.0752\n",
            "Epoch [1/10], Step [1030/1062], Loss: 0.1525\n",
            "Epoch [1/10], Step [1040/1062], Loss: 0.0316\n",
            "Epoch [1/10], Step [1050/1062], Loss: 0.0980\n",
            "Epoch [1/10], Step [1060/1062], Loss: 0.1340\n",
            "Epoch 1 average loss: 0.2034\n",
            "Accuracy on test set after epoch 1: 56.93%\n",
            "Epoch [2/10], Step [10/1062], Loss: 0.0460\n",
            "Epoch [2/10], Step [20/1062], Loss: 0.0360\n",
            "Epoch [2/10], Step [30/1062], Loss: 0.1889\n",
            "Epoch [2/10], Step [40/1062], Loss: 0.1172\n",
            "Epoch [2/10], Step [50/1062], Loss: 0.0421\n",
            "Epoch [2/10], Step [60/1062], Loss: 0.0327\n",
            "Epoch [2/10], Step [70/1062], Loss: 0.1747\n",
            "Epoch [2/10], Step [80/1062], Loss: 0.3551\n",
            "Epoch [2/10], Step [90/1062], Loss: 0.5691\n",
            "Epoch [2/10], Step [100/1062], Loss: 0.2527\n",
            "Epoch [2/10], Step [110/1062], Loss: 0.0750\n",
            "Epoch [2/10], Step [120/1062], Loss: 0.0887\n",
            "Epoch [2/10], Step [130/1062], Loss: 0.1998\n",
            "Epoch [2/10], Step [140/1062], Loss: 0.2050\n",
            "Epoch [2/10], Step [150/1062], Loss: 0.0744\n",
            "Epoch [2/10], Step [160/1062], Loss: 0.1324\n",
            "Epoch [2/10], Step [170/1062], Loss: 0.0110\n",
            "Epoch [2/10], Step [180/1062], Loss: 0.0611\n",
            "Epoch [2/10], Step [190/1062], Loss: 0.0698\n",
            "Epoch [2/10], Step [200/1062], Loss: 0.0834\n",
            "Epoch [2/10], Step [210/1062], Loss: 0.0825\n",
            "Epoch [2/10], Step [220/1062], Loss: 0.0723\n",
            "Epoch [2/10], Step [230/1062], Loss: 0.0541\n",
            "Epoch [2/10], Step [240/1062], Loss: 0.2541\n",
            "Epoch [2/10], Step [250/1062], Loss: 0.1328\n",
            "Epoch [2/10], Step [260/1062], Loss: 0.1254\n",
            "Epoch [2/10], Step [270/1062], Loss: 0.0708\n",
            "Epoch [2/10], Step [280/1062], Loss: 0.0526\n",
            "Epoch [2/10], Step [290/1062], Loss: 0.1467\n",
            "Epoch [2/10], Step [300/1062], Loss: 0.1641\n",
            "Epoch [2/10], Step [310/1062], Loss: 0.1101\n",
            "Epoch [2/10], Step [320/1062], Loss: 0.0285\n",
            "Epoch [2/10], Step [330/1062], Loss: 0.0502\n",
            "Epoch [2/10], Step [340/1062], Loss: 0.1319\n",
            "Epoch [2/10], Step [350/1062], Loss: 0.0630\n",
            "Epoch [2/10], Step [360/1062], Loss: 0.1880\n",
            "Epoch [2/10], Step [370/1062], Loss: 0.0649\n",
            "Epoch [2/10], Step [380/1062], Loss: 0.0805\n",
            "Epoch [2/10], Step [390/1062], Loss: 0.0142\n",
            "Epoch [2/10], Step [400/1062], Loss: 0.0461\n",
            "Epoch [2/10], Step [410/1062], Loss: 0.0801\n",
            "Epoch [2/10], Step [420/1062], Loss: 0.1106\n",
            "Epoch [2/10], Step [430/1062], Loss: 0.0958\n",
            "Epoch [2/10], Step [440/1062], Loss: 0.1240\n",
            "Epoch [2/10], Step [450/1062], Loss: 0.0566\n",
            "Epoch [2/10], Step [460/1062], Loss: 0.0151\n",
            "Epoch [2/10], Step [470/1062], Loss: 0.0352\n",
            "Epoch [2/10], Step [480/1062], Loss: 0.1168\n",
            "Epoch [2/10], Step [490/1062], Loss: 0.0413\n",
            "Epoch [2/10], Step [500/1062], Loss: 0.0270\n",
            "Epoch [2/10], Step [510/1062], Loss: 0.0216\n",
            "Epoch [2/10], Step [520/1062], Loss: 0.0730\n",
            "Epoch [2/10], Step [530/1062], Loss: 0.0357\n",
            "Epoch [2/10], Step [540/1062], Loss: 0.0319\n",
            "Epoch [2/10], Step [550/1062], Loss: 0.0359\n",
            "Epoch [2/10], Step [560/1062], Loss: 0.0421\n",
            "Epoch [2/10], Step [570/1062], Loss: 0.0600\n",
            "Epoch [2/10], Step [580/1062], Loss: 0.0973\n",
            "Epoch [2/10], Step [590/1062], Loss: 0.0203\n",
            "Epoch [2/10], Step [600/1062], Loss: 0.0184\n",
            "Epoch [2/10], Step [610/1062], Loss: 0.1070\n",
            "Epoch [2/10], Step [620/1062], Loss: 0.0556\n",
            "Epoch [2/10], Step [630/1062], Loss: 0.0516\n",
            "Epoch [2/10], Step [640/1062], Loss: 0.3228\n",
            "Epoch [2/10], Step [650/1062], Loss: 0.1005\n",
            "Epoch [2/10], Step [660/1062], Loss: 0.0835\n",
            "Epoch [2/10], Step [670/1062], Loss: 0.0881\n",
            "Epoch [2/10], Step [680/1062], Loss: 0.1964\n",
            "Epoch [2/10], Step [690/1062], Loss: 0.0343\n",
            "Epoch [2/10], Step [700/1062], Loss: 0.0553\n",
            "Epoch [2/10], Step [710/1062], Loss: 0.0516\n",
            "Epoch [2/10], Step [720/1062], Loss: 0.0119\n",
            "Epoch [2/10], Step [730/1062], Loss: 0.0315\n",
            "Epoch [2/10], Step [740/1062], Loss: 0.1611\n",
            "Epoch [2/10], Step [750/1062], Loss: 0.0761\n",
            "Epoch [2/10], Step [760/1062], Loss: 0.0790\n",
            "Epoch [2/10], Step [770/1062], Loss: 0.0549\n",
            "Epoch [2/10], Step [780/1062], Loss: 0.1229\n",
            "Epoch [2/10], Step [790/1062], Loss: 0.0891\n",
            "Epoch [2/10], Step [800/1062], Loss: 0.0502\n",
            "Epoch [2/10], Step [810/1062], Loss: 0.0909\n",
            "Epoch [2/10], Step [820/1062], Loss: 0.0075\n",
            "Epoch [2/10], Step [830/1062], Loss: 0.0219\n",
            "Epoch [2/10], Step [840/1062], Loss: 0.0224\n",
            "Epoch [2/10], Step [850/1062], Loss: 0.0247\n",
            "Epoch [2/10], Step [860/1062], Loss: 0.1733\n",
            "Epoch [2/10], Step [870/1062], Loss: 0.0569\n",
            "Epoch [2/10], Step [880/1062], Loss: 0.1161\n",
            "Epoch [2/10], Step [890/1062], Loss: 0.0401\n",
            "Epoch [2/10], Step [900/1062], Loss: 0.0274\n",
            "Epoch [2/10], Step [910/1062], Loss: 0.0705\n",
            "Epoch [2/10], Step [920/1062], Loss: 0.0408\n",
            "Epoch [2/10], Step [930/1062], Loss: 0.1725\n",
            "Epoch [2/10], Step [940/1062], Loss: 0.1609\n",
            "Epoch [2/10], Step [950/1062], Loss: 0.1508\n",
            "Epoch [2/10], Step [960/1062], Loss: 0.0575\n",
            "Epoch [2/10], Step [970/1062], Loss: 0.0128\n",
            "Epoch [2/10], Step [980/1062], Loss: 0.0028\n",
            "Epoch [2/10], Step [990/1062], Loss: 0.0241\n",
            "Epoch [2/10], Step [1000/1062], Loss: 0.0159\n",
            "Epoch [2/10], Step [1010/1062], Loss: 0.0367\n",
            "Epoch [2/10], Step [1020/1062], Loss: 0.2671\n",
            "Epoch [2/10], Step [1030/1062], Loss: 0.1016\n",
            "Epoch [2/10], Step [1040/1062], Loss: 0.0519\n",
            "Epoch [2/10], Step [1050/1062], Loss: 0.0541\n",
            "Epoch [2/10], Step [1060/1062], Loss: 0.0999\n",
            "Epoch 2 average loss: 0.0928\n",
            "Accuracy on test set after epoch 2: 58.90%\n",
            "Epoch [3/10], Step [10/1062], Loss: 0.1227\n",
            "Epoch [3/10], Step [20/1062], Loss: 0.0367\n",
            "Epoch [3/10], Step [30/1062], Loss: 0.0926\n",
            "Epoch [3/10], Step [40/1062], Loss: 0.0549\n",
            "Epoch [3/10], Step [50/1062], Loss: 0.0919\n",
            "Epoch [3/10], Step [60/1062], Loss: 0.0708\n",
            "Epoch [3/10], Step [70/1062], Loss: 0.0510\n",
            "Epoch [3/10], Step [80/1062], Loss: 0.0271\n",
            "Epoch [3/10], Step [90/1062], Loss: 0.0520\n",
            "Epoch [3/10], Step [100/1062], Loss: 0.0589\n",
            "Epoch [3/10], Step [110/1062], Loss: 0.2230\n",
            "Epoch [3/10], Step [120/1062], Loss: 0.3090\n",
            "Epoch [3/10], Step [130/1062], Loss: 0.1679\n",
            "Epoch [3/10], Step [140/1062], Loss: 0.0442\n",
            "Epoch [3/10], Step [150/1062], Loss: 0.0331\n",
            "Epoch [3/10], Step [160/1062], Loss: 0.0702\n",
            "Epoch [3/10], Step [170/1062], Loss: 0.1275\n",
            "Epoch [3/10], Step [180/1062], Loss: 0.0279\n",
            "Epoch [3/10], Step [190/1062], Loss: 0.0768\n",
            "Epoch [3/10], Step [200/1062], Loss: 0.0369\n",
            "Epoch [3/10], Step [210/1062], Loss: 0.0026\n",
            "Epoch [3/10], Step [220/1062], Loss: 0.0364\n",
            "Epoch [3/10], Step [230/1062], Loss: 0.0115\n",
            "Epoch [3/10], Step [240/1062], Loss: 0.0493\n",
            "Epoch [3/10], Step [250/1062], Loss: 0.0614\n",
            "Epoch [3/10], Step [260/1062], Loss: 0.0844\n",
            "Epoch [3/10], Step [270/1062], Loss: 0.0584\n",
            "Epoch [3/10], Step [280/1062], Loss: 0.0652\n",
            "Epoch [3/10], Step [290/1062], Loss: 0.0767\n",
            "Epoch [3/10], Step [300/1062], Loss: 0.1352\n",
            "Epoch [3/10], Step [310/1062], Loss: 0.1422\n",
            "Epoch [3/10], Step [320/1062], Loss: 0.1989\n",
            "Epoch [3/10], Step [330/1062], Loss: 0.0188\n",
            "Epoch [3/10], Step [340/1062], Loss: 0.0146\n",
            "Epoch [3/10], Step [350/1062], Loss: 0.1609\n",
            "Epoch [3/10], Step [360/1062], Loss: 0.0031\n",
            "Epoch [3/10], Step [370/1062], Loss: 0.0160\n",
            "Epoch [3/10], Step [380/1062], Loss: 0.0462\n",
            "Epoch [3/10], Step [390/1062], Loss: 0.0298\n",
            "Epoch [3/10], Step [400/1062], Loss: 0.0108\n",
            "Epoch [3/10], Step [410/1062], Loss: 0.0316\n",
            "Epoch [3/10], Step [420/1062], Loss: 0.1212\n",
            "Epoch [3/10], Step [430/1062], Loss: 0.0659\n",
            "Epoch [3/10], Step [440/1062], Loss: 0.0753\n",
            "Epoch [3/10], Step [450/1062], Loss: 0.1195\n",
            "Epoch [3/10], Step [460/1062], Loss: 0.0328\n",
            "Epoch [3/10], Step [470/1062], Loss: 0.0242\n",
            "Epoch [3/10], Step [480/1062], Loss: 0.0745\n",
            "Epoch [3/10], Step [490/1062], Loss: 0.0450\n",
            "Epoch [3/10], Step [500/1062], Loss: 0.0204\n",
            "Epoch [3/10], Step [510/1062], Loss: 0.0341\n",
            "Epoch [3/10], Step [520/1062], Loss: 0.1006\n",
            "Epoch [3/10], Step [530/1062], Loss: 0.0062\n",
            "Epoch [3/10], Step [540/1062], Loss: 0.0108\n",
            "Epoch [3/10], Step [550/1062], Loss: 0.0522\n",
            "Epoch [3/10], Step [560/1062], Loss: 0.1006\n",
            "Epoch [3/10], Step [570/1062], Loss: 0.1076\n",
            "Epoch [3/10], Step [580/1062], Loss: 0.0523\n",
            "Epoch [3/10], Step [590/1062], Loss: 0.0291\n",
            "Epoch [3/10], Step [600/1062], Loss: 0.0482\n",
            "Epoch [3/10], Step [610/1062], Loss: 0.0821\n",
            "Epoch [3/10], Step [620/1062], Loss: 0.1636\n",
            "Epoch [3/10], Step [630/1062], Loss: 0.0368\n",
            "Epoch [3/10], Step [640/1062], Loss: 0.0425\n",
            "Epoch [3/10], Step [650/1062], Loss: 0.0321\n",
            "Epoch [3/10], Step [660/1062], Loss: 0.0062\n",
            "Epoch [3/10], Step [670/1062], Loss: 0.0718\n",
            "Epoch [3/10], Step [680/1062], Loss: 0.1430\n",
            "Epoch [3/10], Step [690/1062], Loss: 0.0754\n",
            "Epoch [3/10], Step [700/1062], Loss: 0.1282\n",
            "Epoch [3/10], Step [710/1062], Loss: 0.1110\n",
            "Epoch [3/10], Step [720/1062], Loss: 0.1674\n",
            "Epoch [3/10], Step [730/1062], Loss: 0.0279\n",
            "Epoch [3/10], Step [740/1062], Loss: 0.0806\n",
            "Epoch [3/10], Step [750/1062], Loss: 0.0306\n",
            "Epoch [3/10], Step [760/1062], Loss: 0.0342\n",
            "Epoch [3/10], Step [770/1062], Loss: 0.0690\n",
            "Epoch [3/10], Step [780/1062], Loss: 0.0660\n",
            "Epoch [3/10], Step [790/1062], Loss: 0.0754\n",
            "Epoch [3/10], Step [800/1062], Loss: 0.1224\n",
            "Epoch [3/10], Step [810/1062], Loss: 0.1269\n",
            "Epoch [3/10], Step [820/1062], Loss: 0.1798\n",
            "Epoch [3/10], Step [830/1062], Loss: 0.0087\n",
            "Epoch [3/10], Step [840/1062], Loss: 0.0446\n",
            "Epoch [3/10], Step [850/1062], Loss: 0.0332\n",
            "Epoch [3/10], Step [860/1062], Loss: 0.0194\n",
            "Epoch [3/10], Step [870/1062], Loss: 0.0845\n",
            "Epoch [3/10], Step [880/1062], Loss: 0.0571\n",
            "Epoch [3/10], Step [890/1062], Loss: 0.0452\n",
            "Epoch [3/10], Step [900/1062], Loss: 0.0298\n",
            "Epoch [3/10], Step [910/1062], Loss: 0.0432\n",
            "Epoch [3/10], Step [920/1062], Loss: 0.0263\n",
            "Epoch [3/10], Step [930/1062], Loss: 0.0537\n",
            "Epoch [3/10], Step [940/1062], Loss: 0.0061\n",
            "Epoch [3/10], Step [950/1062], Loss: 0.0032\n",
            "Epoch [3/10], Step [960/1062], Loss: 0.0384\n",
            "Epoch [3/10], Step [970/1062], Loss: 0.0853\n",
            "Epoch [3/10], Step [980/1062], Loss: 0.0292\n",
            "Epoch [3/10], Step [990/1062], Loss: 0.1966\n",
            "Epoch [3/10], Step [1000/1062], Loss: 0.1614\n",
            "Epoch [3/10], Step [1010/1062], Loss: 0.0419\n",
            "Epoch [3/10], Step [1020/1062], Loss: 0.0777\n",
            "Epoch [3/10], Step [1030/1062], Loss: 0.0645\n",
            "Epoch [3/10], Step [1040/1062], Loss: 0.0054\n",
            "Epoch [3/10], Step [1050/1062], Loss: 0.0432\n",
            "Epoch [3/10], Step [1060/1062], Loss: 0.0404\n",
            "Epoch 3 average loss: 0.0651\n",
            "Accuracy on test set after epoch 3: 57.81%\n",
            "Epoch [4/10], Step [10/1062], Loss: 0.0110\n",
            "Epoch [4/10], Step [20/1062], Loss: 0.2603\n",
            "Epoch [4/10], Step [30/1062], Loss: 0.0901\n",
            "Epoch [4/10], Step [40/1062], Loss: 0.0277\n",
            "Epoch [4/10], Step [50/1062], Loss: 0.1291\n",
            "Epoch [4/10], Step [60/1062], Loss: 0.0970\n",
            "Epoch [4/10], Step [70/1062], Loss: 0.0193\n",
            "Epoch [4/10], Step [80/1062], Loss: 0.0924\n",
            "Epoch [4/10], Step [90/1062], Loss: 0.0967\n",
            "Epoch [4/10], Step [100/1062], Loss: 0.0047\n",
            "Epoch [4/10], Step [110/1062], Loss: 0.1052\n",
            "Epoch [4/10], Step [120/1062], Loss: 0.1367\n",
            "Epoch [4/10], Step [130/1062], Loss: 0.0450\n",
            "Epoch [4/10], Step [140/1062], Loss: 0.0874\n",
            "Epoch [4/10], Step [150/1062], Loss: 0.0356\n",
            "Epoch [4/10], Step [160/1062], Loss: 0.0029\n",
            "Epoch [4/10], Step [170/1062], Loss: 0.0370\n",
            "Epoch [4/10], Step [180/1062], Loss: 0.0785\n",
            "Epoch [4/10], Step [190/1062], Loss: 0.0233\n",
            "Epoch [4/10], Step [200/1062], Loss: 0.0855\n",
            "Epoch [4/10], Step [210/1062], Loss: 0.1612\n",
            "Epoch [4/10], Step [220/1062], Loss: 0.0194\n",
            "Epoch [4/10], Step [230/1062], Loss: 0.1167\n",
            "Epoch [4/10], Step [240/1062], Loss: 0.0244\n",
            "Epoch [4/10], Step [250/1062], Loss: 0.0086\n",
            "Epoch [4/10], Step [260/1062], Loss: 0.0629\n",
            "Epoch [4/10], Step [270/1062], Loss: 0.0556\n",
            "Epoch [4/10], Step [280/1062], Loss: 0.0956\n",
            "Epoch [4/10], Step [290/1062], Loss: 0.0182\n",
            "Epoch [4/10], Step [300/1062], Loss: 0.0720\n",
            "Epoch [4/10], Step [310/1062], Loss: 0.1603\n",
            "Epoch [4/10], Step [320/1062], Loss: 0.1617\n",
            "Epoch [4/10], Step [330/1062], Loss: 0.1792\n",
            "Epoch [4/10], Step [340/1062], Loss: 0.0314\n",
            "Epoch [4/10], Step [350/1062], Loss: 0.0061\n",
            "Epoch [4/10], Step [360/1062], Loss: 0.0207\n",
            "Epoch [4/10], Step [370/1062], Loss: 0.0092\n",
            "Epoch [4/10], Step [380/1062], Loss: 0.0283\n",
            "Epoch [4/10], Step [390/1062], Loss: 0.0784\n",
            "Epoch [4/10], Step [400/1062], Loss: 0.0460\n",
            "Epoch [4/10], Step [410/1062], Loss: 0.0412\n",
            "Epoch [4/10], Step [420/1062], Loss: 0.0130\n",
            "Epoch [4/10], Step [430/1062], Loss: 0.0529\n",
            "Epoch [4/10], Step [440/1062], Loss: 0.1133\n",
            "Epoch [4/10], Step [450/1062], Loss: 0.0801\n",
            "Epoch [4/10], Step [460/1062], Loss: 0.0074\n",
            "Epoch [4/10], Step [470/1062], Loss: 0.0775\n",
            "Epoch [4/10], Step [480/1062], Loss: 0.0291\n",
            "Epoch [4/10], Step [490/1062], Loss: 0.0290\n",
            "Epoch [4/10], Step [500/1062], Loss: 0.0183\n",
            "Epoch [4/10], Step [510/1062], Loss: 0.0017\n",
            "Epoch [4/10], Step [520/1062], Loss: 0.0016\n",
            "Epoch [4/10], Step [530/1062], Loss: 0.0987\n",
            "Epoch [4/10], Step [540/1062], Loss: 0.0155\n",
            "Epoch [4/10], Step [550/1062], Loss: 0.0081\n",
            "Epoch [4/10], Step [560/1062], Loss: 0.0682\n",
            "Epoch [4/10], Step [570/1062], Loss: 0.0099\n",
            "Epoch [4/10], Step [580/1062], Loss: 0.0274\n",
            "Epoch [4/10], Step [590/1062], Loss: 0.1066\n",
            "Epoch [4/10], Step [600/1062], Loss: 0.0780\n",
            "Epoch [4/10], Step [610/1062], Loss: 0.0145\n",
            "Epoch [4/10], Step [620/1062], Loss: 0.0094\n",
            "Epoch [4/10], Step [630/1062], Loss: 0.0487\n",
            "Epoch [4/10], Step [640/1062], Loss: 0.0207\n",
            "Epoch [4/10], Step [650/1062], Loss: 0.0423\n",
            "Epoch [4/10], Step [660/1062], Loss: 0.1568\n",
            "Epoch [4/10], Step [670/1062], Loss: 0.0144\n",
            "Epoch [4/10], Step [680/1062], Loss: 0.0244\n",
            "Epoch [4/10], Step [690/1062], Loss: 0.0492\n",
            "Epoch [4/10], Step [700/1062], Loss: 0.0053\n",
            "Epoch [4/10], Step [710/1062], Loss: 0.0018\n",
            "Epoch [4/10], Step [720/1062], Loss: 0.0189\n",
            "Epoch [4/10], Step [730/1062], Loss: 0.0308\n",
            "Epoch [4/10], Step [740/1062], Loss: 0.0143\n",
            "Epoch [4/10], Step [750/1062], Loss: 0.0090\n",
            "Epoch [4/10], Step [760/1062], Loss: 0.0190\n",
            "Epoch [4/10], Step [770/1062], Loss: 0.0285\n",
            "Epoch [4/10], Step [780/1062], Loss: 0.0036\n",
            "Epoch [4/10], Step [790/1062], Loss: 0.1145\n",
            "Epoch [4/10], Step [800/1062], Loss: 0.0102\n",
            "Epoch [4/10], Step [810/1062], Loss: 0.0030\n",
            "Epoch [4/10], Step [820/1062], Loss: 0.0085\n",
            "Epoch [4/10], Step [830/1062], Loss: 0.0141\n",
            "Epoch [4/10], Step [840/1062], Loss: 0.0124\n",
            "Epoch [4/10], Step [850/1062], Loss: 0.0259\n",
            "Epoch [4/10], Step [860/1062], Loss: 0.0061\n",
            "Epoch [4/10], Step [870/1062], Loss: 0.0020\n",
            "Epoch [4/10], Step [880/1062], Loss: 0.0304\n",
            "Epoch [4/10], Step [890/1062], Loss: 0.0192\n",
            "Epoch [4/10], Step [900/1062], Loss: 0.0631\n",
            "Epoch [4/10], Step [910/1062], Loss: 0.0074\n",
            "Epoch [4/10], Step [920/1062], Loss: 0.0105\n",
            "Epoch [4/10], Step [930/1062], Loss: 0.0184\n",
            "Epoch [4/10], Step [940/1062], Loss: 0.1727\n",
            "Epoch [4/10], Step [950/1062], Loss: 0.1367\n",
            "Epoch [4/10], Step [960/1062], Loss: 0.0188\n",
            "Epoch [4/10], Step [970/1062], Loss: 0.1573\n",
            "Epoch [4/10], Step [980/1062], Loss: 0.0685\n",
            "Epoch [4/10], Step [990/1062], Loss: 0.0979\n",
            "Epoch [4/10], Step [1000/1062], Loss: 0.0058\n",
            "Epoch [4/10], Step [1010/1062], Loss: 0.0290\n",
            "Epoch [4/10], Step [1020/1062], Loss: 0.1747\n",
            "Epoch [4/10], Step [1030/1062], Loss: 0.0600\n",
            "Epoch [4/10], Step [1040/1062], Loss: 0.0262\n",
            "Epoch [4/10], Step [1050/1062], Loss: 0.0180\n",
            "Epoch [4/10], Step [1060/1062], Loss: 0.0170\n",
            "Epoch 4 average loss: 0.0529\n",
            "Accuracy on test set after epoch 4: 59.29%\n",
            "Epoch [5/10], Step [10/1062], Loss: 0.0072\n",
            "Epoch [5/10], Step [20/1062], Loss: 0.0995\n",
            "Epoch [5/10], Step [30/1062], Loss: 0.0033\n",
            "Epoch [5/10], Step [40/1062], Loss: 0.0391\n",
            "Epoch [5/10], Step [50/1062], Loss: 0.0029\n",
            "Epoch [5/10], Step [60/1062], Loss: 0.0033\n",
            "Epoch [5/10], Step [70/1062], Loss: 0.0523\n",
            "Epoch [5/10], Step [80/1062], Loss: 0.0008\n",
            "Epoch [5/10], Step [90/1062], Loss: 0.0711\n",
            "Epoch [5/10], Step [100/1062], Loss: 0.1076\n",
            "Epoch [5/10], Step [110/1062], Loss: 0.0496\n",
            "Epoch [5/10], Step [120/1062], Loss: 0.0022\n",
            "Epoch [5/10], Step [130/1062], Loss: 0.0016\n",
            "Epoch [5/10], Step [140/1062], Loss: 0.0110\n",
            "Epoch [5/10], Step [150/1062], Loss: 0.0508\n",
            "Epoch [5/10], Step [160/1062], Loss: 0.0499\n",
            "Epoch [5/10], Step [170/1062], Loss: 0.0055\n",
            "Epoch [5/10], Step [180/1062], Loss: 0.0011\n",
            "Epoch [5/10], Step [190/1062], Loss: 0.1106\n",
            "Epoch [5/10], Step [200/1062], Loss: 0.0001\n",
            "Epoch [5/10], Step [210/1062], Loss: 0.0280\n",
            "Epoch [5/10], Step [220/1062], Loss: 0.1105\n",
            "Epoch [5/10], Step [230/1062], Loss: 0.0085\n",
            "Epoch [5/10], Step [240/1062], Loss: 0.0255\n",
            "Epoch [5/10], Step [250/1062], Loss: 0.1159\n",
            "Epoch [5/10], Step [260/1062], Loss: 0.0044\n",
            "Epoch [5/10], Step [270/1062], Loss: 0.0034\n",
            "Epoch [5/10], Step [280/1062], Loss: 0.0043\n",
            "Epoch [5/10], Step [290/1062], Loss: 0.0003\n",
            "Epoch [5/10], Step [300/1062], Loss: 0.3353\n",
            "Epoch [5/10], Step [310/1062], Loss: 0.0596\n",
            "Epoch [5/10], Step [320/1062], Loss: 0.0030\n",
            "Epoch [5/10], Step [330/1062], Loss: 0.0156\n",
            "Epoch [5/10], Step [340/1062], Loss: 0.0323\n",
            "Epoch [5/10], Step [350/1062], Loss: 0.0304\n",
            "Epoch [5/10], Step [360/1062], Loss: 0.0073\n",
            "Epoch [5/10], Step [370/1062], Loss: 0.0589\n",
            "Epoch [5/10], Step [380/1062], Loss: 0.2365\n",
            "Epoch [5/10], Step [390/1062], Loss: 0.0537\n",
            "Epoch [5/10], Step [400/1062], Loss: 0.0926\n",
            "Epoch [5/10], Step [410/1062], Loss: 0.0341\n",
            "Epoch [5/10], Step [420/1062], Loss: 0.0276\n",
            "Epoch [5/10], Step [430/1062], Loss: 0.1005\n",
            "Epoch [5/10], Step [440/1062], Loss: 0.0264\n",
            "Epoch [5/10], Step [450/1062], Loss: 0.0668\n",
            "Epoch [5/10], Step [460/1062], Loss: 0.0166\n",
            "Epoch [5/10], Step [470/1062], Loss: 0.0859\n",
            "Epoch [5/10], Step [480/1062], Loss: 0.0360\n",
            "Epoch [5/10], Step [490/1062], Loss: 0.0116\n",
            "Epoch [5/10], Step [500/1062], Loss: 0.0071\n",
            "Epoch [5/10], Step [510/1062], Loss: 0.0026\n",
            "Epoch [5/10], Step [520/1062], Loss: 0.1052\n",
            "Epoch [5/10], Step [530/1062], Loss: 0.1040\n",
            "Epoch [5/10], Step [540/1062], Loss: 0.0228\n",
            "Epoch [5/10], Step [550/1062], Loss: 0.0567\n",
            "Epoch [5/10], Step [560/1062], Loss: 0.0277\n",
            "Epoch [5/10], Step [570/1062], Loss: 0.0077\n",
            "Epoch [5/10], Step [580/1062], Loss: 0.0650\n",
            "Epoch [5/10], Step [590/1062], Loss: 0.0075\n",
            "Epoch [5/10], Step [600/1062], Loss: 0.0191\n",
            "Epoch [5/10], Step [610/1062], Loss: 0.1189\n",
            "Epoch [5/10], Step [620/1062], Loss: 0.0612\n",
            "Epoch [5/10], Step [630/1062], Loss: 0.0009\n",
            "Epoch [5/10], Step [640/1062], Loss: 0.1616\n",
            "Epoch [5/10], Step [650/1062], Loss: 0.0775\n",
            "Epoch [5/10], Step [660/1062], Loss: 0.1184\n",
            "Epoch [5/10], Step [670/1062], Loss: 0.0449\n",
            "Epoch [5/10], Step [680/1062], Loss: 0.0006\n",
            "Epoch [5/10], Step [690/1062], Loss: 0.0555\n",
            "Epoch [5/10], Step [700/1062], Loss: 0.0240\n",
            "Epoch [5/10], Step [710/1062], Loss: 0.0200\n",
            "Epoch [5/10], Step [720/1062], Loss: 0.0027\n",
            "Epoch [5/10], Step [730/1062], Loss: 0.0084\n",
            "Epoch [5/10], Step [740/1062], Loss: 0.0268\n",
            "Epoch [5/10], Step [750/1062], Loss: 0.0957\n",
            "Epoch [5/10], Step [760/1062], Loss: 0.0875\n",
            "Epoch [5/10], Step [770/1062], Loss: 0.0333\n",
            "Epoch [5/10], Step [780/1062], Loss: 0.0358\n",
            "Epoch [5/10], Step [790/1062], Loss: 0.0178\n",
            "Epoch [5/10], Step [800/1062], Loss: 0.0032\n",
            "Epoch [5/10], Step [810/1062], Loss: 0.0405\n",
            "Epoch [5/10], Step [820/1062], Loss: 0.0256\n",
            "Epoch [5/10], Step [830/1062], Loss: 0.0818\n",
            "Epoch [5/10], Step [840/1062], Loss: 0.0402\n",
            "Epoch [5/10], Step [850/1062], Loss: 0.0035\n",
            "Epoch [5/10], Step [860/1062], Loss: 0.0018\n",
            "Epoch [5/10], Step [870/1062], Loss: 0.0199\n",
            "Epoch [5/10], Step [880/1062], Loss: 0.0822\n",
            "Epoch [5/10], Step [890/1062], Loss: 0.0141\n",
            "Epoch [5/10], Step [900/1062], Loss: 0.0685\n",
            "Epoch [5/10], Step [910/1062], Loss: 0.0026\n",
            "Epoch [5/10], Step [920/1062], Loss: 0.0059\n",
            "Epoch [5/10], Step [930/1062], Loss: 0.0048\n",
            "Epoch [5/10], Step [940/1062], Loss: 0.0182\n",
            "Epoch [5/10], Step [950/1062], Loss: 0.0013\n",
            "Epoch [5/10], Step [960/1062], Loss: 0.0354\n",
            "Epoch [5/10], Step [970/1062], Loss: 0.0344\n",
            "Epoch [5/10], Step [980/1062], Loss: 0.0007\n",
            "Epoch [5/10], Step [990/1062], Loss: 0.0307\n",
            "Epoch [5/10], Step [1000/1062], Loss: 0.0364\n",
            "Epoch [5/10], Step [1010/1062], Loss: 0.0110\n",
            "Epoch [5/10], Step [1020/1062], Loss: 0.0134\n",
            "Epoch [5/10], Step [1030/1062], Loss: 0.0108\n",
            "Epoch [5/10], Step [1040/1062], Loss: 0.0302\n",
            "Epoch [5/10], Step [1050/1062], Loss: 0.0036\n",
            "Epoch [5/10], Step [1060/1062], Loss: 0.0134\n",
            "Epoch 5 average loss: 0.0472\n",
            "Accuracy on test set after epoch 5: 56.58%\n",
            "Epoch [6/10], Step [10/1062], Loss: 0.0098\n",
            "Epoch [6/10], Step [20/1062], Loss: 0.0237\n",
            "Epoch [6/10], Step [30/1062], Loss: 0.0031\n",
            "Epoch [6/10], Step [40/1062], Loss: 0.0449\n",
            "Epoch [6/10], Step [50/1062], Loss: 0.0612\n",
            "Epoch [6/10], Step [60/1062], Loss: 0.0289\n",
            "Epoch [6/10], Step [70/1062], Loss: 0.1992\n",
            "Epoch [6/10], Step [80/1062], Loss: 0.0029\n",
            "Epoch [6/10], Step [90/1062], Loss: 0.0967\n",
            "Epoch [6/10], Step [100/1062], Loss: 0.0099\n",
            "Epoch [6/10], Step [110/1062], Loss: 0.0086\n",
            "Epoch [6/10], Step [120/1062], Loss: 0.0022\n",
            "Epoch [6/10], Step [130/1062], Loss: 0.0017\n",
            "Epoch [6/10], Step [140/1062], Loss: 0.0556\n",
            "Epoch [6/10], Step [150/1062], Loss: 0.0135\n",
            "Epoch [6/10], Step [160/1062], Loss: 0.0564\n",
            "Epoch [6/10], Step [170/1062], Loss: 0.0084\n",
            "Epoch [6/10], Step [180/1062], Loss: 0.0363\n",
            "Epoch [6/10], Step [190/1062], Loss: 0.0051\n",
            "Epoch [6/10], Step [200/1062], Loss: 0.0148\n",
            "Epoch [6/10], Step [210/1062], Loss: 0.0196\n",
            "Epoch [6/10], Step [220/1062], Loss: 0.0013\n",
            "Epoch [6/10], Step [230/1062], Loss: 0.0494\n",
            "Epoch [6/10], Step [240/1062], Loss: 0.0158\n",
            "Epoch [6/10], Step [250/1062], Loss: 0.0097\n",
            "Epoch [6/10], Step [260/1062], Loss: 0.0796\n",
            "Epoch [6/10], Step [270/1062], Loss: 0.0245\n",
            "Epoch [6/10], Step [280/1062], Loss: 0.0652\n",
            "Epoch [6/10], Step [290/1062], Loss: 0.0019\n",
            "Epoch [6/10], Step [300/1062], Loss: 0.0108\n",
            "Epoch [6/10], Step [310/1062], Loss: 0.0060\n",
            "Epoch [6/10], Step [320/1062], Loss: 0.0094\n",
            "Epoch [6/10], Step [330/1062], Loss: 0.0625\n",
            "Epoch [6/10], Step [340/1062], Loss: 0.0030\n",
            "Epoch [6/10], Step [350/1062], Loss: 0.0865\n",
            "Epoch [6/10], Step [360/1062], Loss: 0.0361\n",
            "Epoch [6/10], Step [370/1062], Loss: 0.0474\n",
            "Epoch [6/10], Step [380/1062], Loss: 0.1025\n",
            "Epoch [6/10], Step [390/1062], Loss: 0.0335\n",
            "Epoch [6/10], Step [400/1062], Loss: 0.2422\n",
            "Epoch [6/10], Step [410/1062], Loss: 0.0256\n",
            "Epoch [6/10], Step [420/1062], Loss: 0.1437\n",
            "Epoch [6/10], Step [430/1062], Loss: 0.0230\n",
            "Epoch [6/10], Step [440/1062], Loss: 0.0167\n",
            "Epoch [6/10], Step [450/1062], Loss: 0.0291\n",
            "Epoch [6/10], Step [460/1062], Loss: 0.1046\n",
            "Epoch [6/10], Step [470/1062], Loss: 0.0124\n",
            "Epoch [6/10], Step [480/1062], Loss: 0.0092\n",
            "Epoch [6/10], Step [490/1062], Loss: 0.0076\n",
            "Epoch [6/10], Step [500/1062], Loss: 0.0049\n",
            "Epoch [6/10], Step [510/1062], Loss: 0.0635\n",
            "Epoch [6/10], Step [520/1062], Loss: 0.0924\n",
            "Epoch [6/10], Step [530/1062], Loss: 0.0377\n",
            "Epoch [6/10], Step [540/1062], Loss: 0.0339\n",
            "Epoch [6/10], Step [550/1062], Loss: 0.0220\n",
            "Epoch [6/10], Step [560/1062], Loss: 0.0102\n",
            "Epoch [6/10], Step [570/1062], Loss: 0.0524\n",
            "Epoch [6/10], Step [580/1062], Loss: 0.0007\n",
            "Epoch [6/10], Step [590/1062], Loss: 0.0005\n",
            "Epoch [6/10], Step [600/1062], Loss: 0.0369\n",
            "Epoch [6/10], Step [610/1062], Loss: 0.0248\n",
            "Epoch [6/10], Step [620/1062], Loss: 0.0326\n",
            "Epoch [6/10], Step [630/1062], Loss: 0.0594\n",
            "Epoch [6/10], Step [640/1062], Loss: 0.0100\n",
            "Epoch [6/10], Step [650/1062], Loss: 0.1143\n",
            "Epoch [6/10], Step [660/1062], Loss: 0.0157\n",
            "Epoch [6/10], Step [670/1062], Loss: 0.0263\n",
            "Epoch [6/10], Step [680/1062], Loss: 0.0267\n",
            "Epoch [6/10], Step [690/1062], Loss: 0.0017\n",
            "Epoch [6/10], Step [700/1062], Loss: 0.0145\n",
            "Epoch [6/10], Step [710/1062], Loss: 0.0671\n",
            "Epoch [6/10], Step [720/1062], Loss: 0.1356\n",
            "Epoch [6/10], Step [730/1062], Loss: 0.0047\n",
            "Epoch [6/10], Step [740/1062], Loss: 0.0056\n",
            "Epoch [6/10], Step [750/1062], Loss: 0.0287\n",
            "Epoch [6/10], Step [760/1062], Loss: 0.0287\n",
            "Epoch [6/10], Step [770/1062], Loss: 0.0005\n",
            "Epoch [6/10], Step [780/1062], Loss: 0.0138\n",
            "Epoch [6/10], Step [790/1062], Loss: 0.0991\n",
            "Epoch [6/10], Step [800/1062], Loss: 0.0389\n",
            "Epoch [6/10], Step [810/1062], Loss: 0.0030\n",
            "Epoch [6/10], Step [820/1062], Loss: 0.0351\n",
            "Epoch [6/10], Step [830/1062], Loss: 0.0153\n",
            "Epoch [6/10], Step [840/1062], Loss: 0.1172\n",
            "Epoch [6/10], Step [850/1062], Loss: 0.0218\n",
            "Epoch [6/10], Step [860/1062], Loss: 0.0413\n",
            "Epoch [6/10], Step [870/1062], Loss: 0.0400\n",
            "Epoch [6/10], Step [880/1062], Loss: 0.0246\n",
            "Epoch [6/10], Step [890/1062], Loss: 0.0159\n",
            "Epoch [6/10], Step [900/1062], Loss: 0.0408\n",
            "Epoch [6/10], Step [910/1062], Loss: 0.0530\n",
            "Epoch [6/10], Step [920/1062], Loss: 0.0700\n",
            "Epoch [6/10], Step [930/1062], Loss: 0.0142\n",
            "Epoch [6/10], Step [940/1062], Loss: 0.0014\n",
            "Epoch [6/10], Step [950/1062], Loss: 0.0264\n",
            "Epoch [6/10], Step [960/1062], Loss: 0.0092\n",
            "Epoch [6/10], Step [970/1062], Loss: 0.0447\n",
            "Epoch [6/10], Step [980/1062], Loss: 0.0250\n",
            "Epoch [6/10], Step [990/1062], Loss: 0.0323\n",
            "Epoch [6/10], Step [1000/1062], Loss: 0.0393\n",
            "Epoch [6/10], Step [1010/1062], Loss: 0.0225\n",
            "Epoch [6/10], Step [1020/1062], Loss: 0.0002\n",
            "Epoch [6/10], Step [1030/1062], Loss: 0.0080\n",
            "Epoch [6/10], Step [1040/1062], Loss: 0.0374\n",
            "Epoch [6/10], Step [1050/1062], Loss: 0.0127\n",
            "Epoch [6/10], Step [1060/1062], Loss: 0.0048\n",
            "Epoch 6 average loss: 0.0360\n",
            "Accuracy on test set after epoch 6: 53.02%\n",
            "Epoch [7/10], Step [10/1062], Loss: 0.0138\n",
            "Epoch [7/10], Step [20/1062], Loss: 0.0074\n",
            "Epoch [7/10], Step [30/1062], Loss: 0.0737\n",
            "Epoch [7/10], Step [40/1062], Loss: 0.0103\n",
            "Epoch [7/10], Step [50/1062], Loss: 0.0283\n",
            "Epoch [7/10], Step [60/1062], Loss: 0.0008\n",
            "Epoch [7/10], Step [70/1062], Loss: 0.0215\n",
            "Epoch [7/10], Step [80/1062], Loss: 0.0298\n",
            "Epoch [7/10], Step [90/1062], Loss: 0.0108\n",
            "Epoch [7/10], Step [100/1062], Loss: 0.0198\n",
            "Epoch [7/10], Step [110/1062], Loss: 0.0023\n",
            "Epoch [7/10], Step [120/1062], Loss: 0.0166\n",
            "Epoch [7/10], Step [130/1062], Loss: 0.0011\n",
            "Epoch [7/10], Step [140/1062], Loss: 0.0353\n",
            "Epoch [7/10], Step [150/1062], Loss: 0.0018\n",
            "Epoch [7/10], Step [160/1062], Loss: 0.0356\n",
            "Epoch [7/10], Step [170/1062], Loss: 0.0193\n",
            "Epoch [7/10], Step [180/1062], Loss: 0.0030\n",
            "Epoch [7/10], Step [190/1062], Loss: 0.0881\n",
            "Epoch [7/10], Step [200/1062], Loss: 0.0057\n",
            "Epoch [7/10], Step [210/1062], Loss: 0.0061\n",
            "Epoch [7/10], Step [220/1062], Loss: 0.0812\n",
            "Epoch [7/10], Step [230/1062], Loss: 0.1337\n",
            "Epoch [7/10], Step [240/1062], Loss: 0.0030\n",
            "Epoch [7/10], Step [250/1062], Loss: 0.0861\n",
            "Epoch [7/10], Step [260/1062], Loss: 0.0102\n",
            "Epoch [7/10], Step [270/1062], Loss: 0.0564\n",
            "Epoch [7/10], Step [280/1062], Loss: 0.0027\n",
            "Epoch [7/10], Step [290/1062], Loss: 0.0108\n",
            "Epoch [7/10], Step [300/1062], Loss: 0.0248\n",
            "Epoch [7/10], Step [310/1062], Loss: 0.0255\n",
            "Epoch [7/10], Step [320/1062], Loss: 0.0042\n",
            "Epoch [7/10], Step [330/1062], Loss: 0.0069\n",
            "Epoch [7/10], Step [340/1062], Loss: 0.0015\n",
            "Epoch [7/10], Step [350/1062], Loss: 0.0045\n",
            "Epoch [7/10], Step [360/1062], Loss: 0.0004\n",
            "Epoch [7/10], Step [370/1062], Loss: 0.0135\n",
            "Epoch [7/10], Step [380/1062], Loss: 0.0630\n",
            "Epoch [7/10], Step [390/1062], Loss: 0.0370\n",
            "Epoch [7/10], Step [400/1062], Loss: 0.0197\n",
            "Epoch [7/10], Step [410/1062], Loss: 0.0220\n",
            "Epoch [7/10], Step [420/1062], Loss: 0.0001\n",
            "Epoch [7/10], Step [430/1062], Loss: 0.0523\n",
            "Epoch [7/10], Step [440/1062], Loss: 0.0166\n",
            "Epoch [7/10], Step [450/1062], Loss: 0.0043\n",
            "Epoch [7/10], Step [460/1062], Loss: 0.0022\n",
            "Epoch [7/10], Step [470/1062], Loss: 0.0552\n",
            "Epoch [7/10], Step [480/1062], Loss: 0.0876\n",
            "Epoch [7/10], Step [490/1062], Loss: 0.0162\n",
            "Epoch [7/10], Step [500/1062], Loss: 0.0417\n",
            "Epoch [7/10], Step [510/1062], Loss: 0.0984\n",
            "Epoch [7/10], Step [520/1062], Loss: 0.0609\n",
            "Epoch [7/10], Step [530/1062], Loss: 0.0033\n",
            "Epoch [7/10], Step [540/1062], Loss: 0.0158\n",
            "Epoch [7/10], Step [550/1062], Loss: 0.0237\n",
            "Epoch [7/10], Step [560/1062], Loss: 0.0537\n",
            "Epoch [7/10], Step [570/1062], Loss: 0.0236\n",
            "Epoch [7/10], Step [580/1062], Loss: 0.0163\n",
            "Epoch [7/10], Step [590/1062], Loss: 0.0830\n",
            "Epoch [7/10], Step [600/1062], Loss: 0.0287\n",
            "Epoch [7/10], Step [610/1062], Loss: 0.0014\n",
            "Epoch [7/10], Step [620/1062], Loss: 0.2040\n",
            "Epoch [7/10], Step [630/1062], Loss: 0.0090\n",
            "Epoch [7/10], Step [640/1062], Loss: 0.0199\n",
            "Epoch [7/10], Step [650/1062], Loss: 0.0044\n",
            "Epoch [7/10], Step [660/1062], Loss: 0.0114\n",
            "Epoch [7/10], Step [670/1062], Loss: 0.0006\n",
            "Epoch [7/10], Step [680/1062], Loss: 0.0007\n",
            "Epoch [7/10], Step [690/1062], Loss: 0.0002\n",
            "Epoch [7/10], Step [700/1062], Loss: 0.0027\n",
            "Epoch [7/10], Step [710/1062], Loss: 0.0059\n",
            "Epoch [7/10], Step [720/1062], Loss: 0.0392\n",
            "Epoch [7/10], Step [730/1062], Loss: 0.0050\n",
            "Epoch [7/10], Step [740/1062], Loss: 0.0073\n",
            "Epoch [7/10], Step [750/1062], Loss: 0.0210\n",
            "Epoch [7/10], Step [760/1062], Loss: 0.0010\n",
            "Epoch [7/10], Step [770/1062], Loss: 0.0156\n",
            "Epoch [7/10], Step [780/1062], Loss: 0.0009\n",
            "Epoch [7/10], Step [790/1062], Loss: 0.0493\n",
            "Epoch [7/10], Step [800/1062], Loss: 0.0308\n",
            "Epoch [7/10], Step [810/1062], Loss: 0.0223\n",
            "Epoch [7/10], Step [820/1062], Loss: 0.0369\n",
            "Epoch [7/10], Step [830/1062], Loss: 0.0508\n",
            "Epoch [7/10], Step [840/1062], Loss: 0.0005\n",
            "Epoch [7/10], Step [850/1062], Loss: 0.0060\n",
            "Epoch [7/10], Step [860/1062], Loss: 0.0413\n",
            "Epoch [7/10], Step [870/1062], Loss: 0.0095\n",
            "Epoch [7/10], Step [880/1062], Loss: 0.0918\n",
            "Epoch [7/10], Step [890/1062], Loss: 0.0045\n",
            "Epoch [7/10], Step [900/1062], Loss: 0.0023\n",
            "Epoch [7/10], Step [910/1062], Loss: 0.0252\n",
            "Epoch [7/10], Step [920/1062], Loss: 0.0015\n",
            "Epoch [7/10], Step [930/1062], Loss: 0.0038\n",
            "Epoch [7/10], Step [940/1062], Loss: 0.0183\n",
            "Epoch [7/10], Step [950/1062], Loss: 0.0052\n",
            "Epoch [7/10], Step [960/1062], Loss: 0.0092\n",
            "Epoch [7/10], Step [970/1062], Loss: 0.0006\n",
            "Epoch [7/10], Step [980/1062], Loss: 0.0048\n",
            "Epoch [7/10], Step [990/1062], Loss: 0.0726\n",
            "Epoch [7/10], Step [1000/1062], Loss: 0.0455\n",
            "Epoch [7/10], Step [1010/1062], Loss: 0.1471\n",
            "Epoch [7/10], Step [1020/1062], Loss: 0.0018\n",
            "Epoch [7/10], Step [1030/1062], Loss: 0.1036\n",
            "Epoch [7/10], Step [1040/1062], Loss: 0.0011\n",
            "Epoch [7/10], Step [1050/1062], Loss: 0.0605\n",
            "Epoch [7/10], Step [1060/1062], Loss: 0.0157\n",
            "Epoch 7 average loss: 0.0345\n",
            "Accuracy on test set after epoch 7: 57.34%\n",
            "Epoch [8/10], Step [10/1062], Loss: 0.0947\n",
            "Epoch [8/10], Step [20/1062], Loss: 0.0279\n",
            "Epoch [8/10], Step [30/1062], Loss: 0.0036\n",
            "Epoch [8/10], Step [40/1062], Loss: 0.0117\n",
            "Epoch [8/10], Step [50/1062], Loss: 0.0289\n",
            "Epoch [8/10], Step [60/1062], Loss: 0.0056\n",
            "Epoch [8/10], Step [70/1062], Loss: 0.0468\n",
            "Epoch [8/10], Step [80/1062], Loss: 0.0147\n",
            "Epoch [8/10], Step [90/1062], Loss: 0.0687\n",
            "Epoch [8/10], Step [100/1062], Loss: 0.0048\n",
            "Epoch [8/10], Step [110/1062], Loss: 0.0211\n",
            "Epoch [8/10], Step [120/1062], Loss: 0.0204\n",
            "Epoch [8/10], Step [130/1062], Loss: 0.0318\n",
            "Epoch [8/10], Step [140/1062], Loss: 0.0421\n",
            "Epoch [8/10], Step [150/1062], Loss: 0.0053\n",
            "Epoch [8/10], Step [160/1062], Loss: 0.0345\n",
            "Epoch [8/10], Step [170/1062], Loss: 0.0001\n",
            "Epoch [8/10], Step [180/1062], Loss: 0.0574\n",
            "Epoch [8/10], Step [190/1062], Loss: 0.2203\n",
            "Epoch [8/10], Step [200/1062], Loss: 0.2997\n",
            "Epoch [8/10], Step [210/1062], Loss: 0.0778\n",
            "Epoch [8/10], Step [220/1062], Loss: 0.1074\n",
            "Epoch [8/10], Step [230/1062], Loss: 0.0687\n",
            "Epoch [8/10], Step [240/1062], Loss: 0.0338\n",
            "Epoch [8/10], Step [250/1062], Loss: 0.0144\n",
            "Epoch [8/10], Step [260/1062], Loss: 0.0111\n",
            "Epoch [8/10], Step [270/1062], Loss: 0.0101\n",
            "Epoch [8/10], Step [280/1062], Loss: 0.0895\n",
            "Epoch [8/10], Step [290/1062], Loss: 0.0020\n",
            "Epoch [8/10], Step [300/1062], Loss: 0.0340\n",
            "Epoch [8/10], Step [310/1062], Loss: 0.0471\n",
            "Epoch [8/10], Step [320/1062], Loss: 0.0018\n",
            "Epoch [8/10], Step [330/1062], Loss: 0.0240\n",
            "Epoch [8/10], Step [340/1062], Loss: 0.0621\n",
            "Epoch [8/10], Step [350/1062], Loss: 0.0011\n",
            "Epoch [8/10], Step [360/1062], Loss: 0.0194\n",
            "Epoch [8/10], Step [370/1062], Loss: 0.0026\n",
            "Epoch [8/10], Step [380/1062], Loss: 0.0377\n",
            "Epoch [8/10], Step [390/1062], Loss: 0.0306\n",
            "Epoch [8/10], Step [400/1062], Loss: 0.0337\n",
            "Epoch [8/10], Step [410/1062], Loss: 0.0069\n",
            "Epoch [8/10], Step [420/1062], Loss: 0.0133\n",
            "Epoch [8/10], Step [430/1062], Loss: 0.0257\n",
            "Epoch [8/10], Step [440/1062], Loss: 0.0260\n",
            "Epoch [8/10], Step [450/1062], Loss: 0.0297\n",
            "Epoch [8/10], Step [460/1062], Loss: 0.0092\n",
            "Epoch [8/10], Step [470/1062], Loss: 0.0773\n",
            "Epoch [8/10], Step [480/1062], Loss: 0.0240\n",
            "Epoch [8/10], Step [490/1062], Loss: 0.0002\n",
            "Epoch [8/10], Step [500/1062], Loss: 0.1033\n",
            "Epoch [8/10], Step [510/1062], Loss: 0.0269\n",
            "Epoch [8/10], Step [520/1062], Loss: 0.0009\n",
            "Epoch [8/10], Step [530/1062], Loss: 0.0578\n",
            "Epoch [8/10], Step [540/1062], Loss: 0.0013\n",
            "Epoch [8/10], Step [550/1062], Loss: 0.0269\n",
            "Epoch [8/10], Step [560/1062], Loss: 0.0022\n",
            "Epoch [8/10], Step [570/1062], Loss: 0.0230\n",
            "Epoch [8/10], Step [580/1062], Loss: 0.0004\n",
            "Epoch [8/10], Step [590/1062], Loss: 0.0083\n",
            "Epoch [8/10], Step [600/1062], Loss: 0.0032\n",
            "Epoch [8/10], Step [610/1062], Loss: 0.0029\n",
            "Epoch [8/10], Step [620/1062], Loss: 0.0016\n",
            "Epoch [8/10], Step [630/1062], Loss: 0.0645\n",
            "Epoch [8/10], Step [640/1062], Loss: 0.0097\n",
            "Epoch [8/10], Step [650/1062], Loss: 0.0069\n",
            "Epoch [8/10], Step [660/1062], Loss: 0.0527\n",
            "Epoch [8/10], Step [670/1062], Loss: 0.0307\n",
            "Epoch [8/10], Step [680/1062], Loss: 0.0780\n",
            "Epoch [8/10], Step [690/1062], Loss: 0.0618\n",
            "Epoch [8/10], Step [700/1062], Loss: 0.0064\n",
            "Epoch [8/10], Step [710/1062], Loss: 0.0608\n",
            "Epoch [8/10], Step [720/1062], Loss: 0.0039\n",
            "Epoch [8/10], Step [730/1062], Loss: 0.0650\n",
            "Epoch [8/10], Step [740/1062], Loss: 0.1053\n",
            "Epoch [8/10], Step [750/1062], Loss: 0.0136\n",
            "Epoch [8/10], Step [760/1062], Loss: 0.0146\n",
            "Epoch [8/10], Step [770/1062], Loss: 0.0147\n",
            "Epoch [8/10], Step [780/1062], Loss: 0.0094\n",
            "Epoch [8/10], Step [790/1062], Loss: 0.1212\n",
            "Epoch [8/10], Step [800/1062], Loss: 0.0502\n",
            "Epoch [8/10], Step [810/1062], Loss: 0.0003\n",
            "Epoch [8/10], Step [820/1062], Loss: 0.0271\n",
            "Epoch [8/10], Step [830/1062], Loss: 0.0703\n",
            "Epoch [8/10], Step [840/1062], Loss: 0.0153\n",
            "Epoch [8/10], Step [850/1062], Loss: 0.0050\n",
            "Epoch [8/10], Step [860/1062], Loss: 0.0007\n",
            "Epoch [8/10], Step [870/1062], Loss: 0.0117\n",
            "Epoch [8/10], Step [880/1062], Loss: 0.0723\n",
            "Epoch [8/10], Step [890/1062], Loss: 0.0314\n",
            "Epoch [8/10], Step [900/1062], Loss: 0.0103\n",
            "Epoch [8/10], Step [910/1062], Loss: 0.0005\n",
            "Epoch [8/10], Step [920/1062], Loss: 0.0014\n",
            "Epoch [8/10], Step [930/1062], Loss: 0.0032\n",
            "Epoch [8/10], Step [940/1062], Loss: 0.0094\n",
            "Epoch [8/10], Step [950/1062], Loss: 0.0089\n",
            "Epoch [8/10], Step [960/1062], Loss: 0.0007\n",
            "Epoch [8/10], Step [970/1062], Loss: 0.0093\n",
            "Epoch [8/10], Step [980/1062], Loss: 0.0030\n",
            "Epoch [8/10], Step [990/1062], Loss: 0.0323\n",
            "Epoch [8/10], Step [1000/1062], Loss: 0.0587\n",
            "Epoch [8/10], Step [1010/1062], Loss: 0.0058\n",
            "Epoch [8/10], Step [1020/1062], Loss: 0.0016\n",
            "Epoch [8/10], Step [1030/1062], Loss: 0.0306\n",
            "Epoch [8/10], Step [1040/1062], Loss: 0.0057\n",
            "Epoch [8/10], Step [1050/1062], Loss: 0.0109\n",
            "Epoch [8/10], Step [1060/1062], Loss: 0.0481\n",
            "Epoch 8 average loss: 0.0354\n",
            "Accuracy on test set after epoch 8: 56.02%\n",
            "Epoch [9/10], Step [10/1062], Loss: 0.2259\n",
            "Epoch [9/10], Step [20/1062], Loss: 0.0158\n",
            "Epoch [9/10], Step [30/1062], Loss: 0.0369\n",
            "Epoch [9/10], Step [40/1062], Loss: 0.0324\n",
            "Epoch [9/10], Step [50/1062], Loss: 0.0009\n",
            "Epoch [9/10], Step [60/1062], Loss: 0.0671\n",
            "Epoch [9/10], Step [70/1062], Loss: 0.0265\n",
            "Epoch [9/10], Step [80/1062], Loss: 0.0515\n",
            "Epoch [9/10], Step [90/1062], Loss: 0.0138\n",
            "Epoch [9/10], Step [100/1062], Loss: 0.0388\n",
            "Epoch [9/10], Step [110/1062], Loss: 0.1335\n",
            "Epoch [9/10], Step [120/1062], Loss: 0.0094\n",
            "Epoch [9/10], Step [130/1062], Loss: 0.0296\n",
            "Epoch [9/10], Step [140/1062], Loss: 0.0220\n",
            "Epoch [9/10], Step [150/1062], Loss: 0.0047\n",
            "Epoch [9/10], Step [160/1062], Loss: 0.0036\n",
            "Epoch [9/10], Step [170/1062], Loss: 0.0086\n",
            "Epoch [9/10], Step [180/1062], Loss: 0.0081\n",
            "Epoch [9/10], Step [190/1062], Loss: 0.0454\n",
            "Epoch [9/10], Step [200/1062], Loss: 0.0097\n",
            "Epoch [9/10], Step [210/1062], Loss: 0.0016\n",
            "Epoch [9/10], Step [220/1062], Loss: 0.0386\n",
            "Epoch [9/10], Step [230/1062], Loss: 0.0292\n",
            "Epoch [9/10], Step [240/1062], Loss: 0.0008\n",
            "Epoch [9/10], Step [250/1062], Loss: 0.0873\n",
            "Epoch [9/10], Step [260/1062], Loss: 0.0052\n",
            "Epoch [9/10], Step [270/1062], Loss: 0.0009\n",
            "Epoch [9/10], Step [280/1062], Loss: 0.0096\n",
            "Epoch [9/10], Step [290/1062], Loss: 0.0011\n",
            "Epoch [9/10], Step [300/1062], Loss: 0.0000\n",
            "Epoch [9/10], Step [310/1062], Loss: 0.0015\n",
            "Epoch [9/10], Step [320/1062], Loss: 0.0007\n",
            "Epoch [9/10], Step [330/1062], Loss: 0.0006\n",
            "Epoch [9/10], Step [340/1062], Loss: 0.0345\n",
            "Epoch [9/10], Step [350/1062], Loss: 0.0598\n",
            "Epoch [9/10], Step [360/1062], Loss: 0.0968\n",
            "Epoch [9/10], Step [370/1062], Loss: 0.1763\n",
            "Epoch [9/10], Step [380/1062], Loss: 0.0124\n",
            "Epoch [9/10], Step [390/1062], Loss: 0.0006\n",
            "Epoch [9/10], Step [400/1062], Loss: 0.0282\n",
            "Epoch [9/10], Step [410/1062], Loss: 0.0679\n",
            "Epoch [9/10], Step [420/1062], Loss: 0.0528\n",
            "Epoch [9/10], Step [430/1062], Loss: 0.0040\n",
            "Epoch [9/10], Step [440/1062], Loss: 0.0119\n",
            "Epoch [9/10], Step [450/1062], Loss: 0.0389\n",
            "Epoch [9/10], Step [460/1062], Loss: 0.0010\n",
            "Epoch [9/10], Step [470/1062], Loss: 0.0392\n",
            "Epoch [9/10], Step [480/1062], Loss: 0.0223\n",
            "Epoch [9/10], Step [490/1062], Loss: 0.0014\n",
            "Epoch [9/10], Step [500/1062], Loss: 0.0033\n",
            "Epoch [9/10], Step [510/1062], Loss: 0.0045\n",
            "Epoch [9/10], Step [520/1062], Loss: 0.0025\n",
            "Epoch [9/10], Step [530/1062], Loss: 0.0001\n",
            "Epoch [9/10], Step [540/1062], Loss: 0.0010\n",
            "Epoch [9/10], Step [550/1062], Loss: 0.0731\n",
            "Epoch [9/10], Step [560/1062], Loss: 0.0192\n",
            "Epoch [9/10], Step [570/1062], Loss: 0.0446\n",
            "Epoch [9/10], Step [580/1062], Loss: 0.0023\n",
            "Epoch [9/10], Step [590/1062], Loss: 0.0108\n",
            "Epoch [9/10], Step [600/1062], Loss: 0.0014\n",
            "Epoch [9/10], Step [610/1062], Loss: 0.0019\n",
            "Epoch [9/10], Step [620/1062], Loss: 0.0510\n",
            "Epoch [9/10], Step [630/1062], Loss: 0.0045\n",
            "Epoch [9/10], Step [640/1062], Loss: 0.0005\n",
            "Epoch [9/10], Step [650/1062], Loss: 0.0715\n",
            "Epoch [9/10], Step [660/1062], Loss: 0.0005\n",
            "Epoch [9/10], Step [670/1062], Loss: 0.0542\n",
            "Epoch [9/10], Step [680/1062], Loss: 0.0077\n",
            "Epoch [9/10], Step [690/1062], Loss: 0.2041\n",
            "Epoch [9/10], Step [700/1062], Loss: 0.0158\n",
            "Epoch [9/10], Step [710/1062], Loss: 0.0007\n",
            "Epoch [9/10], Step [720/1062], Loss: 0.0113\n",
            "Epoch [9/10], Step [730/1062], Loss: 0.0008\n",
            "Epoch [9/10], Step [740/1062], Loss: 0.0537\n",
            "Epoch [9/10], Step [750/1062], Loss: 0.0394\n",
            "Epoch [9/10], Step [760/1062], Loss: 0.0564\n",
            "Epoch [9/10], Step [770/1062], Loss: 0.0006\n",
            "Epoch [9/10], Step [780/1062], Loss: 0.0002\n",
            "Epoch [9/10], Step [790/1062], Loss: 0.0178\n",
            "Epoch [9/10], Step [800/1062], Loss: 0.0010\n",
            "Epoch [9/10], Step [810/1062], Loss: 0.0036\n",
            "Epoch [9/10], Step [820/1062], Loss: 0.0465\n",
            "Epoch [9/10], Step [830/1062], Loss: 0.0427\n",
            "Epoch [9/10], Step [840/1062], Loss: 0.0544\n",
            "Epoch [9/10], Step [850/1062], Loss: 0.0181\n",
            "Epoch [9/10], Step [860/1062], Loss: 0.0012\n",
            "Epoch [9/10], Step [870/1062], Loss: 0.0004\n",
            "Epoch [9/10], Step [880/1062], Loss: 0.0233\n",
            "Epoch [9/10], Step [890/1062], Loss: 0.0002\n",
            "Epoch [9/10], Step [900/1062], Loss: 0.0039\n",
            "Epoch [9/10], Step [910/1062], Loss: 0.0043\n",
            "Epoch [9/10], Step [920/1062], Loss: 0.0029\n",
            "Epoch [9/10], Step [930/1062], Loss: 0.0049\n",
            "Epoch [9/10], Step [940/1062], Loss: 0.0008\n",
            "Epoch [9/10], Step [950/1062], Loss: 0.0300\n",
            "Epoch [9/10], Step [960/1062], Loss: 0.0086\n",
            "Epoch [9/10], Step [970/1062], Loss: 0.0076\n",
            "Epoch [9/10], Step [980/1062], Loss: 0.0000\n",
            "Epoch [9/10], Step [990/1062], Loss: 0.0085\n",
            "Epoch [9/10], Step [1000/1062], Loss: 0.0054\n",
            "Epoch [9/10], Step [1010/1062], Loss: 0.0666\n",
            "Epoch [9/10], Step [1020/1062], Loss: 0.0057\n",
            "Epoch [9/10], Step [1030/1062], Loss: 0.0112\n",
            "Epoch [9/10], Step [1040/1062], Loss: 0.0004\n",
            "Epoch [9/10], Step [1050/1062], Loss: 0.0032\n",
            "Epoch [9/10], Step [1060/1062], Loss: 0.0585\n",
            "Epoch 9 average loss: 0.0251\n",
            "Accuracy on test set after epoch 9: 56.64%\n",
            "Epoch [10/10], Step [10/1062], Loss: 0.0473\n",
            "Epoch [10/10], Step [20/1062], Loss: 0.0012\n",
            "Epoch [10/10], Step [30/1062], Loss: 0.2187\n",
            "Epoch [10/10], Step [40/1062], Loss: 0.0042\n",
            "Epoch [10/10], Step [50/1062], Loss: 0.0012\n",
            "Epoch [10/10], Step [60/1062], Loss: 0.0184\n",
            "Epoch [10/10], Step [70/1062], Loss: 0.1445\n",
            "Epoch [10/10], Step [80/1062], Loss: 0.0200\n",
            "Epoch [10/10], Step [90/1062], Loss: 0.0147\n",
            "Epoch [10/10], Step [100/1062], Loss: 0.0047\n",
            "Epoch [10/10], Step [110/1062], Loss: 0.0914\n",
            "Epoch [10/10], Step [120/1062], Loss: 0.0052\n",
            "Epoch [10/10], Step [130/1062], Loss: 0.0000\n",
            "Epoch [10/10], Step [140/1062], Loss: 0.0745\n",
            "Epoch [10/10], Step [150/1062], Loss: 0.0067\n",
            "Epoch [10/10], Step [160/1062], Loss: 0.0121\n",
            "Epoch [10/10], Step [170/1062], Loss: 0.0303\n",
            "Epoch [10/10], Step [180/1062], Loss: 0.0574\n",
            "Epoch [10/10], Step [190/1062], Loss: 0.0217\n",
            "Epoch [10/10], Step [200/1062], Loss: 0.0002\n",
            "Epoch [10/10], Step [210/1062], Loss: 0.0053\n",
            "Epoch [10/10], Step [220/1062], Loss: 0.0191\n",
            "Epoch [10/10], Step [230/1062], Loss: 0.0407\n",
            "Epoch [10/10], Step [240/1062], Loss: 0.0088\n",
            "Epoch [10/10], Step [250/1062], Loss: 0.0122\n",
            "Epoch [10/10], Step [260/1062], Loss: 0.0019\n",
            "Epoch [10/10], Step [270/1062], Loss: 0.1218\n",
            "Epoch [10/10], Step [280/1062], Loss: 0.0278\n",
            "Epoch [10/10], Step [290/1062], Loss: 0.0058\n",
            "Epoch [10/10], Step [300/1062], Loss: 0.0003\n",
            "Epoch [10/10], Step [310/1062], Loss: 0.1285\n",
            "Epoch [10/10], Step [320/1062], Loss: 0.0186\n",
            "Epoch [10/10], Step [330/1062], Loss: 0.0016\n",
            "Epoch [10/10], Step [340/1062], Loss: 0.0748\n",
            "Epoch [10/10], Step [350/1062], Loss: 0.0066\n",
            "Epoch [10/10], Step [360/1062], Loss: 0.0006\n",
            "Epoch [10/10], Step [370/1062], Loss: 0.1619\n",
            "Epoch [10/10], Step [380/1062], Loss: 0.0147\n",
            "Epoch [10/10], Step [390/1062], Loss: 0.0061\n",
            "Epoch [10/10], Step [400/1062], Loss: 0.0314\n",
            "Epoch [10/10], Step [410/1062], Loss: 0.0214\n",
            "Epoch [10/10], Step [420/1062], Loss: 0.0022\n",
            "Epoch [10/10], Step [430/1062], Loss: 0.0019\n",
            "Epoch [10/10], Step [440/1062], Loss: 0.1016\n",
            "Epoch [10/10], Step [450/1062], Loss: 0.0145\n",
            "Epoch [10/10], Step [460/1062], Loss: 0.0438\n",
            "Epoch [10/10], Step [470/1062], Loss: 0.0003\n",
            "Epoch [10/10], Step [480/1062], Loss: 0.0192\n",
            "Epoch [10/10], Step [490/1062], Loss: 0.0017\n",
            "Epoch [10/10], Step [500/1062], Loss: 0.0164\n",
            "Epoch [10/10], Step [510/1062], Loss: 0.0005\n",
            "Epoch [10/10], Step [520/1062], Loss: 0.0071\n",
            "Epoch [10/10], Step [530/1062], Loss: 0.0580\n",
            "Epoch [10/10], Step [540/1062], Loss: 0.0386\n",
            "Epoch [10/10], Step [550/1062], Loss: 0.0071\n",
            "Epoch [10/10], Step [560/1062], Loss: 0.0064\n",
            "Epoch [10/10], Step [570/1062], Loss: 0.0393\n",
            "Epoch [10/10], Step [580/1062], Loss: 0.0068\n",
            "Epoch [10/10], Step [590/1062], Loss: 0.1002\n",
            "Epoch [10/10], Step [600/1062], Loss: 0.2511\n",
            "Epoch [10/10], Step [610/1062], Loss: 0.0802\n",
            "Epoch [10/10], Step [620/1062], Loss: 0.0037\n",
            "Epoch [10/10], Step [630/1062], Loss: 0.0139\n",
            "Epoch [10/10], Step [640/1062], Loss: 0.0209\n",
            "Epoch [10/10], Step [650/1062], Loss: 0.0197\n",
            "Epoch [10/10], Step [660/1062], Loss: 0.0015\n",
            "Epoch [10/10], Step [670/1062], Loss: 0.0022\n",
            "Epoch [10/10], Step [680/1062], Loss: 0.0964\n",
            "Epoch [10/10], Step [690/1062], Loss: 0.0064\n",
            "Epoch [10/10], Step [700/1062], Loss: 0.0043\n",
            "Epoch [10/10], Step [710/1062], Loss: 0.1042\n",
            "Epoch [10/10], Step [720/1062], Loss: 0.0232\n",
            "Epoch [10/10], Step [730/1062], Loss: 0.0840\n",
            "Epoch [10/10], Step [740/1062], Loss: 0.0020\n",
            "Epoch [10/10], Step [750/1062], Loss: 0.0068\n",
            "Epoch [10/10], Step [760/1062], Loss: 0.1100\n",
            "Epoch [10/10], Step [770/1062], Loss: 0.0180\n",
            "Epoch [10/10], Step [780/1062], Loss: 0.0018\n",
            "Epoch [10/10], Step [790/1062], Loss: 0.0635\n",
            "Epoch [10/10], Step [800/1062], Loss: 0.0000\n",
            "Epoch [10/10], Step [810/1062], Loss: 0.0009\n",
            "Epoch [10/10], Step [820/1062], Loss: 0.0034\n",
            "Epoch [10/10], Step [830/1062], Loss: 0.0020\n",
            "Epoch [10/10], Step [840/1062], Loss: 0.0230\n",
            "Epoch [10/10], Step [850/1062], Loss: 0.0060\n",
            "Epoch [10/10], Step [860/1062], Loss: 0.1572\n",
            "Epoch [10/10], Step [870/1062], Loss: 0.0231\n",
            "Epoch [10/10], Step [880/1062], Loss: 0.0001\n",
            "Epoch [10/10], Step [890/1062], Loss: 0.0000\n",
            "Epoch [10/10], Step [900/1062], Loss: 0.0001\n",
            "Epoch [10/10], Step [910/1062], Loss: 0.0012\n",
            "Epoch [10/10], Step [920/1062], Loss: 0.0070\n",
            "Epoch [10/10], Step [930/1062], Loss: 0.0415\n",
            "Epoch [10/10], Step [940/1062], Loss: 0.0274\n",
            "Epoch [10/10], Step [950/1062], Loss: 0.0112\n",
            "Epoch [10/10], Step [960/1062], Loss: 0.0069\n",
            "Epoch [10/10], Step [970/1062], Loss: 0.0013\n",
            "Epoch [10/10], Step [980/1062], Loss: 0.0001\n",
            "Epoch [10/10], Step [990/1062], Loss: 0.0030\n",
            "Epoch [10/10], Step [1000/1062], Loss: 0.0071\n",
            "Epoch [10/10], Step [1010/1062], Loss: 0.0020\n",
            "Epoch [10/10], Step [1020/1062], Loss: 0.0216\n",
            "Epoch [10/10], Step [1030/1062], Loss: 0.0002\n",
            "Epoch [10/10], Step [1040/1062], Loss: 0.0057\n",
            "Epoch [10/10], Step [1050/1062], Loss: 0.0003\n",
            "Epoch [10/10], Step [1060/1062], Loss: 0.0015\n",
            "Epoch 10 average loss: 0.0269\n",
            "Accuracy on test set after epoch 10: 55.61%\n",
            "2D CNN Training finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler # StandardScaler might not be suitable for this spatial approach\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# --- User-Defined Parameters ---\n",
        "ORIGINAL_FRAME_WIDTH = 1440\n",
        "ORIGINAL_FRAME_HEIGHT = 1080\n",
        "\n",
        "\n",
        "# --- Parameters for Spatial Pose Image Representation ---\n",
        "n_in_steps = 30  # Sequence length (will be number of CHANNELS for 2D CNN input)\n",
        "GRID_H = 64      # Height of the spatial grid for each pose\n",
        "GRID_W = 64      # Width of the spatial grid for each pose\n",
        "\n",
        "print(f\"Original frame dimensions: {ORIGINAL_FRAME_WIDTH}x{ORIGINAL_FRAME_HEIGHT}\")\n",
        "print(f\"Input to 2D CNN will be (Batch, Channels={n_in_steps}, Height={GRID_H}, Width={GRID_W})\")\n",
        "\n",
        "# --- 2. Split video IDs for training and testing ---\n",
        "if 'source_video' not in baby_df.columns:\n",
        "    raise ValueError(\"DataFrame must contain 'source_video' column for splitting.\")\n",
        "unique_videos = baby_df['source_video'].unique()\n",
        "\n",
        "train_videos = np.array([])\n",
        "test_videos = np.array([])\n",
        "\n",
        "if len(unique_videos) < 2:\n",
        "    print(\"Warning: Too few unique videos for video-based train/test split.\")\n",
        "    if len(unique_videos) == 1:\n",
        "        print(\"Only one unique video found. Using all data for training, empty test set.\")\n",
        "        train_videos = unique_videos\n",
        "    else:\n",
        "        print(\"Error: No unique videos found. Cannot proceed.\")\n",
        "        exit()\n",
        "else:\n",
        "    train_videos, test_videos = train_test_split(unique_videos, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Total unique videos: {len(unique_videos)}\")\n",
        "print(f\"Training videos: {list(train_videos)}, Count: {len(train_videos)}\")\n",
        "print(f\"Testing videos: {list(test_videos)}, Count: {len(test_videos)}\")\n",
        "\n",
        "\n",
        "# --- 3. Scaler (Commented Out - Per-pose normalization is now handled in step 4) ---\n",
        "print(\"Skipping global StandardScaler. Per-pose normalization/scaling to grid is applied during sequence preparation.\")\n",
        "\n",
        "\n",
        "# --- 4. Prepare Sequences for 2D CNN (Spatial Pose Images) ---\n",
        "X_train_list, y_train_list = [], []\n",
        "X_test_list, y_test_list = [], []\n",
        "\n",
        "videos_to_assign_to_train = train_videos\n",
        "videos_to_assign_to_test = test_videos\n",
        "\n",
        "print(\"Preparing sequences as spatial pose images for 2D CNN...\")\n",
        "for video_id in unique_videos:\n",
        "    video_df = baby_df[baby_df['source_video'] == video_id]\n",
        "    for tid in video_df['tracking_id'].unique():\n",
        "        person_df = video_df[(video_df['tracking_id'] == tid) & (video_df['source_video'] == video_id)].copy()\n",
        "        person_df = person_df.sort_values('sec')\n",
        "\n",
        "        if len(person_df) < n_in_steps:\n",
        "            continue\n",
        "\n",
        "        # Keypoint data for this person: shape (num_timesteps_for_person, num_original_features)\n",
        "        kp_data_all_timesteps = person_df[keypoint_cols].values\n",
        "        label_data = person_df[target_column].values\n",
        "\n",
        "        num_sequences_possible = len(kp_data_all_timesteps) - n_in_steps + 1\n",
        "        if num_sequences_possible <= 0:\n",
        "            continue\n",
        "\n",
        "        current_X_sequences_list_for_person = []\n",
        "        current_y_sequences_list_for_person = []\n",
        "\n",
        "        for i in range(num_sequences_possible):\n",
        "            # Get the window of n_in_steps for keypoint data\n",
        "            # Shape: (n_in_steps, num_original_features), where num_original_features = 17*2 = 34\n",
        "            raw_kp_sequence = kp_data_all_timesteps[i : i + n_in_steps]\n",
        "\n",
        "            # Create the multi-channel 2D \"image\" for the sequence\n",
        "            # Shape: (n_in_steps_as_channels, GRID_H, GRID_W)\n",
        "            sequence_as_spatial_image = np.zeros((n_in_steps, GRID_H, GRID_W), dtype=np.float32)\n",
        "\n",
        "            for t_idx in range(n_in_steps): # Iterate through each time step in the sequence\n",
        "                # features_at_t has shape (num_original_features), e.g., (kp0_x, kp0_y, kp1_x, kp1_y, ...)\n",
        "                features_at_t = raw_kp_sequence[t_idx, :]\n",
        "\n",
        "                # This grid will represent the pose at the current time step t_idx\n",
        "                current_timestep_grid = np.zeros((GRID_H, GRID_W), dtype=np.float32)\n",
        "\n",
        "                for kp_i in range(int(17)): # Iterate through 17 keypoints\n",
        "                    kp_x_original = features_at_t[kp_i * 2]     # Absolute pixel coordinate X\n",
        "                    kp_y_original = features_at_t[kp_i * 2 + 1] # Absolute pixel coordinate Y\n",
        "\n",
        "                    if pd.isna(kp_x_original) or pd.isna(kp_y_original):\n",
        "                        continue # Skip NaN coordinates\n",
        "\n",
        "                    # Normalize keypoint coordinates to [0, 1] range based on original frame dimensions\n",
        "                    kp_x_normalized = kp_x_original / ORIGINAL_FRAME_WIDTH\n",
        "                    kp_y_normalized = kp_y_original / ORIGINAL_FRAME_HEIGHT\n",
        "\n",
        "                    # Scale normalized coordinates to the grid dimensions and clip\n",
        "                    grid_x = int(np.clip(kp_x_normalized * (GRID_W - 1), 0, GRID_W - 1))\n",
        "                    grid_y = int(np.clip(kp_y_normalized * (GRID_H - 1), 0, GRID_H - 1))\n",
        "\n",
        "                    current_timestep_grid[grid_y, grid_x] = 1.0 # Mark keypoint presence\n",
        "\n",
        "                sequence_as_spatial_image[t_idx, :, :] = current_timestep_grid\n",
        "\n",
        "            current_X_sequences_list_for_person.append(sequence_as_spatial_image) # Shape (n_in_steps, GRID_H, GRID_W)\n",
        "            current_y_sequences_list_for_person.append(label_data[i + n_in_steps - 1])\n",
        "\n",
        "        if not current_X_sequences_list_for_person:\n",
        "            continue\n",
        "\n",
        "        # Stack sequences for this person. Each item is (n_in_steps, GRID_H, GRID_W)\n",
        "        # Resulting X_person_sequences shape: (num_person_sequences, n_in_steps_as_channels, GRID_H, GRID_W)\n",
        "        X_person_sequences = np.stack(current_X_sequences_list_for_person, axis=0)\n",
        "        y_person_sequences = np.array(current_y_sequences_list_for_person)\n",
        "\n",
        "        if video_id in videos_to_assign_to_train:\n",
        "            X_train_list.append(X_person_sequences)\n",
        "            y_train_list.append(y_person_sequences)\n",
        "        elif video_id in videos_to_assign_to_test:\n",
        "            X_test_list.append(X_person_sequences)\n",
        "            y_test_list.append(y_person_sequences)\n",
        "\n",
        "# --- 5. Final Train/Test Arrays ---\n",
        "# Expected shape: (N_total_sequences, n_in_steps_as_channels, GRID_H, GRID_W)\n",
        "if X_train_list:\n",
        "    X_train = np.concatenate(X_train_list, axis=0)\n",
        "    y_train = np.concatenate(y_train_list, axis=0).astype(np.int64)\n",
        "else:\n",
        "    X_train = np.empty((0, n_in_steps, GRID_H, GRID_W), dtype=np.float32)\n",
        "    y_train = np.array([], dtype=np.int64)\n",
        "\n",
        "if X_test_list:\n",
        "    X_test = np.concatenate(X_test_list, axis=0)\n",
        "    y_test = np.concatenate(y_test_list, axis=0).astype(np.int64)\n",
        "else:\n",
        "    X_test = np.empty((0, n_in_steps, GRID_H, GRID_W), dtype=np.float32)\n",
        "    y_test = np.array([], dtype=np.int64)\n",
        "\n",
        "print(\"✅ Train/test data prepared for 2D CNN (spatial pose images).\")\n",
        "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape) # Should be (N, n_in_steps, GRID_H, GRID_W)\n",
        "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)\n",
        "\n",
        "num_classes = 0\n",
        "if y_train.size > 0:\n",
        "    unique_train_labels = np.unique(y_train)\n",
        "    num_classes = len(unique_train_labels)\n",
        "    print(f\"Number of unique classes in y_train: {num_classes}\")\n",
        "    print(f\"Unique y_train labels: {unique_train_labels}\")\n",
        "elif y_test.size > 0:\n",
        "    unique_test_labels = np.unique(y_test)\n",
        "    num_classes = len(unique_test_labels)\n",
        "    print(f\"Warning: y_train is empty. Using y_test to determine num_classes: {num_classes}\")\n",
        "    print(f\"Unique y_test labels: {unique_test_labels}\")\n",
        "else:\n",
        "    print(\"Error: Both y_train and y_test are empty. Cannot determine num_classes.\")\n",
        "    exit()\n",
        "\n",
        "if num_classes <= 1 and (X_train.size > 0 or X_test.size > 0) :\n",
        "    print(f\"Error: num_classes is {num_classes}. Need at least 2 classes for classification.\")\n",
        "    exit()\n",
        "if num_classes == 0:\n",
        "    print(\"Error: num_classes is 0. No data available.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# --- 6. Define Adapted 2D CNN Model for Spatial Pose Images ---\n",
        "class AlexNet2D_SpatialPose(nn.Module):\n",
        "    # input_channels will now be n_in_steps\n",
        "    def __init__(self, num_classes, input_channels, input_h, input_w):\n",
        "        super(AlexNet2D_SpatialPose, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Input: (N, C_in=n_in_steps, H_in=GRID_H, W_in=GRID_W)\n",
        "            # Example: (N, 30, 64, 64)\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=3, padding=1), # Keep H, W same\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # H, W become GRID_H/2, GRID_W/2 (e.g., 32x32)\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # H, W become GRID_H/4, GRID_W/4 (e.g., 16x16)\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(256),\n",
        "            # Optional: another conv/pool layer if GRID_H/W are large enough\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # H, W become GRID_H/8, GRID_W/8 (e.g., 8x8)\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, input_channels, input_h, input_w)\n",
        "            conv_out_shape = self.features(dummy_input).shape\n",
        "\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1)) # Output: (N, last_conv_channels, 1, 1)\n",
        "\n",
        "        num_features_after_pool = conv_out_shape[1] # Channels from last conv layer (e.g., 256)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features_after_pool, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x input shape: (N, n_in_steps_as_channels, GRID_H, GRID_W)\n",
        "        x = self.features(x)\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# --- 7. Prepare PyTorch DataLoaders ---\n",
        "if X_train.shape[0] == 0:\n",
        "    print(\"Error: Training data (X_train) is empty. Cannot create DataLoaders or train model.\")\n",
        "    exit()\n",
        "\n",
        "# X_train and X_test should already be (N, n_in_steps, GRID_H, GRID_W) from Step 5\n",
        "X_train_tensor = torch.from_numpy(X_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).long()\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "print(\"Training DataLoader created.\")\n",
        "\n",
        "test_loader = None\n",
        "if X_test.shape[0] > 0:\n",
        "    X_test_tensor = torch.from_numpy(X_test).float()\n",
        "    y_test_tensor = torch.from_numpy(y_test).long()\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "    print(\"Test DataLoader created.\")\n",
        "else:\n",
        "    print(\"Test data is empty. No Test DataLoader will be created.\")\n",
        "\n",
        "\n",
        "# --- 8. Initialize Model, Loss, Optimizer ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = AlexNet2D_SpatialPose(\n",
        "    num_classes=num_classes,\n",
        "    input_channels=n_in_steps, # Number of channels is the sequence length\n",
        "    input_h=GRID_H,\n",
        "    input_w=GRID_W\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"2D Spatial Pose Model, Loss, and Optimizer initialized.\")\n",
        "print(model)\n",
        "\n",
        "# --- 9. Training Loop ---\n",
        "num_epochs = 10  # Adjust as needed\n",
        "\n",
        "print(\"Starting 2D Spatial Pose CNN training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "        inputs, labels = batch_data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Inputs should already be (B, n_in_steps, GRID_H, GRID_W)\n",
        "        # No unsqueeze(1) needed here.\n",
        "        # if i == 0 and epoch == 0:\n",
        "        #     print(f\"Shape of 'inputs' tensor going into model: {inputs.shape}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if (i + 1) % 10 == 0:\n",
        "            if len(train_loader) > 0 :\n",
        "                 print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    if len(train_loader) > 0:\n",
        "        print(f'Epoch {epoch+1} average loss: {running_loss / len(train_loader):.4f}')\n",
        "    else:\n",
        "        print(f'Epoch {epoch+1} completed (no training data in loader).')\n",
        "\n",
        "    # --- 10. (Optional) Validation Loop ---\n",
        "    if test_loader:\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs_val, labels_val in test_loader:\n",
        "                inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
        "                # inputs_val should also be (B, n_in_steps, GRID_H, GRID_W)\n",
        "                outputs_val = model(inputs_val)\n",
        "                _, predicted = torch.max(outputs_val.data, 1)\n",
        "                total += labels_val.size(0)\n",
        "                correct += (predicted == labels_val).sum().item()\n",
        "\n",
        "        if total > 0:\n",
        "            accuracy = 100 * correct / total\n",
        "            print(f'Accuracy on test set after epoch {epoch+1}: {accuracy:.2f}%')\n",
        "\n",
        "print('2D Spatial Pose CNN Training finished!')\n",
        "\n",
        "# TODO: Save the model if needed\n",
        "# torch.save(model.state_dict(), 'alexnet2d_spatial_pose_action.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLRq1mSf8KGK",
        "outputId": "c8676aa5-98cd-4395-afa9-b70b31e3bcc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original frame dimensions: 1440x1080\n",
            "Input to 2D CNN will be (Batch, Channels=30, Height=64, Width=64)\n",
            "Total unique videos: 17\n",
            "Training videos: ['Fp29', 'Fp35', 'Fp19', 'Fp30', 'Fp40', 'Fp21', 'Fp28', 'Fp31', 'Fp34', 'Fp20', 'Fp27'], Count: 11\n",
            "Testing videos: ['Fp17', 'Fp18', 'Fp24', 'Fp39', 'Fp33', 'Fp38'], Count: 6\n",
            "Skipping global StandardScaler. Per-pose normalization/scaling to grid is applied during sequence preparation.\n",
            "Preparing sequences as spatial pose images for 2D CNN...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler # StandardScaler might not be suitable for this spatial approach\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# --- User-Defined Parameters ---\n",
        "ORIGINAL_FRAME_WIDTH = 1440\n",
        "ORIGINAL_FRAME_HEIGHT = 1080\n",
        "\n",
        "\n",
        "# --- Parameters for Spatial Pose Image Representation ---\n",
        "n_in_steps = 30  # Sequence length (will be number of CHANNELS for 2D CNN input)\n",
        "GRID_H = 64      # Height of the spatial grid for each pose\n",
        "GRID_W = 64      # Width of the spatial grid for each pose\n",
        "\n",
        "print(f\"Original frame dimensions: {ORIGINAL_FRAME_WIDTH}x{ORIGINAL_FRAME_HEIGHT}\")\n",
        "print(f\"Input to 2D CNN will be (Batch, Channels={n_in_steps}, Height={GRID_H}, Width={GRID_W})\")\n",
        "\n",
        "# --- 2. Split video IDs for training and testing ---\n",
        "if 'source_video' not in baby_df.columns:\n",
        "    raise ValueError(\"DataFrame must contain 'source_video' column for splitting.\")\n",
        "unique_videos = baby_df['source_video'].unique()\n",
        "print(f\"Found unique video IDs: {unique_videos}\")\n",
        "\n",
        "\n",
        "train_videos = np.array([])\n",
        "test_videos = np.array([])\n",
        "\n",
        "if len(unique_videos) < 2:\n",
        "    print(\"Warning: Too few unique videos for video-based train/test split.\")\n",
        "    if len(unique_videos) == 1:\n",
        "        print(\"Only one unique video found. Using all data for training, empty test set.\")\n",
        "        train_videos = unique_videos\n",
        "    else:\n",
        "        print(\"Error: No unique videos found. Cannot proceed.\")\n",
        "        exit()\n",
        "else:\n",
        "    # Sort unique_videos to ensure consistent splitting if the order from .unique() varies\n",
        "    train_videos, test_videos = train_test_split(np.sort(unique_videos), test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Total unique videos: {len(unique_videos)}\")\n",
        "print(f\"Training videos: {list(train_videos)}, Count: {len(train_videos)}\")\n",
        "print(f\"Testing videos: {list(test_videos)}, Count: {len(test_videos)}\")\n",
        "\n",
        "\n",
        "# --- 3. Scaler (Commented Out - Per-pose normalization is now handled in step 4) ---\n",
        "print(\"Skipping global StandardScaler. Per-pose normalization/scaling to grid is applied during sequence preparation.\")\n",
        "\n",
        "\n",
        "# --- 4. Prepare Sequences for 2D CNN (Spatial Pose Images) ---\n",
        "X_train_list, y_train_list = [], []\n",
        "X_test_list, y_test_list = [], []\n",
        "\n",
        "videos_to_assign_to_train = train_videos\n",
        "videos_to_assign_to_test = test_videos\n",
        "\n",
        "print(\"Preparing sequences as spatial pose images for 2D CNN...\") # CRASH POINT\n",
        "for video_idx, video_id in enumerate(unique_videos):\n",
        "    print(f\"  Processing video {video_idx + 1}/{len(unique_videos)}: {video_id}\")\n",
        "    video_df = baby_df[baby_df['source_video'] == video_id]\n",
        "\n",
        "    unique_tracking_ids_in_video = video_df['tracking_id'].unique()\n",
        "    for tid_idx, tid in enumerate(unique_tracking_ids_in_video):\n",
        "        person_df = video_df[(video_df['tracking_id'] == tid) & (video_df['source_video'] == video_id)].copy()\n",
        "        person_df = person_df.sort_values('sec')\n",
        "\n",
        "        print(f\"    Processing person {tid_idx + 1}/{len(unique_tracking_ids_in_video)} (ID: {tid}) from video {video_id}.DataFrame length for this person: {len(person_df)}\")\n",
        "\n",
        "        if len(person_df) < n_in_steps:\n",
        "            print(f\"      Skipping person ID {tid} in video {video_id} due to insufficient data (Length: {len(person_df)}, Needed: {n_in_steps})\")\n",
        "            continue\n",
        "\n",
        "        # Keypoint data for this person: shape (num_timesteps_for_person, num_original_features)\n",
        "        kp_data_all_timesteps = person_df[keypoint_cols].values\n",
        "        label_data = person_df[target_column].values\n",
        "\n",
        "        num_sequences_possible = len(kp_data_all_timesteps) - n_in_steps + 1\n",
        "        print(f\"      Number of sequences possible for this person: {num_sequences_possible}\")\n",
        "\n",
        "        if num_sequences_possible <= 0: # Should be caught by len(person_df) < n_in_steps, but as a safeguard\n",
        "            continue\n",
        "\n",
        "        # Pre-allocate array for this person's sequences\n",
        "        # Shape: (num_sequences_possible, n_in_steps_as_channels, GRID_H, GRID_W)\n",
        "        try:\n",
        "            print(f\"      Attempting to allocate array of shape: ({num_sequences_possible}, {n_in_steps}, {GRID_H}, {GRID_W})\")\n",
        "            X_person_sequences_direct = np.zeros((num_sequences_possible, n_in_steps, GRID_H, GRID_W), dtype=np.float32)\n",
        "            y_person_sequences_direct = np.zeros(num_sequences_possible, dtype=np.int64)\n",
        "        except MemoryError:\n",
        "            print(f\"      ❌ MEMORY ERROR: Failed to allocate array for person {tid}, video {video_id}. Shape: ({num_sequences_possible}, {n_in_steps}, {GRID_H}, {GRID_W}). Skipping this person.\")\n",
        "            continue # Skip to the next person\n",
        "        except Exception as e:\n",
        "            print(f\"      ❌ ERROR during allocation for person {tid}, video {video_id}: {e}. Skipping this person.\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        sequence_idx_for_person = 0\n",
        "\n",
        "        for i in range(num_sequences_possible):\n",
        "            raw_kp_sequence = kp_data_all_timesteps[i : i + n_in_steps]\n",
        "            sequence_as_spatial_image = np.zeros((n_in_steps, GRID_H, GRID_W), dtype=np.float32)\n",
        "\n",
        "            for t_idx in range(n_in_steps):\n",
        "                features_at_t = raw_kp_sequence[t_idx, :]\n",
        "                current_timestep_grid = np.zeros((GRID_H, GRID_W), dtype=np.float32)\n",
        "\n",
        "                for kp_i in range(int(17)):\n",
        "                    kp_x_original = features_at_t[kp_i * 2]\n",
        "                    kp_y_original = features_at_t[kp_i * 2 + 1]\n",
        "\n",
        "                    if pd.isna(kp_x_original) or pd.isna(kp_y_original):\n",
        "                        continue\n",
        "\n",
        "                    kp_x_normalized = kp_x_original / ORIGINAL_FRAME_WIDTH\n",
        "                    kp_y_normalized = kp_y_original / ORIGINAL_FRAME_HEIGHT\n",
        "\n",
        "                    grid_x = int(np.clip(kp_x_normalized * (GRID_W - 1), 0, GRID_W - 1))\n",
        "                    grid_y = int(np.clip(kp_y_normalized * (GRID_H - 1), 0, GRID_H - 1))\n",
        "\n",
        "                    current_timestep_grid[grid_y, grid_x] = 1.0\n",
        "\n",
        "                sequence_as_spatial_image[t_idx, :, :] = current_timestep_grid\n",
        "\n",
        "            X_person_sequences_direct[sequence_idx_for_person] = sequence_as_spatial_image\n",
        "            y_person_sequences_direct[sequence_idx_for_person] = label_data[i + n_in_steps - 1]\n",
        "            sequence_idx_for_person += 1\n",
        "\n",
        "        if X_person_sequences_direct.shape[0] > 0:\n",
        "            if video_id in videos_to_assign_to_train:\n",
        "                X_train_list.append(X_person_sequences_direct)\n",
        "                y_train_list.append(y_person_sequences_direct)\n",
        "            elif video_id in videos_to_assign_to_test:\n",
        "                X_test_list.append(X_person_sequences_direct)\n",
        "                y_test_list.append(y_person_sequences_direct)\n",
        "\n",
        "# --- 5. Final Train/Test Arrays ---\n",
        "# Expected shape: (N_total_sequences, n_in_steps_as_channels, GRID_H, GRID_W)\n",
        "if X_train_list:\n",
        "    try:\n",
        "        print(\"Concatenating training data...\")\n",
        "        X_train = np.concatenate(X_train_list, axis=0)\n",
        "        y_train = np.concatenate(y_train_list, axis=0).astype(np.int64)\n",
        "    except MemoryError:\n",
        "        print(\"❌ MEMORY ERROR during final concatenation of X_train_list. Data might be too large.\")\n",
        "        # Handle error, e.g., by exiting or trying to use a subset\n",
        "        exit()\n",
        "else:\n",
        "    X_train = np.empty((0, n_in_steps, GRID_H, GRID_W), dtype=np.float32)\n",
        "    y_train = np.array([], dtype=np.int64)\n",
        "\n",
        "if X_test_list:\n",
        "    try:\n",
        "        print(\"Concatenating testing data...\")\n",
        "        X_test = np.concatenate(X_test_list, axis=0)\n",
        "        y_test = np.concatenate(y_test_list, axis=0).astype(np.int64)\n",
        "    except MemoryError:\n",
        "        print(\"❌ MEMORY ERROR during final concatenation of X_test_list. Data might be too large.\")\n",
        "        exit()\n",
        "else:\n",
        "    X_test = np.empty((0, n_in_steps, GRID_H, GRID_W), dtype=np.float32)\n",
        "    y_test = np.array([], dtype=np.int64)\n",
        "\n",
        "print(\"✅ Train/test data prepared for 2D CNN (spatial pose images).\")\n",
        "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)\n",
        "\n",
        "num_classes = 0\n",
        "if y_train.size > 0:\n",
        "    unique_train_labels = np.unique(y_train)\n",
        "    num_classes = len(unique_train_labels)\n",
        "    print(f\"Number of unique classes in y_train: {num_classes}\")\n",
        "    print(f\"Unique y_train labels: {unique_train_labels}\")\n",
        "elif y_test.size > 0:\n",
        "    unique_test_labels = np.unique(y_test)\n",
        "    num_classes = len(unique_test_labels)\n",
        "    print(f\"Warning: y_train is empty. Using y_test to determine num_classes: {num_classes}\")\n",
        "    print(f\"Unique y_test labels: {unique_test_labels}\")\n",
        "else:\n",
        "    print(\"Error: Both y_train and y_test are empty. Cannot determine num_classes.\")\n",
        "    exit()\n",
        "\n",
        "if num_classes <= 1 and (X_train.size > 0 or X_test.size > 0) :\n",
        "    print(f\"Error: num_classes is {num_classes}. Need at least 2 classes for classification.\")\n",
        "    exit()\n",
        "if num_classes == 0:\n",
        "    print(\"Error: num_classes is 0. No data available.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# --- 6. Define Adapted 2D CNN Model for Spatial Pose Images ---\n",
        "class AlexNet2D_SpatialPose(nn.Module):\n",
        "    # input_channels will now be n_in_steps\n",
        "    def __init__(self, num_classes, input_channels, input_h, input_w):\n",
        "        super(AlexNet2D_SpatialPose, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, input_channels, input_h, input_w)\n",
        "            conv_out_shape = self.features(dummy_input).shape\n",
        "\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        num_features_after_pool = conv_out_shape[1]\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features_after_pool, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# --- 7. Prepare PyTorch DataLoaders ---\n",
        "if X_train.shape[0] == 0:\n",
        "    print(\"Error: Training data (X_train) is empty. Cannot create DataLoaders or train model.\")\n",
        "    exit()\n",
        "\n",
        "X_train_tensor = torch.from_numpy(X_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).long()\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "print(\"Training DataLoader created.\")\n",
        "\n",
        "test_loader = None\n",
        "if X_test.shape[0] > 0:\n",
        "    X_test_tensor = torch.from_numpy(X_test).float()\n",
        "    y_test_tensor = torch.from_numpy(y_test).long()\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "    print(\"Test DataLoader created.\")\n",
        "else:\n",
        "    print(\"Test data is empty. No Test DataLoader will be created.\")\n",
        "\n",
        "\n",
        "# --- 8. Initialize Model, Loss, Optimizer ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = AlexNet2D_SpatialPose(\n",
        "    num_classes=num_classes,\n",
        "    input_channels=n_in_steps,\n",
        "    input_h=GRID_H,\n",
        "    input_w=GRID_W\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"2D Spatial Pose Model, Loss, and Optimizer initialized.\")\n",
        "print(model)\n",
        "\n",
        "# --- 9. Training Loop ---\n",
        "num_epochs = 10\n",
        "\n",
        "print(\"Starting 2D Spatial Pose CNN training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "        inputs, labels = batch_data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if (i + 1) % 10 == 0:\n",
        "            if len(train_loader) > 0 :\n",
        "                 print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    if len(train_loader) > 0:\n",
        "        print(f'Epoch {epoch+1} average loss: {running_loss / len(train_loader):.4f}')\n",
        "    else:\n",
        "        print(f'Epoch {epoch+1} completed (no training data in loader).')\n",
        "\n",
        "    # --- 10. (Optional) Validation Loop ---\n",
        "    if test_loader:\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs_val, labels_val in test_loader:\n",
        "                inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
        "                outputs_val = model(inputs_val)\n",
        "                _, predicted = torch.max(outputs_val.data, 1)\n",
        "                total += labels_val.size(0)\n",
        "                correct += (predicted == labels_val).sum().item()\n",
        "\n",
        "        if total > 0:\n",
        "            accuracy = 100 * correct / total\n",
        "            print(f'Accuracy on test set after epoch {epoch+1}: {accuracy:.2f}%')\n",
        "\n",
        "print('2D Spatial Pose CNN Training finished!')\n",
        "\n",
        "# TODO: Save the model if needed\n",
        "# torch.save(model.state_dict(), 'alexnet2d_spatial_pose_action.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04-gdbTIDLvC",
        "outputId": "a3468b45-efb0-4ee5-f4ee-62f440f743bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original frame dimensions: 1440x1080\n",
            "Input to 2D CNN will be (Batch, Channels=30, Height=64, Width=64)\n",
            "Found unique video IDs: ['Fp17' 'Fp18' 'Fp19' 'Fp20' 'Fp21' 'Fp24' 'Fp27' 'Fp28' 'Fp29' 'Fp30'\n",
            " 'Fp31' 'Fp33' 'Fp34' 'Fp35' 'Fp38' 'Fp39' 'Fp40']\n",
            "Total unique videos: 17\n",
            "Training videos: ['Fp29', 'Fp35', 'Fp19', 'Fp30', 'Fp40', 'Fp21', 'Fp28', 'Fp31', 'Fp34', 'Fp20', 'Fp27'], Count: 11\n",
            "Testing videos: ['Fp17', 'Fp18', 'Fp24', 'Fp39', 'Fp33', 'Fp38'], Count: 6\n",
            "Skipping global StandardScaler. Per-pose normalization/scaling to grid is applied during sequence preparation.\n",
            "Preparing sequences as spatial pose images for 2D CNN...\n",
            "  Processing video 1/17: Fp17\n",
            "    Processing person 1/2 (ID: 164) from video Fp17.DataFrame length for this person: 884\n",
            "      Number of sequences possible for this person: 855\n",
            "      Attempting to allocate array of shape: (855, 30, 64, 64)\n",
            "    Processing person 2/2 (ID: 167) from video Fp17.DataFrame length for this person: 1075\n",
            "      Number of sequences possible for this person: 1046\n",
            "      Attempting to allocate array of shape: (1046, 30, 64, 64)\n",
            "  Processing video 2/17: Fp18\n",
            "    Processing person 1/5 (ID: 571) from video Fp18.DataFrame length for this person: 325\n",
            "      Number of sequences possible for this person: 296\n",
            "      Attempting to allocate array of shape: (296, 30, 64, 64)\n",
            "    Processing person 2/5 (ID: 572) from video Fp18.DataFrame length for this person: 664\n",
            "      Number of sequences possible for this person: 635\n",
            "      Attempting to allocate array of shape: (635, 30, 64, 64)\n",
            "    Processing person 3/5 (ID: 569) from video Fp18.DataFrame length for this person: 18\n",
            "      Skipping person ID 569 in video Fp18 due to insufficient data (Length: 18, Needed: 30)\n",
            "    Processing person 4/5 (ID: 574) from video Fp18.DataFrame length for this person: 599\n",
            "      Number of sequences possible for this person: 570\n",
            "      Attempting to allocate array of shape: (570, 30, 64, 64)\n",
            "    Processing person 5/5 (ID: 576) from video Fp18.DataFrame length for this person: 362\n",
            "      Number of sequences possible for this person: 333\n",
            "      Attempting to allocate array of shape: (333, 30, 64, 64)\n",
            "  Processing video 3/17: Fp19\n",
            "    Processing person 1/7 (ID: 271) from video Fp19.DataFrame length for this person: 713\n",
            "      Number of sequences possible for this person: 684\n",
            "      Attempting to allocate array of shape: (684, 30, 64, 64)\n",
            "    Processing person 2/7 (ID: 303) from video Fp19.DataFrame length for this person: 32\n",
            "      Number of sequences possible for this person: 3\n",
            "      Attempting to allocate array of shape: (3, 30, 64, 64)\n",
            "    Processing person 3/7 (ID: 305) from video Fp19.DataFrame length for this person: 6\n",
            "      Skipping person ID 305 in video Fp19 due to insufficient data (Length: 6, Needed: 30)\n",
            "    Processing person 4/7 (ID: 308) from video Fp19.DataFrame length for this person: 3\n",
            "      Skipping person ID 308 in video Fp19 due to insufficient data (Length: 3, Needed: 30)\n",
            "    Processing person 5/7 (ID: 309) from video Fp19.DataFrame length for this person: 36\n",
            "      Number of sequences possible for this person: 7\n",
            "      Attempting to allocate array of shape: (7, 30, 64, 64)\n",
            "    Processing person 6/7 (ID: 311) from video Fp19.DataFrame length for this person: 64\n",
            "      Number of sequences possible for this person: 35\n",
            "      Attempting to allocate array of shape: (35, 30, 64, 64)\n",
            "    Processing person 7/7 (ID: 317) from video Fp19.DataFrame length for this person: 230\n",
            "      Number of sequences possible for this person: 201\n",
            "      Attempting to allocate array of shape: (201, 30, 64, 64)\n",
            "  Processing video 4/17: Fp20\n",
            "    Processing person 1/7 (ID: 418) from video Fp20.DataFrame length for this person: 73\n",
            "      Number of sequences possible for this person: 44\n",
            "      Attempting to allocate array of shape: (44, 30, 64, 64)\n",
            "    Processing person 2/7 (ID: 420) from video Fp20.DataFrame length for this person: 2\n",
            "      Skipping person ID 420 in video Fp20 due to insufficient data (Length: 2, Needed: 30)\n",
            "    Processing person 3/7 (ID: 425) from video Fp20.DataFrame length for this person: 136\n",
            "      Number of sequences possible for this person: 107\n",
            "      Attempting to allocate array of shape: (107, 30, 64, 64)\n",
            "    Processing person 4/7 (ID: 429) from video Fp20.DataFrame length for this person: 322\n",
            "      Number of sequences possible for this person: 293\n",
            "      Attempting to allocate array of shape: (293, 30, 64, 64)\n",
            "    Processing person 5/7 (ID: 433) from video Fp20.DataFrame length for this person: 832\n",
            "      Number of sequences possible for this person: 803\n",
            "      Attempting to allocate array of shape: (803, 30, 64, 64)\n",
            "    Processing person 6/7 (ID: 438) from video Fp20.DataFrame length for this person: 227\n",
            "      Number of sequences possible for this person: 198\n",
            "      Attempting to allocate array of shape: (198, 30, 64, 64)\n",
            "    Processing person 7/7 (ID: 439) from video Fp20.DataFrame length for this person: 271\n",
            "      Number of sequences possible for this person: 242\n",
            "      Attempting to allocate array of shape: (242, 30, 64, 64)\n",
            "  Processing video 5/17: Fp21\n",
            "    Processing person 1/4 (ID: 854) from video Fp21.DataFrame length for this person: 1486\n",
            "      Number of sequences possible for this person: 1457\n",
            "      Attempting to allocate array of shape: (1457, 30, 64, 64)\n",
            "    Processing person 2/4 (ID: 901) from video Fp21.DataFrame length for this person: 86\n",
            "      Number of sequences possible for this person: 57\n",
            "      Attempting to allocate array of shape: (57, 30, 64, 64)\n",
            "    Processing person 3/4 (ID: 903) from video Fp21.DataFrame length for this person: 89\n",
            "      Number of sequences possible for this person: 60\n",
            "      Attempting to allocate array of shape: (60, 30, 64, 64)\n",
            "    Processing person 4/4 (ID: 908) from video Fp21.DataFrame length for this person: 254\n",
            "      Number of sequences possible for this person: 225\n",
            "      Attempting to allocate array of shape: (225, 30, 64, 64)\n",
            "  Processing video 6/17: Fp24\n",
            "    Processing person 1/4 (ID: 457) from video Fp24.DataFrame length for this person: 156\n",
            "      Number of sequences possible for this person: 127\n",
            "      Attempting to allocate array of shape: (127, 30, 64, 64)\n",
            "    Processing person 2/4 (ID: 460) from video Fp24.DataFrame length for this person: 793\n",
            "      Number of sequences possible for this person: 764\n",
            "      Attempting to allocate array of shape: (764, 30, 64, 64)\n",
            "    Processing person 3/4 (ID: 462) from video Fp24.DataFrame length for this person: 703\n",
            "      Number of sequences possible for this person: 674\n",
            "      Attempting to allocate array of shape: (674, 30, 64, 64)\n",
            "    Processing person 4/4 (ID: 464) from video Fp24.DataFrame length for this person: 115\n",
            "      Number of sequences possible for this person: 86\n",
            "      Attempting to allocate array of shape: (86, 30, 64, 64)\n",
            "  Processing video 7/17: Fp27\n",
            "    Processing person 1/2 (ID: 31) from video Fp27.DataFrame length for this person: 2263\n",
            "      Number of sequences possible for this person: 2234\n",
            "      Attempting to allocate array of shape: (2234, 30, 64, 64)\n",
            "    Processing person 2/2 (ID: 48) from video Fp27.DataFrame length for this person: 18\n",
            "      Skipping person ID 48 in video Fp27 due to insufficient data (Length: 18, Needed: 30)\n",
            "  Processing video 8/17: Fp28\n",
            "    Processing person 1/2 (ID: 367) from video Fp28.DataFrame length for this person: 2129\n",
            "      Number of sequences possible for this person: 2100\n",
            "      Attempting to allocate array of shape: (2100, 30, 64, 64)\n",
            "    Processing person 2/2 (ID: 370) from video Fp28.DataFrame length for this person: 2119\n",
            "      Number of sequences possible for this person: 2090\n",
            "      Attempting to allocate array of shape: (2090, 30, 64, 64)\n",
            "  Processing video 9/17: Fp29\n",
            "    Processing person 1/3 (ID: 2) from video Fp29.DataFrame length for this person: 1263\n",
            "      Number of sequences possible for this person: 1234\n",
            "      Attempting to allocate array of shape: (1234, 30, 64, 64)\n",
            "    Processing person 2/3 (ID: 10) from video Fp29.DataFrame length for this person: 181\n",
            "      Number of sequences possible for this person: 152\n",
            "      Attempting to allocate array of shape: (152, 30, 64, 64)\n",
            "    Processing person 3/3 (ID: 24) from video Fp29.DataFrame length for this person: 2275\n",
            "      Number of sequences possible for this person: 2246\n",
            "      Attempting to allocate array of shape: (2246, 30, 64, 64)\n",
            "  Processing video 10/17: Fp30\n",
            "    Processing person 1/5 (ID: 206) from video Fp30.DataFrame length for this person: 314\n",
            "      Number of sequences possible for this person: 285\n",
            "      Attempting to allocate array of shape: (285, 30, 64, 64)\n",
            "    Processing person 2/5 (ID: 214) from video Fp30.DataFrame length for this person: 2737\n",
            "      Number of sequences possible for this person: 2708\n",
            "      Attempting to allocate array of shape: (2708, 30, 64, 64)\n",
            "    Processing person 3/5 (ID: 215) from video Fp30.DataFrame length for this person: 39\n",
            "      Number of sequences possible for this person: 10\n",
            "      Attempting to allocate array of shape: (10, 30, 64, 64)\n",
            "    Processing person 4/5 (ID: 217) from video Fp30.DataFrame length for this person: 12\n",
            "      Skipping person ID 217 in video Fp30 due to insufficient data (Length: 12, Needed: 30)\n",
            "    Processing person 5/5 (ID: 219) from video Fp30.DataFrame length for this person: 2373\n",
            "      Number of sequences possible for this person: 2344\n",
            "      Attempting to allocate array of shape: (2344, 30, 64, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zyDdIfAPJGU3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa7ccd61e14e48e6a6140711c53aa186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba99f64c17ba400fbced5cfe9470a69d",
              "IPY_MODEL_c19fc3792eed45c9894678b18ce01727",
              "IPY_MODEL_9b255af148b148f1be331c42df687c29"
            ],
            "layout": "IPY_MODEL_ff887d3ef7944230b18dd85c4228ede2"
          }
        },
        "ba99f64c17ba400fbced5cfe9470a69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b2788e1a8b2468f9864bf89a0d777b6",
            "placeholder": "​",
            "style": "IPY_MODEL_80030398f1a74069a79706ff23e2b723",
            "value": "100%"
          }
        },
        "c19fc3792eed45c9894678b18ce01727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eed4717c4e864972a8f48d54b9c3cd4c",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c8ecdf4a34148209f26a2371e575476",
            "value": 50
          }
        },
        "9b255af148b148f1be331c42df687c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9395972b3b743db9eff57e109b71c49",
            "placeholder": "​",
            "style": "IPY_MODEL_0bca2bb47e4a4f19aa6ef6b265500252",
            "value": " 50/50 [25:43&lt;00:00, 29.96s/it]"
          }
        },
        "ff887d3ef7944230b18dd85c4228ede2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b2788e1a8b2468f9864bf89a0d777b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80030398f1a74069a79706ff23e2b723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eed4717c4e864972a8f48d54b9c3cd4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c8ecdf4a34148209f26a2371e575476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9395972b3b743db9eff57e109b71c49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bca2bb47e4a4f19aa6ef6b265500252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}