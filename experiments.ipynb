{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/begumaktann/Infant-Engagement-Interaction/blob/main/experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5PA3sgrLy5D"
      },
      "outputs": [],
      "source": [
        "# prompt: load /content/drive/MyDrive/merged_all_keypoints_b_label_only.csv and /content/drive/MyDrive/engagement_cleaned.csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the first CSV file\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/merged_all_keypoints_b_label_only.csv')\n",
        "\n",
        "# Load the second CSV file\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/engagement_cleaned.csv')\n",
        "\n",
        "# Now you have two pandas DataFrames: df1 and df2\n",
        "# You can work with them, for example, print the first few rows:\n",
        "# print(df1.head())\n",
        "# print(df2.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GazyME7eMJw2"
      },
      "outputs": [],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haZVpiiZMM_L"
      },
      "outputs": [],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcqzhYAZMYLF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "df_keypoints = pd.read_csv(\"/content/drive/MyDrive/merged_all_keypoints_b_label_only.csv\")\n",
        "df_engagement = pd.read_csv(\"/content/drive/MyDrive/engagement_cleaned.csv\")\n",
        "\n",
        "# Round seconds in both dataframes\n",
        "df_keypoints[\"sec_rounded\"] = df_keypoints[\"sec\"].round().astype(int)\n",
        "df_engagement[\"seconds_rounded\"] = df_engagement[\"seconds\"].round().astype(int)\n",
        "\n",
        "# Create a helper column for matching\n",
        "df_keypoints[\"merge_key\"] = list(zip(df_keypoints[\"source_video\"], df_keypoints[\"sec_rounded\"]))\n",
        "df_engagement[\"merge_key\"] = list(zip(df_engagement[\"video_id\"], df_engagement[\"seconds_rounded\"]))\n",
        "\n",
        "# Create a dictionary mapping (video_id, second) to the engagement labels\n",
        "engagement_lookup = {}\n",
        "\n",
        "for _, row in df_engagement.iterrows():\n",
        "    video = row[\"video_id\"]\n",
        "    second = int(row[\"seconds_rounded\"])\n",
        "    labels = row.drop([\"video_id\", \"seconds\", \"seconds_rounded\", \"merge_key\"])\n",
        "\n",
        "    for offset in range(-15, 16):  # Tolerance of ±15 seconds\n",
        "        engagement_lookup[(video, second + offset)] = labels\n",
        "\n",
        "# Apply engagement labels to keypoints data\n",
        "engagement_columns = df_engagement.columns.difference([\"video_id\", \"seconds\", \"seconds_rounded\", \"merge_key\"])\n",
        "for col in engagement_columns:\n",
        "    df_keypoints[col] = df_keypoints[\"merge_key\"].map(lambda key: engagement_lookup.get(key, pd.Series([np.nan]*len(engagement_columns)))[col])\n",
        "\n",
        "# Drop helper columns\n",
        "df_keypoints.drop(columns=[\"sec_rounded\", \"merge_key\"], inplace=True)\n",
        "\n",
        "# Save the merged dataframe\n",
        "df_keypoints.to_csv(\"merged_with_engagement_labels.csv\", index=False)\n",
        "\n",
        "print(\"✅ Merged file saved as: merged_with_engagement_labels.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSideMHK2VCV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq1BS-AtO1Wz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "df_keypoints = pd.read_csv(\"/content/drive/MyDrive/merged_all_keypoints_b_label_only.csv\")\n",
        "df_engagement = pd.read_csv(\"/content/drive/MyDrive/engagement_cleaned.csv\")\n",
        "\n",
        "# Round seconds in both dataframes\n",
        "df_keypoints[\"sec_rounded\"] = df_keypoints[\"sec\"].round().astype(int)\n",
        "df_engagement[\"seconds_rounded\"] = df_engagement[\"seconds\"].round().astype(int)\n",
        "\n",
        "# Create a helper column for matching\n",
        "df_keypoints[\"merge_key\"] = list(zip(df_keypoints[\"source_video\"], df_keypoints[\"sec_rounded\"]))\n",
        "df_engagement[\"merge_key\"] = list(zip(df_engagement[\"video_id\"], df_engagement[\"seconds_rounded\"]))\n",
        "\n",
        "# Create a dictionary mapping (video_id, second) to the engagement labels\n",
        "engagement_lookup = {}\n",
        "\n",
        "for _, row in df_engagement.iterrows():\n",
        "    video = row[\"video_id\"]\n",
        "    second = int(row[\"seconds_rounded\"])\n",
        "    labels = row.drop([\"video_id\", \"seconds\", \"seconds_rounded\", \"merge_key\"])\n",
        "\n",
        "    for offset in range(-15, 16):  # Tolerance of ±15 seconds\n",
        "        engagement_lookup[(video, second + offset)] = labels.to_dict() # Convert labels to a dictionary\n",
        "\n",
        "# Apply engagement labels to keypoints data\n",
        "engagement_columns = df_engagement.columns.difference([\"video_id\", \"seconds\", \"seconds_rounded\", \"merge_key\"])\n",
        "for col in engagement_columns:\n",
        "    df_keypoints[col] = df_keypoints[\"merge_key\"].map(lambda key: engagement_lookup.get(key, {}).get(col, np.nan)) # Access using column name and handle missing values\n",
        "\n",
        "# Drop helper columns\n",
        "df_keypoints.drop(columns=[\"sec_rounded\", \"merge_key\"], inplace=True)\n",
        "\n",
        "# Save the merged dataframe\n",
        "df_keypoints.to_csv(\"merged_with_engagement_labels.csv\", index=False)\n",
        "\n",
        "print(\"✅ Merged file saved as: merged_with_engagement_labels.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24cI9WwCfm-6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "df_keypoints = pd.read_csv(\"/content/drive/MyDrive/merged_all_keypoints_b_label_only.csv\")\n",
        "df_engagement = pd.read_csv(\"engagement_cleaned.csv\",sep=';')\n",
        "\n",
        "# Round seconds\n",
        "df_keypoints[\"sec_rounded\"] = df_keypoints[\"sec\"].round().astype(int)\n",
        "df_engagement[\"seconds_rounded\"] = df_engagement[\"seconds\"].round().astype(int)\n",
        "\n",
        "# Sort for forward search\n",
        "df_keypoints.sort_values(by=[\"source_video\", \"sec_rounded\"], inplace=True)\n",
        "df_engagement.sort_values(by=[\"video_id\", \"seconds_rounded\"], inplace=True)\n",
        "\n",
        "# Create a list to store matches\n",
        "matched_rows = []\n",
        "\n",
        "# Iterate over keypoints\n",
        "for idx, row in df_keypoints.iterrows():\n",
        "    video = row[\"source_video\"]\n",
        "    frame_sec = row[\"sec_rounded\"]\n",
        "\n",
        "    # Filter engagement labels for same video and future timestamps\n",
        "    future_engagements = df_engagement[\n",
        "        (df_engagement[\"video_id\"] == video) &\n",
        "        (df_engagement[\"seconds_rounded\"] >= frame_sec) &\n",
        "        (df_engagement[\"seconds_rounded\"] <= frame_sec + 30)\n",
        "    ]\n",
        "\n",
        "    if not future_engagements.empty:\n",
        "        # Take the first future label (i.e., nearest next engagement)\n",
        "        label_row = future_engagements.iloc[0]\n",
        "        label_data = label_row.drop([\"video_id\", \"seconds\", \"seconds_rounded\", \"merge_key\"], errors=\"ignore\").to_dict()\n",
        "    else:\n",
        "        label_data = {col: np.nan for col in df_engagement.columns if col not in [\"video_id\", \"seconds\", \"seconds_rounded\", \"merge_key\"]}\n",
        "\n",
        "    # Append label columns to the current keypoint row\n",
        "    new_row = row.to_dict()\n",
        "    new_row.update(label_data)\n",
        "    matched_rows.append(new_row)\n",
        "\n",
        "# Convert list to DataFrame\n",
        "merged_df = pd.DataFrame(matched_rows)\n",
        "\n",
        "# Drop helper column\n",
        "merged_df.drop(columns=[\"sec_rounded\"], inplace=True)\n",
        "\n",
        "# Save the new merged DataFrame\n",
        "merged_df.to_csv(\"merged_with_forward_labels.csv\", index=False)\n",
        "\n",
        "print(\"✅ Merged with forward matching saved to: merged_with_forward_labels_with_tasks.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SogBdqRF3JYE"
      },
      "outputs": [],
      "source": [
        "merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhNT2UrW5J9f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPqJWaZr5KAM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPVtMJuO5KC3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iSAU4rb5KFu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "so_0w8pr5KIZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gTFKnRq5KLf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG6BpqiT5KNX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMNPwT0q5KP9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUHRiO-C5KTX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_s0HqESReDr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_keypoints=pd.read_csv(\"merged_with_forward_labels.csv\",sep=',',low_memory=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_keypoints"
      ],
      "metadata": {
        "id": "35Gdny1kKzmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SdWoiIJR0Qo"
      },
      "outputs": [],
      "source": [
        "merged_df=df_keypoints"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 1"
      ],
      "metadata": {
        "id": "m_J4kLETREm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load the Data --\n",
        "df=merged_df[merged_df[\"task\"]=='p']\n",
        "print(\"Data loaded successfully.\")\n",
        "print(\"Shape of the dataframe:\", df.shape)\n"
      ],
      "metadata": {
        "id": "dq5VuVnEMmk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "BBIBbQSKMnwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- 2. Define Target (y) and Prepare for Feature (X) Selection ---\n",
        "target_column = 'playfully_engaged'\n",
        "video_id_column = 'source_video' # IMPORTANT: Verify this is the correct column name for video IDs in your CSV\n",
        "\n",
        "if target_column not in df.columns:\n",
        "    print(f\"Error: Target column '{target_column}' not found in the dataframe.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "if video_id_column not in df.columns:\n",
        "    print(f\"Error: Video ID column '{video_id_column}' for data splitting not found.\")\n",
        "    print(f\"Please ensure '{video_id_column}' exists or update the 'video_id_column' variable.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "# Drop rows where the target variable is NaN, as they cannot be used for training or evaluation.\n",
        "df.dropna(subset=[target_column], inplace=True)\n",
        "print(f\"\\nShape of dataframe after dropping NaNs in target column '{target_column}': {df.shape}\")\n",
        "\n",
        "# Convert target variable to numeric if it's not already\n",
        "if df[target_column].dtype == 'bool':\n",
        "    df[target_column] = df[target_column].astype(int)\n",
        "elif df[target_column].dtype == 'object':\n",
        "    print(f\"Target column '{target_column}' is of object type. Attempting to encode it.\")\n",
        "    le = LabelEncoder()\n",
        "    try:\n",
        "        df[target_column] = le.fit_transform(df[target_column])\n",
        "        print(f\"Target column '{target_column}' encoded. Classes: {le.classes_}\")\n",
        "        if len(le.classes_) > 2:\n",
        "            print(\"Warning: Target variable has more than two classes. This will be a multi-class SVM.\")\n",
        "        elif len(le.classes_) <= 1:\n",
        "            print(f\"Error: Target column '{target_column}' has only one class after encoding ({le.classes_}). Cannot train a classifier.\")\n",
        "            exit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error encoding target column '{target_column}': {e}\")\n",
        "        print(\"Please ensure the target column contains appropriate values for classification.\")\n",
        "        exit()\n",
        "\n",
        "# Define feature columns\n",
        "# Identify potential keypoint columns (typically floats or integers)\n",
        "potential_feature_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Columns to exclude from features (USER UPDATED LIST)\n",
        "# This list now means other engagement labels (like focused_engagement) MIGHT become features if numeric\n",
        "columns_to_exclude_from_features = [\n",
        "    target_column, video_id_column, # video_id_column is used for splitting, not as a feature\n",
        "    'video_id', # if 'video_id' is different from video_id_column and also an identifier\n",
        "    'sec', 'seconds', 'seconds_rounded', 'sec_rounded', 'merge_key',\n",
        "    'angrily_engaged', 'playing_engaged', 'time', 'watching', 'frame', 'tracking_id','task'\n",
        "]\n",
        "# Add any other known non-feature or identifier columns if necessary.\n",
        "\n",
        "# Filter out columns from the exclusion list that might not exist in the dataframe\n",
        "columns_to_exclude_from_features = [col for col in columns_to_exclude_from_features if col in df.columns]\n",
        "\n",
        "feature_cols = [col for col in potential_feature_cols if col not in columns_to_exclude_from_features]\n",
        "\n",
        "if not feature_cols:\n",
        "    print(\"Error: No feature columns were identified. Please check the column names, types, and exclusion list.\")\n",
        "    print(f\"Potential numeric columns found: {potential_feature_cols}\")\n",
        "    print(f\"Columns excluded: {columns_to_exclude_from_features}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\nIdentified {len(feature_cols)} feature columns: {feature_cols}\")\n",
        "print(f\"Target column: {target_column}\")\n",
        "print(f\"Video ID column for splitting: {video_id_column}\")\n",
        "\n",
        "# --- 3. Split Data into Training and Testing Sets based on Video IDs ---\n",
        "unique_videos = df[video_id_column].unique()\n",
        "print(f\"\\nFound {len(unique_videos)} unique videos for splitting.\")\n",
        "\n",
        "if len(unique_videos) < 2: # Need at least one video for train and one for test\n",
        "    print(\"Error: Not enough unique videos to perform a train/test split. Need at least 2.\")\n",
        "    exit()\n",
        "# Ensure test_size is not too large for the number of videos\n",
        "test_size_videos = 0.3\n",
        "if len(unique_videos) * test_size_videos < 1:\n",
        "    print(f\"Warning: Number of unique videos ({len(unique_videos)}) is small. Adjusting test_size for videos to ensure at least 1 test video.\")\n",
        "    # Ensure at least 1 video for testing, if possible.\n",
        "    # If only 2 videos, it will be 1 train, 1 test. If 3, 2 train, 1 test.\n",
        "    test_video_count = 1\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_video_count, random_state=21, shuffle=True)\n",
        "else:\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_size_videos, random_state=21, shuffle=True)\n",
        "\n",
        "\n",
        "print(f\"Number of videos in training set: {len(train_video_ids)}\")\n",
        "print(f\"Number of videos in testing set: {len(test_video_ids)}\")\n",
        "\n",
        "if len(train_video_ids) == 0 or len(test_video_ids) == 0:\n",
        "    print(\"Error: Splitting videos resulted in an empty training or testing set of videos.\")\n",
        "    exit()\n",
        "\n",
        "# Create training and testing dataframes\n",
        "train_df = df[df[video_id_column].isin(train_video_ids)].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "test_df = df[df[video_id_column].isin(test_video_ids)].copy()\n",
        "\n",
        "if train_df.empty or test_df.empty:\n",
        "    print(\"Error: Training or testing dataframe is empty after filtering by video IDs.\")\n",
        "    exit()\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[target_column]\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "print(\"\\nData split into training and testing sets based on video IDs.\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "if X_train.empty or X_test.empty:\n",
        "    print(\"Error: X_train or X_test is empty. Check feature selection and data splitting.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Distribution of target variable in training set:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"Distribution of target variable in test set:\\n\", y_test.value_counts(normalize=True))\n",
        "\n",
        "# --- 4. Handle Missing Values in Features (Post-Split) ---\n",
        "print(f\"\\nMissing values in X_train before imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test before imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test) # Use transform only on test data\n",
        "\n",
        "# Convert imputed arrays back to DataFrames with original column names\n",
        "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns, index=X_train.index)\n",
        "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(f\"Missing values in X_train after imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test after imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "# --- 5. Scale Numerical Features (Post-Split and Post-Imputation) ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test) # Use transform only on test data\n",
        "\n",
        "print(\"\\nFeatures scaled.\")"
      ],
      "metadata": {
        "id": "S5SDSwVOMeww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2EXQhHiPDW3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# --- 6. Train the SVM Model ---\n",
        "print(\"\\nTraining the SVM model...\")\n",
        "# Ensure y_train has more than one class for stratification or balanced class weights\n",
        "if len(y_train.unique()) <= 1:\n",
        "    print(f\"Error: Training target variable 'y_train' has only one class: {y_train.unique()}. Cannot train classifier.\")\n",
        "    exit()\n",
        "\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, class_weight='balanced', probability=True)\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "print(\"SVM model trained successfully.\")\n",
        "\n",
        "# --- 7. Make Predictions and Evaluate the Model ---\n",
        "print(\"\\nMaking predictions on the test set...\")\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "if 'le' in globals() and hasattr(le, 'classes_'):\n",
        "    target_names_report = [str(cls) for cls in le.classes_]\n",
        "    # Ensure labels for confusion matrix and report match actual unique values in y_test/y_pred\n",
        "    unique_test_labels_sorted = sorted(y_test.unique())\n",
        "    # If le.classes_ were [False, True] -> [0, 1], and y_test contains 0, 1, this is fine.\n",
        "    # If le.classes_ were ['A', 'B'] -> [0, 1], this is fine.\n",
        "    # We need to ensure the order of target_names_report matches the sorted unique labels if they are numeric.\n",
        "    if all(isinstance(c, (int, float)) for c in unique_test_labels_sorted) and \\\n",
        "       all(isinstance(c, str) for c in target_names_report) and \\\n",
        "       len(unique_test_labels_sorted) == len(target_names_report):\n",
        "        # This attempts to map sorted numeric labels to the string names from LabelEncoder\n",
        "        # This might need adjustment if LabelEncoder classes are not simple True/False or ordered strings\n",
        "        report_labels_ordered = unique_test_labels_sorted\n",
        "    else:\n",
        "        report_labels_ordered = le.transform(le.classes_) # Use the transformed numeric values corresponding to le.classes_\n",
        "\n",
        "else: # Fallback if LabelEncoder was not used (e.g., target was already 0/1)\n",
        "    unique_test_labels_sorted = sorted(y_test.unique())\n",
        "    target_names_report = [f\"Class {i}\" for i in unique_test_labels_sorted]\n",
        "    report_labels_ordered = unique_test_labels_sorted\n",
        "\n",
        "try:\n",
        "    print(classification_report(y_test, y_pred, labels=report_labels_ordered, target_names=target_names_report, zero_division=0))\n",
        "except Exception as e_report:\n",
        "    print(f\"Could not generate classification report with specific target names/labels: {e_report}\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "try:\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=report_labels_ordered)\n",
        "    print(pd.DataFrame(cm, index=target_names_report, columns=target_names_report))\n",
        "except Exception as e_cm:\n",
        "    print(f\"Could not generate confusion matrix with specific labels/names: {e_cm}\")\n",
        "    cm = confusion_matrix(y_test, y_pred) # Fallback\n",
        "    print(cm)\n",
        "\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_6jjY5NQPZz"
      },
      "outputs": [],
      "source": [
        "# Assuming your data is loaded into df\n",
        "# and you already split by video_id\n",
        "\n",
        "# Example split (replace with your actual split if different)\n",
        "unique_videos = df[\"source_video\"].unique()\n",
        "train_videos = unique_videos[:int(len(unique_videos) * 0.8)]\n",
        "test_videos = unique_videos[int(len(unique_videos) * 0.8):]\n",
        "\n",
        "# Filter the DataFrames\n",
        "train_df = df[df[\"source_video\"].isin(train_videos)]\n",
        "test_df = df[df[\"source_video\"].isin(test_videos)]\n",
        "\n",
        "# Show unique video IDs\n",
        "print(\"🎓 Train Set Video IDs:\")\n",
        "print(sorted(train_df[\"source_video\"].unique()))\n",
        "\n",
        "print(\"\\n🧪 Test Set Video IDs:\")\n",
        "print(sorted(test_df[\"source_video\"].unique()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 2"
      ],
      "metadata": {
        "id": "pnaL6mE-RMuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV # Added GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Additional model imports (optional, for trying other models)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "\n",
        "\n",
        "# Store a list of columns before feature engineering to identify new ones later\n",
        "original_columns = df.columns.tolist()\n",
        "\n",
        "# --- 1.5. Feature Engineering ---\n",
        "print(\"\\n--- 1.5. Feature Engineering ---\")\n",
        "\n",
        "# IMPORTANT: Define your keypoint indices here!\n",
        "# These are EXAMPLES. You MUST verify and update them based on YOUR data's keypoint model.\n",
        "# (e.g., if your model's nose is keypoint 0, left_eye is 1, etc.)\n",
        "KP_NOSE = 0\n",
        "KP_LEFT_EYE = 1\n",
        "KP_RIGHT_EYE = 2\n",
        "KP_LEFT_EAR = 3\n",
        "KP_RIGHT_EAR = 4\n",
        "KP_LEFT_SHOULDER = 5\n",
        "KP_RIGHT_SHOULDER = 6\n",
        "KP_LEFT_ELBOW = 7\n",
        "KP_RIGHT_ELBOW = 8\n",
        "KP_LEFT_WRIST = 9\n",
        "KP_RIGHT_WRIST = 10\n",
        "\n",
        "# Helper function for distance (Uses kp0_x, kp0_y format)\n",
        "def calculate_distance(df_calc, kp1_idx, kp2_idx):\n",
        "    x1_col, y1_col = f'kp{kp1_idx}_x', f'kp{kp1_idx}_y'\n",
        "    x2_col, y2_col = f'kp{kp2_idx}_x', f'kp{kp2_idx}_y'\n",
        "\n",
        "    required_cols = [x1_col, y1_col, x2_col, y2_col]\n",
        "    if not all(col in df_calc.columns for col in required_cols):\n",
        "        # print(f\"Warning: Missing one or more columns for distance: {', '.join(list(set(required_cols) - set(df_calc.columns)))}\")\n",
        "        return pd.Series(np.nan, index=df_calc.index)\n",
        "    return np.sqrt((df_calc[x1_col] - df_calc[x2_col])**2 + (df_calc[y1_col] - df_calc[y2_col])**2)\n",
        "\n",
        "# Helper function for centroid (Uses kp0_x, kp0_y format)\n",
        "def calculate_centroid_x(df_calc, kp_indices):\n",
        "    x_cols = [f'kp{idx}_x' for idx in kp_indices if f'kp{idx}_x' in df_calc.columns]\n",
        "    if not x_cols: return pd.Series(np.nan, index=df_calc.index)\n",
        "    return df_calc[x_cols].mean(axis=1)\n",
        "\n",
        "def calculate_centroid_y(df_calc, kp_indices):\n",
        "    y_cols = [f'kp{idx}_y' for idx in kp_indices if f'kp{idx}_y' in df_calc.columns]\n",
        "    if not y_cols: return pd.Series(np.nan, index=df_calc.index)\n",
        "    return df_calc[y_cols].mean(axis=1)\n",
        "\n",
        "# --- Face Features ---\n",
        "face_kp_indices = [KP_NOSE, KP_LEFT_EYE, KP_RIGHT_EYE, KP_LEFT_EAR, KP_RIGHT_EAR]\n",
        "if all(f'kp{idx}_x' in df.columns and f'kp{idx}_y' in df.columns for idx in [KP_LEFT_EYE, KP_RIGHT_EYE]):\n",
        "    df['face_eye_dist'] = calculate_distance(df, KP_LEFT_EYE, KP_RIGHT_EYE)\n",
        "\n",
        "df['face_centroid_x'] = calculate_centroid_x(df, face_kp_indices)\n",
        "df['face_centroid_y'] = calculate_centroid_y(df, face_kp_indices)\n",
        "\n",
        "# --- Hand Features ---\n",
        "# Define more hand keypoints if you have them (e.g., fingers)\n",
        "left_hand_kp_indices = [KP_LEFT_WRIST] #, KP_LEFT_ELBOW] # Example: Add elbow if part of \"hand gesture\" context\n",
        "right_hand_kp_indices = [KP_RIGHT_WRIST] #, KP_RIGHT_ELBOW]\n",
        "\n",
        "df['left_hand_centroid_x'] = calculate_centroid_x(df, left_hand_kp_indices)\n",
        "df['left_hand_centroid_y'] = calculate_centroid_y(df, left_hand_kp_indices)\n",
        "df['right_hand_centroid_x'] = calculate_centroid_x(df, right_hand_kp_indices)\n",
        "df['right_hand_centroid_y'] = calculate_centroid_y(df, right_hand_kp_indices)\n",
        "\n",
        "# Distance of hands to face (using face centroid)\n",
        "if 'face_centroid_x' in df.columns and 'face_centroid_y' in df.columns:\n",
        "    if 'left_hand_centroid_x' in df.columns and 'left_hand_centroid_y' in df.columns and df['face_centroid_x'].notna().any():\n",
        "        df['dist_left_hand_to_face'] = np.sqrt(\n",
        "            (df['left_hand_centroid_x'] - df['face_centroid_x'])**2 +\n",
        "            (df['left_hand_centroid_y'] - df['face_centroid_y'])**2\n",
        "        )\n",
        "    if 'right_hand_centroid_x' in df.columns and 'right_hand_centroid_y' in df.columns and df['face_centroid_x'].notna().any():\n",
        "        df['dist_right_hand_to_face'] = np.sqrt(\n",
        "            (df['right_hand_centroid_x'] - df['face_centroid_x'])**2 +\n",
        "            (df['right_hand_centroid_y'] - df['face_centroid_y'])**2\n",
        "        )\n",
        "else:\n",
        "    print(\"Warning: Face centroid columns not found or all NaN, cannot calculate hand-to-face distance.\")\n",
        "\n",
        "\n",
        "# --- Temporal Features (Velocity/Movement) ---\n",
        "# Ensure you have a time column, e.g., 'frame' or 'sec'\n",
        "# 'video_id_column' will be defined in section 2 below.\n",
        "# We anticipate its use here.\n",
        "target_column_temp_ref = 'playfully_engaged' # Temporary ref for this block, will be formally defined later\n",
        "video_id_column_temp_ref = 'source_video' # Temporary ref\n",
        "\n",
        "time_col_for_diff = 'frame' # Or 'sec', 'seconds_rounded' - choose one that increments consistently\n",
        "grouping_cols = [video_id_column_temp_ref]\n",
        "\n",
        "# Check if 'tracking_id' exists and is not in the exclusion list planned for later\n",
        "# This is a bit of a forward reference to 'columns_to_exclude_from_features'\n",
        "# A simpler check for now:\n",
        "if 'tracking_id' in df.columns:\n",
        "    # A more robust check would involve seeing if 'tracking_id' will be a feature or not.\n",
        "    # For now, if it exists, we assume it can be used for grouping temporal features.\n",
        "    # Typically, 'tracking_id' is an identifier, not a feature itself.\n",
        "    if 'tracking_id' not in [target_column_temp_ref, video_id_column_temp_ref, 'video_id', 'sec', 'seconds', 'time', 'task']: # common non-feature identifiers\n",
        "        grouping_cols.append('tracking_id')\n",
        "        print(f\"Temporal features will be grouped by: {grouping_cols}\")\n",
        "    else:\n",
        "        print(f\"Temporal features will be grouped by: {grouping_cols} ('tracking_id' seems to be excluded or target/video_id)\")\n",
        "else:\n",
        "    print(f\"Warning: 'tracking_id' column not found. Temporal features calculated per video ({video_id_column_temp_ref}).\")\n",
        "    print(f\"If multiple subjects per video without tracking_id, their temporal data might be mixed if not sorted/grouped properly.\")\n",
        "\n",
        "\n",
        "if video_id_column_temp_ref not in df.columns:\n",
        "    print(f\"Error: Anticipated video ID column '{video_id_column_temp_ref}' not found for temporal features. Skipping.\")\n",
        "elif time_col_for_diff in df.columns:\n",
        "    df = df.sort_values(by=grouping_cols + [time_col_for_diff])\n",
        "\n",
        "    features_to_diff = []\n",
        "    # Centroid velocities\n",
        "    if 'face_centroid_x' in df.columns: features_to_diff.extend(['face_centroid_x', 'face_centroid_y'])\n",
        "    if 'left_hand_centroid_x' in df.columns: features_to_diff.extend(['left_hand_centroid_x', 'left_hand_centroid_y'])\n",
        "    if 'right_hand_centroid_x' in df.columns: features_to_diff.extend(['right_hand_centroid_x', 'right_hand_centroid_y'])\n",
        "\n",
        "    # Optionally, add raw keypoint velocities (can create many features)\n",
        "    # for i in range(17): # Assuming 0-16 keypoints\n",
        "    #     if f'kp{i}_x' in df.columns: features_to_diff.append(f'kp{i}_x')\n",
        "    #     if f'kp{i}_y' in df.columns: features_to_diff.append(f'kp{i}_y')\n",
        "\n",
        "    for feature_col_name in features_to_diff:\n",
        "        if feature_col_name in df.columns:\n",
        "            # Calculate difference within each group\n",
        "            df[f'{feature_col_name}_vel'] = df.groupby(grouping_cols)[feature_col_name].diff().fillna(0)\n",
        "            # If you have deltaTime (time difference between frames), divide by it for true velocity.\n",
        "            # e.g., df['dt'] = df.groupby(grouping_cols)[time_col_for_diff].diff().fillna(method='bfill').fillna(1e-6)\n",
        "            # df[f'{feature_col_name}_vel'] = df.groupby(grouping_cols)[feature_col_name].diff().fillna(0) / df['dt']\n",
        "        else:\n",
        "            print(f\"Warning: Column {feature_col_name} not found for velocity calculation.\")\n",
        "\n",
        "\n",
        "    # Speeds (magnitude of velocity vectors)\n",
        "    if 'left_hand_centroid_x_vel' in df.columns and 'left_hand_centroid_y_vel' in df.columns:\n",
        "        df['left_hand_speed'] = np.sqrt(df['left_hand_centroid_x_vel']**2 + df['left_hand_centroid_y_vel']**2)\n",
        "    if 'right_hand_centroid_x_vel' in df.columns and 'right_hand_centroid_y_vel' in df.columns:\n",
        "        df['right_hand_speed'] = np.sqrt(df['right_hand_centroid_x_vel']**2 + df['right_hand_centroid_y_vel']**2)\n",
        "    if 'face_centroid_x_vel' in df.columns and 'face_centroid_y_vel' in df.columns:\n",
        "        df['face_speed'] = np.sqrt(df['face_centroid_x_vel']**2 + df['face_centroid_y_vel']**2)\n",
        "else:\n",
        "    print(f\"Warning: Time column '{time_col_for_diff}' (or video ID '{video_id_column_temp_ref}') not found. Skipping temporal feature generation.\")\n",
        "\n",
        "\n",
        "# --- Body Shape/Pose Features (Example) ---\n",
        "if all(f'kp{idx}_x' in df.columns and f'kp{idx}_y' in df.columns for idx in [KP_LEFT_SHOULDER, KP_RIGHT_SHOULDER]):\n",
        "    df['shoulder_width'] = calculate_distance(df, KP_LEFT_SHOULDER, KP_RIGHT_SHOULDER)\n",
        "\n",
        "newly_created_columns = [col for col in df.columns if col not in original_columns]\n",
        "print(f\"\\nShape of dataframe after feature engineering: {df.shape}\")\n",
        "if newly_created_columns:\n",
        "    print(f\"Newly created columns: {newly_created_columns}\")\n",
        "else:\n",
        "    print(\"No new columns were created during feature engineering (check column names and conditions).\")\n",
        "\n",
        "\n",
        "# --- 2. Define Target (y) and Prepare for Feature (X) Selection ---\n",
        "target_column = 'playfully_engaged'\n",
        "video_id_column = 'source_video' # IMPORTANT: Verify this is the correct column name\n",
        "\n",
        "if target_column not in df.columns:\n",
        "    print(f\"Error: Target column '{target_column}' not found in the dataframe.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "if video_id_column not in df.columns:\n",
        "    print(f\"Error: Video ID column '{video_id_column}' for data splitting not found.\")\n",
        "    print(f\"Please ensure '{video_id_column}' exists or update the 'video_id_column' variable.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "# Drop rows where the target variable is NaN\n",
        "df.dropna(subset=[target_column], inplace=True)\n",
        "print(f\"\\nShape of dataframe after dropping NaNs in target column '{target_column}': {df.shape}\")\n",
        "\n",
        "# Convert target variable to numeric\n",
        "if df[target_column].dtype == 'bool':\n",
        "    df[target_column] = df[target_column].astype(int)\n",
        "elif df[target_column].dtype == 'object':\n",
        "    print(f\"Target column '{target_column}' is of object type. Attempting to encode it.\")\n",
        "    le = LabelEncoder()\n",
        "    try:\n",
        "        df[target_column] = le.fit_transform(df[target_column])\n",
        "        print(f\"Target column '{target_column}' encoded. Classes: {le.classes_}\")\n",
        "        if len(le.classes_) > 2:\n",
        "            print(\"Warning: Target variable has more than two classes. This will be a multi-class classification.\")\n",
        "        elif len(le.classes_) <= 1:\n",
        "            print(f\"Error: Target column '{target_column}' has only one class after encoding ({le.classes_}). Cannot train a classifier.\")\n",
        "            exit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error encoding target column '{target_column}': {e}\")\n",
        "        exit()\n",
        "\n",
        "# Define feature columns\n",
        "potential_feature_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Columns to exclude from features (USER UPDATED LIST from original query)\n",
        "# Newly engineered features (if numeric and not listed here) will be included.\n",
        "columns_to_exclude_from_features = [\n",
        "    target_column, video_id_column,\n",
        "    'video_id', # if 'video_id' is different from video_id_column and also an identifier\n",
        "    'sec', 'seconds', 'seconds_rounded', 'sec_rounded', 'merge_key',\n",
        "    'angrily_engaged', 'playing_engaged', 'time', 'watching', 'frame', 'tracking_id','task'\n",
        "]\n",
        "# Add any other known non-feature or identifier columns if necessary.\n",
        "\n",
        "# Filter out columns from the exclusion list that might not exist in the dataframe\n",
        "columns_to_exclude_from_features = [col for col in columns_to_exclude_from_features if col in df.columns]\n",
        "\n",
        "feature_cols = [col for col in potential_feature_cols if col not in columns_to_exclude_from_features]\n",
        "\n",
        "if not feature_cols:\n",
        "    print(\"Error: No feature columns were identified. Please check the column names, types, and exclusion list.\")\n",
        "    print(f\"Potential numeric columns found: {potential_feature_cols}\")\n",
        "    print(f\"Columns excluded: {columns_to_exclude_from_features}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\nIdentified {len(feature_cols)} feature columns.\") # Cut down print for brevity: {feature_cols}\")\n",
        "print(f\"Target column: {target_column}\")\n",
        "print(f\"Video ID column for splitting: {video_id_column}\")\n",
        "\n",
        "\n",
        "# --- 3. Split Data into Training and Testing Sets based on Video IDs ---\n",
        "unique_videos = df[video_id_column].unique()\n",
        "print(f\"\\nFound {len(unique_videos)} unique videos for splitting.\")\n",
        "\n",
        "if len(unique_videos) < 2:\n",
        "    print(\"Error: Not enough unique videos to perform a train/test split. Need at least 2.\")\n",
        "    exit()\n",
        "\n",
        "test_size_videos = 0.3\n",
        "if len(unique_videos) == 1: # Cannot split if only 1 video\n",
        "    print(\"Error: Only 1 unique video found. Cannot split into train and test based on video ID.\")\n",
        "    # Alternative: Split randomly, but this is not ideal for video data.\n",
        "    # Or, use this one video for training and test on a different dataset if available.\n",
        "    # For now, we will exit.\n",
        "    exit()\n",
        "elif len(unique_videos) * test_size_videos < 1:\n",
        "    print(f\"Warning: Number of unique videos ({len(unique_videos)}) is small. Adjusting test_size for videos to ensure at least 1 test video.\")\n",
        "    test_video_count = 1\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_video_count, random_state=21, shuffle=True)\n",
        "else:\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_size_videos, random_state=21, shuffle=True)\n",
        "\n",
        "print(f\"Number of videos in training set: {len(train_video_ids)}\")\n",
        "print(f\"Number of videos in testing set: {len(test_video_ids)}\")\n",
        "\n",
        "if len(train_video_ids) == 0 or len(test_video_ids) == 0:\n",
        "    print(\"Error: Splitting videos resulted in an empty training or testing set of videos.\")\n",
        "    exit()\n",
        "\n",
        "train_df = df[df[video_id_column].isin(train_video_ids)].copy()\n",
        "test_df = df[df[video_id_column].isin(test_video_ids)].copy()\n",
        "\n",
        "if train_df.empty or test_df.empty:\n",
        "    print(\"Error: Training or testing dataframe is empty after filtering by video IDs.\")\n",
        "    exit()\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[target_column]\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "print(\"\\nData split into training and testing sets based on video IDs.\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "if X_train.empty or X_test.empty:\n",
        "    print(\"Error: X_train or X_test is empty. Check feature selection and data splitting.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Distribution of target variable in training set:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"Distribution of target variable in test set:\\n\", y_test.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "qgdAwocXRN4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- 4. Handle Missing Values in Features (Post-Split) ---\n",
        "print(f\"\\nMissing values in X_train before imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test before imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean') # Could also try 'median' or 'most_frequent'\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns, index=X_train.index)\n",
        "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(f\"Missing values in X_train after imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test after imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "\n",
        "# --- 5. Scale Numerical Features (Post-Split and Post-Imputation) ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"\\nFeatures scaled.\")\n",
        "\n",
        "# --- 6. Train and Evaluate SVM Model ---\n",
        "print(\"\\n--- Training SVM Model ---\")\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, class_weight='balanced', probability=True) # Added class_weight and probability\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_svm = svm_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nSVM Model Evaluation:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n",
        "\n",
        "# --- 7. (Optional) Train and Evaluate Other Models ---\n",
        "\n",
        "# --- Random Forest Classifier ---\n",
        "# print(\"\\n--- Training Random Forest Model ---\")\n",
        "# rf_model = RandomForestClassifier(n_estimators=100, random_state=21, class_weight='balanced', n_jobs=-1)\n",
        "# rf_model.fit(X_train_scaled, y_train) # Tree models are less sensitive to scaling, but it doesn't hurt\n",
        "#\n",
        "# y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "#\n",
        "# print(\"\\nRandom Forest Model Evaluation:\")\n",
        "# print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
        "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
        "#\n",
        "# # Feature importances (if you want to see them)\n",
        "# # importances_rf = pd.Series(rf_model.feature_importances_, index=X_train.columns)\n",
        "# # print(\"\\nTop 10 Feature Importances (Random Forest):\\n\", importances_rf.nlargest(10))\n",
        "\n",
        "\n",
        "# --- XGBoost Classifier ---\n",
        "# print(\"\\n--- Training XGBoost Model ---\")\n",
        "# # Handle potential class imbalance with scale_pos_weight if it's binary classification\n",
        "# # For binary classification:\n",
        "# # counts = np.bincount(y_train)\n",
        "# # scale_pos_weight_xgb = counts[0] / counts[1] if len(counts) > 1 and counts[1] > 0 else 1\n",
        "\n",
        "# xgb_model = xgb.XGBClassifier(\n",
        "#     objective='binary:logistic', # or 'multi:softprob' for multi-class\n",
        "#     eval_metric='logloss',       # or 'mlogloss'\n",
        "#     use_label_encoder=False,     # Suppress warning with newer XGBoost\n",
        "#     random_state=21,\n",
        "#     # scale_pos_weight=scale_pos_weight_xgb # for binary class imbalance\n",
        "#     n_estimators=100\n",
        "# )\n",
        "# xgb_model.fit(X_train_scaled, y_train)\n",
        "#\n",
        "# y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
        "#\n",
        "# print(\"\\nXGBoost Model Evaluation:\")\n",
        "# print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
        "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
        "\n",
        "\n",
        "# --- LightGBM Classifier ---\n",
        "# print(\"\\n--- Training LightGBM Model ---\")\n",
        "# lgbm_model = lgb.LGBMClassifier(random_state=21, class_weight='balanced', n_estimators=100)\n",
        "# lgbm_model.fit(X_train_scaled, y_train)\n",
        "#\n",
        "# y_pred_lgbm = lgbm_model.predict(X_test_scaled)\n",
        "#\n",
        "# print(\"\\nLightGBM Model Evaluation:\")\n",
        "# print(\"Accuracy:\", accuracy_score(y_test, y_pred_lgbm))\n",
        "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lgbm))\n",
        "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lgbm))\n",
        "\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "id": "Qi_m_jNWTb-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "VLlA87eNU_0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your data is loaded into df\n",
        "# and you already split by video_id\n",
        "\n",
        "# Example split (replace with your actual split if different)\n",
        "unique_videos = df[\"source_video\"].unique()\n",
        "train_videos = unique_videos[:int(len(unique_videos) * 0.8)]\n",
        "test_videos = unique_videos[int(len(unique_videos) * 0.8):]\n",
        "\n",
        "# Filter the DataFrames\n",
        "train_df = df[df[\"source_video\"].isin(train_videos)]\n",
        "test_df = df[df[\"source_video\"].isin(test_videos)]\n",
        "\n",
        "# Show unique video IDs\n",
        "print(\"🎓 Train Set Video IDs:\")\n",
        "print(sorted(train_df[\"source_video\"].unique()))\n",
        "\n",
        "print(\"\\n🧪 Test Set Video IDs:\")\n",
        "print(sorted(test_df[\"source_video\"].unique()))\n"
      ],
      "metadata": {
        "id": "c4hCw6w1VBLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1yHPvb-OVRRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP3\n"
      ],
      "metadata": {
        "id": "s_lxwjKHWDH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/merged_with_forward_labels_with_tasks.csv')"
      ],
      "metadata": {
        "id": "A8ubuLCDWFTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df[\"task\"]=='p']\n",
        "print(\"Data loaded successfully.\")\n",
        "print(\"Shape of the dataframe:\", df.shape)"
      ],
      "metadata": {
        "id": "ACX4CjmtWbAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- 2. Define Target (y) and Prepare for Feature (X) Selection ---\n",
        "target_column = 'playfully_engaged'\n",
        "video_id_column = 'source_video' # IMPORTANT: Verify this is the correct column name for video IDs in your CSV\n",
        "\n",
        "if target_column not in df.columns:\n",
        "    print(f\"Error: Target column '{target_column}' not found in the dataframe.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "if video_id_column not in df.columns:\n",
        "    print(f\"Error: Video ID column '{video_id_column}' for data splitting not found.\")\n",
        "    print(f\"Please ensure '{video_id_column}' exists or update the 'video_id_column' variable.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "# Drop rows where the target variable is NaN, as they cannot be used for training or evaluation.\n",
        "df.dropna(subset=[target_column], inplace=True)\n",
        "print(f\"\\nShape of dataframe after dropping NaNs in target column '{target_column}': {df.shape}\")\n",
        "\n",
        "# Convert target variable to numeric if it's not already\n",
        "if df[target_column].dtype == 'bool':\n",
        "    df[target_column] = df[target_column].astype(int)\n",
        "elif df[target_column].dtype == 'object':\n",
        "    print(f\"Target column '{target_column}' is of object type. Attempting to encode it.\")\n",
        "    le = LabelEncoder()\n",
        "    try:\n",
        "        df[target_column] = le.fit_transform(df[target_column])\n",
        "        print(f\"Target column '{target_column}' encoded. Classes: {le.classes_}\")\n",
        "        if len(le.classes_) > 2:\n",
        "            print(\"Warning: Target variable has more than two classes. This will be a multi-class SVM.\")\n",
        "        elif len(le.classes_) <= 1:\n",
        "            print(f\"Error: Target column '{target_column}' has only one class after encoding ({le.classes_}). Cannot train a classifier.\")\n",
        "            exit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error encoding target column '{target_column}': {e}\")\n",
        "        print(\"Please ensure the target column contains appropriate values for classification.\")\n",
        "        exit()\n",
        "\n",
        "# Define feature columns\n",
        "# Identify potential keypoint columns (typically floats or integers)\n",
        "potential_feature_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Columns to exclude from features (USER UPDATED LIST)\n",
        "# This list now means other engagement labels (like focused_engagement) MIGHT become features if numeric\n",
        "columns_to_exclude_from_features = [\n",
        "    target_column, video_id_column, # video_id_column is used for splitting, not as a feature\n",
        "    'video_id', # if 'video_id' is different from video_id_column and also an identifier\n",
        "    'sec', 'seconds', 'seconds_rounded', 'sec_rounded', 'merge_key',\n",
        "    'angrily_engaged', 'playing_engaged', 'time', 'watching', 'frame', 'tracking_id','task'\n",
        "]\n",
        "# Add any other known non-feature or identifier columns if necessary.\n",
        "\n",
        "# Filter out columns from the exclusion list that might not exist in the dataframe\n",
        "columns_to_exclude_from_features = [col for col in columns_to_exclude_from_features if col in df.columns]\n",
        "\n",
        "feature_cols = [col for col in potential_feature_cols if col not in columns_to_exclude_from_features]\n",
        "\n",
        "if not feature_cols:\n",
        "    print(\"Error: No feature columns were identified. Please check the column names, types, and exclusion list.\")\n",
        "    print(f\"Potential numeric columns found: {potential_feature_cols}\")\n",
        "    print(f\"Columns excluded: {columns_to_exclude_from_features}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\nIdentified {len(feature_cols)} feature columns: {feature_cols}\")\n",
        "print(f\"Target column: {target_column}\")\n",
        "print(f\"Video ID column for splitting: {video_id_column}\")\n",
        "\n",
        "# --- 3. Split Data into Training and Testing Sets based on Video IDs ---\n",
        "unique_videos = df[video_id_column].unique()\n",
        "print(f\"\\nFound {len(unique_videos)} unique videos for splitting.\")\n",
        "\n",
        "if len(unique_videos) < 2: # Need at least one video for train and one for test\n",
        "    print(\"Error: Not enough unique videos to perform a train/test split. Need at least 2.\")\n",
        "    exit()\n",
        "# Ensure test_size is not too large for the number of videos\n",
        "test_size_videos = 0.3\n",
        "if len(unique_videos) * test_size_videos < 1:\n",
        "    print(f\"Warning: Number of unique videos ({len(unique_videos)}) is small. Adjusting test_size for videos to ensure at least 1 test video.\")\n",
        "    # Ensure at least 1 video for testing, if possible.\n",
        "    # If only 2 videos, it will be 1 train, 1 test. If 3, 2 train, 1 test.\n",
        "    test_video_count = 1\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_video_count, random_state=21, shuffle=True)\n",
        "else:\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_size_videos, random_state=21, shuffle=True)\n",
        "\n",
        "\n",
        "print(f\"Number of videos in training set: {len(train_video_ids)}\")\n",
        "print(f\"Number of videos in testing set: {len(test_video_ids)}\")\n",
        "\n",
        "if len(train_video_ids) == 0 or len(test_video_ids) == 0:\n",
        "    print(\"Error: Splitting videos resulted in an empty training or testing set of videos.\")\n",
        "    exit()\n",
        "\n",
        "# Create training and testing dataframes\n",
        "train_df = df[df[video_id_column].isin(train_video_ids)].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "test_df = df[df[video_id_column].isin(test_video_ids)].copy()\n",
        "\n",
        "if train_df.empty or test_df.empty:\n",
        "    print(\"Error: Training or testing dataframe is empty after filtering by video IDs.\")\n",
        "    exit()\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[target_column]\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "print(\"\\nData split into training and testing sets based on video IDs.\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "if X_train.empty or X_test.empty:\n",
        "    print(\"Error: X_train or X_test is empty. Check feature selection and data splitting.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Distribution of target variable in training set:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"Distribution of target variable in test set:\\n\", y_test.value_counts(normalize=True))\n",
        "\n",
        "# --- 4. Handle Missing Values in Features (Post-Split) ---\n",
        "print(f\"\\nMissing values in X_train before imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test before imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test) # Use transform only on test data\n",
        "\n",
        "# Convert imputed arrays back to DataFrames with original column names\n",
        "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns, index=X_train.index)\n",
        "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(f\"Missing values in X_train after imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test after imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "# --- 5. Scale Numerical Features (Post-Split and Post-Imputation) ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test) # Use transform only on test data\n",
        "\n",
        "print(\"\\nFeatures scaled.\")"
      ],
      "metadata": {
        "id": "QEcthCf-WfIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 4. Handle Missing Values in Features (Post-Split) ---\n",
        "print(f\"\\nMissing values in X_train before imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test before imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean') # Could also try 'median' or 'most_frequent'\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns, index=X_train.index)\n",
        "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(f\"Missing values in X_train after imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test after imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "\n",
        "# --- 5. Scale Numerical Features (Post-Split and Post-Imputation) ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"\\nFeatures scaled.\")"
      ],
      "metadata": {
        "id": "RsOPP9-yWqwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- XGBoost Classifier ---\n",
        "print(\"\\n--- Training XGBoost Model ---\")\n",
        "# Handle potential class imbalance with scale_pos_weight if it's binary classification\n",
        "# # For binary classification:\n",
        "# # counts = np.bincount(y_train)\n",
        "# # scale_pos_weight_xgb = counts[0] / counts[1] if len(counts) > 1 and counts[1] > 0 else 1\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "     objective='binary:logistic', # or 'multi:softprob' for multi-class\n",
        "     eval_metric='logloss',       # or 'mlogloss'\n",
        "     use_label_encoder=False,     # Suppress warning with newer XGBoost\n",
        "     random_state=21,\n",
        "     # scale_pos_weight=scale_pos_weight_xgb # for binary class imbalance\n",
        "     n_estimators=100\n",
        " )\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
        "#\n",
        "print(\"\\nXGBoost Model Evaluation:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n"
      ],
      "metadata": {
        "id": "p_tJwmVjWvuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Training LightGBM Model ---\")\n",
        "lgbm_model = lgb.LGBMClassifier(random_state=21, class_weight='balanced', n_estimators=100)\n",
        "lgbm_model.fit(X_train_scaled, y_train)\n",
        "#\n",
        "y_pred_lgbm = lgbm_model.predict(X_test_scaled)\n",
        "#\n",
        "print(\"\\nLightGBM Model Evaluation:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lgbm))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lgbm))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lgbm))"
      ],
      "metadata": {
        "id": "_EqWukyBXG7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-la3OsgDbBUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### randomsearch svm"
      ],
      "metadata": {
        "id": "XaVpxk2sbBaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example using loguniform (better for C and gamma)\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.datasets import make_classification # To generate sample data\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.stats import loguniform\n",
        "\n",
        "\n",
        "svm_model = SVC(random_state=21, class_weight='balanced', probability=True)\n",
        "param_dist = {\n",
        "    'C': loguniform(1e-2, 1e2), # Example range: 0.01 to 100\n",
        "    'gamma': loguniform(1e-4, 1e-1), # Example range: 0.0001 to 0.1\n",
        "    'kernel': ['rbf', 'linear']\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "   estimator=svm_model,\n",
        "   param_distributions=param_dist,\n",
        "   n_iter=25, # Try 100 random combinations\n",
        "   cv=2,\n",
        "   scoring='accuracy', # Or other relevant metric\n",
        "   n_jobs=-1,\n",
        "   verbose=2,\n",
        "   random_state=21\n",
        ")\n",
        "\n",
        "print(\"\\nStarting RandomizedSearchCV for SVM...\")\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "print(\"RandomizedSearchCV fitting complete.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"\\nBest Hyperparameters Found (RandomizedSearch):\")\n",
        "print(random_search.best_params_)\n",
        "print(\"\\nBest Cross-Validation Score (RandomizedSearch):\")\n",
        "print(random_search.best_score_)\n",
        "\n",
        "best_svm_model_random = random_search.best_estimator_\n",
        "y_pred_best_svm_random = best_svm_model_random.predict(X_test_scaled)\n",
        "print(\"\\nPerformance of the Best SVM Model from RandomizedSearch on the (Sample) Test Set:\")\n",
        "print(classification_report(y_test, y_pred_best_svm_random))"
      ],
      "metadata": {
        "id": "oI8g8BHdXPBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best_svm_random))"
      ],
      "metadata": {
        "id": "2J1wjAU-X-pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best_svm_random))"
      ],
      "metadata": {
        "id": "1fd_Rt_Zt2bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iH2TslCOva2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 4\n"
      ],
      "metadata": {
        "id": "dXMvSQZdv1SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# --- 6. Apply PCA (Try different values for n_components) ---\n",
        "pca = PCA(n_components=10)  # You can try 5, 10, 15, etc.\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "print(f\"\\nPCA applied. Explained variance ratio (first 10 components):\\n{pca.explained_variance_ratio_}\")\n",
        "\n",
        "# --- 7. Train an SVM Model on PCA Features ---\n",
        "model = SVC(C= np.float64(50.79933389275528), gamma= np.float64(0.07427781917044056), kernel= 'rbf', random_state=42)\n",
        "model.fit(X_train_pca, y_train)\n",
        "\n",
        "print(\"\\nSVM model trained on PCA-reduced features.\")\n",
        "\n",
        "# --- 8. Evaluate the Model ---\n",
        "y_pred = model.predict(X_test_pca)\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "GoEf-RHIv2ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 5"
      ],
      "metadata": {
        "id": "dUP9lUVAybzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Build the MLP model\n",
        "mlp_model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')  # Use 'softmax' and adjust units if multiclass\n",
        "])\n",
        "\n",
        "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Add early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = mlp_model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_data=(X_test_scaled, y_test),\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "l1SJdlPtydLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# --- Parameters ---\n",
        "sequence_length = 30  # Number of timesteps per sequence\n",
        "feature_count = X_train.shape[1]\n",
        "\n",
        "# --- Sequence Preparation Function ---\n",
        "def create_sequences(X, y, video_ids, sequence_length):\n",
        "    X_seq, y_seq = [], []\n",
        "    current_video = None\n",
        "    buffer_X, buffer_y = [], []\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        if video_ids.iloc[i] != current_video:\n",
        "            buffer_X, buffer_y = [], []\n",
        "            current_video = video_ids.iloc[i]\n",
        "\n",
        "        buffer_X.append(X.iloc[i].values)\n",
        "        buffer_y.append(y.iloc[i])\n",
        "\n",
        "        if len(buffer_X) == sequence_length:\n",
        "            X_seq.append(np.array(buffer_X))\n",
        "            y_seq.append(buffer_y[-1])  # Use label of last frame in window\n",
        "            buffer_X.pop(0)\n",
        "            buffer_y.pop(0)\n",
        "\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# --- Prepare Sequences ---\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train, train_df[video_id_column], sequence_length)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test, y_test, test_df[video_id_column], sequence_length)\n",
        "\n",
        "print(\"X_train_seq shape:\", X_train_seq.shape)\n",
        "print(\"y_train_seq shape:\", y_train_seq.shape)\n",
        "\n",
        "# --- Binary Classification LSTM Model ---\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(sequence_length, feature_count), return_sequences=False))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  # 🔁 Binary output\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# --- Train Model ---\n",
        "history = model.fit(X_train_seq, y_train_seq, epochs=10, batch_size=32, validation_data=(X_test_seq, y_test_seq))\n",
        "\n",
        "# --- Evaluate Model ---\n",
        "loss, acc = model.evaluate(X_test_seq, y_test_seq)\n",
        "print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
        "\n",
        "# --- Optional: Print detailed metrics ---\n",
        "y_pred = (model.predict(X_test_seq) > 0.5).astype(\"int32\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_seq, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_seq, y_pred))\n"
      ],
      "metadata": {
        "id": "raewHAy-z-KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Train a Random Forest Classifier ---\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=None,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'  # Helps with imbalanced classes if any\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# --- 7. Evaluate the Model ---\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\n--- Evaluation Results (Random Forest) ---\")\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Optional: Feature Importance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "importances = rf_model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "feature_names_sorted = [feature_cols[i] for i in indices]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Feature Importances (Random Forest)\")\n",
        "plt.bar(range(len(importances)), importances[indices], align=\"center\")\n",
        "plt.xticks(range(len(importances)), feature_names_sorted, rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hPVzipAUOnhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iLFlIQz7On5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_b0sCd7zIvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- 6. Train the SVM Model ---\n",
        "print(\"\\nTraining the SVM model...\")\n",
        "# Ensure y_train has more than one class for stratification or balanced class weights\n",
        "if len(y_train.unique()) <= 1:\n",
        "    print(f\"Error: Training target variable 'y_train' has only one class: {y_train.unique()}. Cannot train classifier.\")\n",
        "    exit()\n",
        "\n",
        "svm_model = SVC(C= np.float64(50.79933389275528), gamma= np.float64(0.07427781917044056), kernel= 'rbf', random_state=42)\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "print(\"SVM model trained successfully.\")\n",
        "\n",
        "# --- 7. Make Predictions and Evaluate the Model ---\n",
        "print(\"\\nMaking predictions on the test set...\")\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "if 'le' in globals() and hasattr(le, 'classes_'):\n",
        "    target_names_report = [str(cls) for cls in le.classes_]\n",
        "    # Ensure labels for confusion matrix and report match actual unique values in y_test/y_pred\n",
        "    unique_test_labels_sorted = sorted(y_test.unique())\n",
        "    # If le.classes_ were [False, True] -> [0, 1], and y_test contains 0, 1, this is fine.\n",
        "    # If le.classes_ were ['A', 'B'] -> [0, 1], this is fine.\n",
        "    # We need to ensure the order of target_names_report matches the sorted unique labels if they are numeric.\n",
        "    if all(isinstance(c, (int, float)) for c in unique_test_labels_sorted) and \\\n",
        "       all(isinstance(c, str) for c in target_names_report) and \\\n",
        "       len(unique_test_labels_sorted) == len(target_names_report):\n",
        "        # This attempts to map sorted numeric labels to the string names from LabelEncoder\n",
        "        # This might need adjustment if LabelEncoder classes are not simple True/False or ordered strings\n",
        "        report_labels_ordered = unique_test_labels_sorted\n",
        "    else:\n",
        "        report_labels_ordered = le.transform(le.classes_) # Use the transformed numeric values corresponding to le.classes_\n",
        "\n",
        "else: # Fallback if LabelEncoder was not used (e.g., target was already 0/1)\n",
        "    unique_test_labels_sorted = sorted(y_test.unique())\n",
        "    target_names_report = [f\"Class {i}\" for i in unique_test_labels_sorted]\n",
        "    report_labels_ordered = unique_test_labels_sorted\n",
        "\n",
        "try:\n",
        "    print(classification_report(y_test, y_pred, labels=report_labels_ordered, target_names=target_names_report, zero_division=0))\n",
        "except Exception as e_report:\n",
        "    print(f\"Could not generate classification report with specific target names/labels: {e_report}\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "try:\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=report_labels_ordered)\n",
        "    print(pd.DataFrame(cm, index=target_names_report, columns=target_names_report))\n",
        "except Exception as e_cm:\n",
        "    print(f\"Could not generate confusion matrix with specific labels/names: {e_cm}\")\n",
        "    cm = confusion_matrix(y_test, y_pred) # Fallback\n",
        "    print(cm)\n",
        "\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")\n"
      ],
      "metadata": {
        "id": "UD2-ZOr5zIzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap\n"
      ],
      "metadata": {
        "id": "ckFOilYF0QtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# Note: KernelExplainer is slow, but works with any model\n",
        "explainer = shap.KernelExplainer(svm_model.predict, X_train_scaled[:100])  # Use a small sample\n",
        "shap_values = explainer.shap_values(X_test_scaled[:50])  # Again, small sample for speed\n",
        "\n"
      ],
      "metadata": {
        "id": "PK_juDSe1OuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary plot\n",
        "shap.summary_plot(shap_values, X_test.iloc[:50], feature_names=feature_cols)\n"
      ],
      "metadata": {
        "id": "JOlAXi6Z1U2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(shap_values)"
      ],
      "metadata": {
        "id": "yRxpZD8o7rzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model.save('/content/drive/MyDrive/svm_model.h')"
      ],
      "metadata": {
        "id": "CB6x3MaR7gF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ikC3Up691FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 6- CNN"
      ],
      "metadata": {
        "id": "hYHDQDaeEEF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load your keypoints CSV\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/merged_with_forward_labels_with_tasks.csv\")\n",
        "df=df[df[\"task\"]=='p']\n",
        "print(\"Data loaded successfully.\")\n",
        "print(\"Shape of the dataframe:\", df.shape)\n",
        "# Set output directory\n",
        "output_dir = \"/content/drive/MyDrive/pose_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Parameters\n",
        "image_size = 64\n",
        "num_keypoints = 17\n",
        "\n",
        "# Create pose images\n",
        "def keypoints_to_image(row):\n",
        "    img = np.zeros((image_size, image_size), dtype=np.uint8)\n",
        "    for i in range(num_keypoints):\n",
        "        x = row.get(f\"kp{i}_x\", np.nan)\n",
        "        y = row.get(f\"kp{i}_y\", np.nan)\n",
        "        if not np.isnan(x) and not np.isnan(y):\n",
        "            x = int(np.clip(x / 640 * image_size, 0, image_size - 1))\n",
        "            y = int(np.clip(y / 480 * image_size, 0, image_size - 1))\n",
        "            cv2.circle(img, (x, y), radius=2, color=255, thickness=-1)\n",
        "    return img\n",
        "\n",
        "# Generate and save images\n",
        "image_paths = []\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    img = keypoints_to_image(row)\n",
        "    path = os.path.join(output_dir, f\"pose_{idx}.png\")\n",
        "    cv2.imwrite(path, img)\n",
        "    image_paths.append(path)\n",
        "\n",
        "# Save new CSV\n",
        "df[\"pose_image_path\"] = image_paths\n",
        "df.to_csv(\"/content/drive/MyDrive/keypoints_with_pose_images.csv\", index=False)\n",
        "print(\"✅ Done. CSV saved as keypoints_with_pose_images.csv\")\n"
      ],
      "metadata": {
        "id": "1tcQzV13EFkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# --- 1. Load and clean the CSV ---\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/keypoints_with_pose_images.csv\")\n",
        "df = df.dropna(subset=['pose_image_path', 'playfully_engaged'])\n",
        "\n",
        "# Convert label to int if needed\n",
        "if df['playfully_engaged'].dtype != 'int':\n",
        "    le = LabelEncoder()\n",
        "    df['playfully_engaged'] = le.fit_transform(df['playfully_engaged'])\n",
        "\n",
        "# --- 2. Train/Test split by video ---\n",
        "unique_videos = df['source_video'].unique()\n",
        "train_videos, test_videos = train_test_split(unique_videos, test_size=0.2, random_state=42)\n",
        "\n",
        "train_df = df[df['source_video'].isin(train_videos)].reset_index(drop=True)\n",
        "test_df = df[df['source_video'].isin(test_videos)].reset_index(drop=True)\n",
        "\n",
        "# --- 3. Dataset Class ---\n",
        "class PoseImageDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.df = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.df.loc[idx, 'pose_image_path']\n",
        "        label = int(self.df.loc[idx, 'playfully_engaged'])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# --- 4. Image Transform ---\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# --- 5. Dataloaders ---\n",
        "train_dataset = PoseImageDataset(train_df, transform)\n",
        "test_dataset = PoseImageDataset(test_df, transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# --- 6. Simple CNN Model ---\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 8 * 8, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "# --- 7. Train the CNN ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    acc = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {running_loss:.4f}, Accuracy: {acc:.2f}%\")\n",
        "\n",
        "# --- 8. Evaluate the CNN ---\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "print(f\"\\nTest Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "gYKlPqrlEg3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_Lh5C4NHH5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 7"
      ],
      "metadata": {
        "id": "D40PgbECYEIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "8I8IF3icYHpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df[\"task\"]=='e']\n",
        "print(\"Data loaded successfully.\")\n",
        "print(\"Shape of the dataframe:\", df.shape)"
      ],
      "metadata": {
        "id": "mq8IpD0NYFix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- 2. Define Target (y) and Prepare for Feature (X) Selection ---\n",
        "target_column = 'playfully_engaged'\n",
        "video_id_column = 'source_video' # IMPORTANT: Verify this is the correct column name for video IDs in your CSV\n",
        "\n",
        "if target_column not in df.columns:\n",
        "    print(f\"Error: Target column '{target_column}' not found in the dataframe.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "if video_id_column not in df.columns:\n",
        "    print(f\"Error: Video ID column '{video_id_column}' for data splitting not found.\")\n",
        "    print(f\"Please ensure '{video_id_column}' exists or update the 'video_id_column' variable.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "# Drop rows where the target variable is NaN, as they cannot be used for training or evaluation.\n",
        "df.dropna(subset=[target_column], inplace=True)\n",
        "print(f\"\\nShape of dataframe after dropping NaNs in target column '{target_column}': {df.shape}\")\n",
        "\n",
        "# Convert target variable to numeric if it's not already\n",
        "if df[target_column].dtype == 'bool':\n",
        "    df[target_column] = df[target_column].astype(int)\n",
        "elif df[target_column].dtype == 'object':\n",
        "    print(f\"Target column '{target_column}' is of object type. Attempting to encode it.\")\n",
        "    le = LabelEncoder()\n",
        "    try:\n",
        "        df[target_column] = le.fit_transform(df[target_column])\n",
        "        print(f\"Target column '{target_column}' encoded. Classes: {le.classes_}\")\n",
        "        if len(le.classes_) > 2:\n",
        "            print(\"Warning: Target variable has more than two classes. This will be a multi-class SVM.\")\n",
        "        elif len(le.classes_) <= 1:\n",
        "            print(f\"Error: Target column '{target_column}' has only one class after encoding ({le.classes_}). Cannot train a classifier.\")\n",
        "            exit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error encoding target column '{target_column}': {e}\")\n",
        "        print(\"Please ensure the target column contains appropriate values for classification.\")\n",
        "        exit()\n",
        "\n",
        "# Define feature columns\n",
        "# Identify potential keypoint columns (typically floats or integers)\n",
        "potential_feature_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Columns to exclude from features (USER UPDATED LIST)\n",
        "# This list now means other engagement labels (like focused_engagement) MIGHT become features if numeric\n",
        "columns_to_exclude_from_features = [\n",
        "    target_column, video_id_column, # video_id_column is used for splitting, not as a feature\n",
        "    'video_id', # if 'video_id' is different from video_id_column and also an identifier\n",
        "    'sec', 'seconds', 'seconds_rounded', 'sec_rounded', 'merge_key',\n",
        "    'angrily_engaged', 'playing_engaged', 'time', 'watching', 'frame', 'tracking_id','task'\n",
        "]\n",
        "# Add any other known non-feature or identifier columns if necessary.\n",
        "\n",
        "# Filter out columns from the exclusion list that might not exist in the dataframe\n",
        "columns_to_exclude_from_features = [col for col in columns_to_exclude_from_features if col in df.columns]\n",
        "\n",
        "feature_cols = [col for col in potential_feature_cols if col not in columns_to_exclude_from_features]\n",
        "\n",
        "if not feature_cols:\n",
        "    print(\"Error: No feature columns were identified. Please check the column names, types, and exclusion list.\")\n",
        "    print(f\"Potential numeric columns found: {potential_feature_cols}\")\n",
        "    print(f\"Columns excluded: {columns_to_exclude_from_features}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\nIdentified {len(feature_cols)} feature columns: {feature_cols}\")\n",
        "print(f\"Target column: {target_column}\")\n",
        "print(f\"Video ID column for splitting: {video_id_column}\")\n",
        "\n",
        "# --- 3. Split Data into Training and Testing Sets based on Video IDs ---\n",
        "unique_videos = df[video_id_column].unique()\n",
        "print(f\"\\nFound {len(unique_videos)} unique videos for splitting.\")\n",
        "\n",
        "if len(unique_videos) < 2: # Need at least one video for train and one for test\n",
        "    print(\"Error: Not enough unique videos to perform a train/test split. Need at least 2.\")\n",
        "    exit()\n",
        "# Ensure test_size is not too large for the number of videos\n",
        "test_size_videos = 0.3\n",
        "if len(unique_videos) * test_size_videos < 1:\n",
        "    print(f\"Warning: Number of unique videos ({len(unique_videos)}) is small. Adjusting test_size for videos to ensure at least 1 test video.\")\n",
        "    # Ensure at least 1 video for testing, if possible.\n",
        "    # If only 2 videos, it will be 1 train, 1 test. If 3, 2 train, 1 test.\n",
        "    test_video_count = 1\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_video_count, random_state=2, shuffle=True)\n",
        "else:\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_size_videos, random_state=2, shuffle=True)\n",
        "\n",
        "\n",
        "print(f\"Number of videos in training set: {len(train_video_ids)}\")\n",
        "print(f\"Number of videos in testing set: {len(test_video_ids)}\")\n",
        "\n",
        "if len(train_video_ids) == 0 or len(test_video_ids) == 0:\n",
        "    print(\"Error: Splitting videos resulted in an empty training or testing set of videos.\")\n",
        "    exit()\n",
        "\n",
        "# Create training and testing dataframes\n",
        "train_df = df[df[video_id_column].isin(train_video_ids)].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "test_df = df[df[video_id_column].isin(test_video_ids)].copy()\n",
        "\n",
        "if train_df.empty or test_df.empty:\n",
        "    print(\"Error: Training or testing dataframe is empty after filtering by video IDs.\")\n",
        "    exit()\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[target_column]\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "print(\"\\nData split into training and testing sets based on video IDs.\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "if X_train.empty or X_test.empty:\n",
        "    print(\"Error: X_train or X_test is empty. Check feature selection and data splitting.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Distribution of target variable in training set:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"Distribution of target variable in test set:\\n\", y_test.value_counts(normalize=True))\n",
        "\n",
        "# --- 4. Handle Missing Values in Features (Post-Split) ---\n",
        "print(f\"\\nMissing values in X_train before imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test before imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test) # Use transform only on test data\n",
        "\n",
        "# Convert imputed arrays back to DataFrames with original column names\n",
        "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns, index=X_train.index)\n",
        "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(f\"Missing values in X_train after imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test after imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "# --- 5. Scale Numerical Features (Post-Split and Post-Imputation) ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test) # Use transform only on test data\n",
        "\n",
        "print(\"\\nFeatures scaled.\")"
      ],
      "metadata": {
        "id": "92OY338QYR-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example using loguniform (better for C and gamma)\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.datasets import make_classification # To generate sample data\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.stats import loguniform\n",
        "\n",
        "\n",
        "svm_model = SVC(random_state=21, class_weight='balanced', probability=True)\n",
        "param_dist = {\n",
        "    'C': loguniform(1e-2, 1e2), # Example range: 0.01 to 100\n",
        "    'gamma': loguniform(1e-4, 1e-1), # Example range: 0.0001 to 0.1\n",
        "    'kernel': ['rbf', 'linear']\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "   estimator=svm_model,\n",
        "   param_distributions=param_dist,\n",
        "   n_iter=25, # Try 100 random combinations\n",
        "   cv=2,\n",
        "   scoring='accuracy', # Or other relevant metric\n",
        "   n_jobs=-1,\n",
        "   verbose=2,\n",
        "   random_state=21\n",
        ")\n",
        "\n",
        "print(\"\\nStarting RandomizedSearchCV for SVM...\")\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "print(\"RandomizedSearchCV fitting complete.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"\\nBest Hyperparameters Found (RandomizedSearch):\")\n",
        "print(random_search.best_params_)\n",
        "print(\"\\nBest Cross-Validation Score (RandomizedSearch):\")\n",
        "print(random_search.best_score_)\n",
        "\n",
        "best_svm_model_random = random_search.best_estimator_\n",
        "y_pred_best_svm_random = best_svm_model_random.predict(X_test_scaled)\n",
        "print(\"\\nPerformance of the Best SVM Model from RandomizedSearch on the (Sample) Test Set:\")\n",
        "print(classification_report(y_test, y_pred_best_svm_random))"
      ],
      "metadata": {
        "id": "uM7GUvqMYcNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 8"
      ],
      "metadata": {
        "id": "zSiOWa6Vl1nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/merged_with_forward_labels_with_tasks.csv')"
      ],
      "metadata": {
        "id": "o_08erHxl5HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df[\"task\"]=='d']\n",
        "print(\"Data loaded successfully.\")\n",
        "print(\"Shape of the dataframe:\", df.shape)"
      ],
      "metadata": {
        "id": "dl9Y55IumLAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- 2. Define Target (y) and Prepare for Feature (X) Selection ---\n",
        "target_column = 'playfully_engaged'\n",
        "video_id_column = 'source_video' # IMPORTANT: Verify this is the correct column name for video IDs in your CSV\n",
        "\n",
        "if target_column not in df.columns:\n",
        "    print(f\"Error: Target column '{target_column}' not found in the dataframe.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "if video_id_column not in df.columns:\n",
        "    print(f\"Error: Video ID column '{video_id_column}' for data splitting not found.\")\n",
        "    print(f\"Please ensure '{video_id_column}' exists or update the 'video_id_column' variable.\")\n",
        "    print(f\"Available columns: {df.columns.tolist()}\")\n",
        "    exit()\n",
        "\n",
        "# Drop rows where the target variable is NaN, as they cannot be used for training or evaluation.\n",
        "df.dropna(subset=[target_column], inplace=True)\n",
        "print(f\"\\nShape of dataframe after dropping NaNs in target column '{target_column}': {df.shape}\")\n",
        "\n",
        "# Convert target variable to numeric if it's not already\n",
        "if df[target_column].dtype == 'bool':\n",
        "    df[target_column] = df[target_column].astype(int)\n",
        "elif df[target_column].dtype == 'object':\n",
        "    print(f\"Target column '{target_column}' is of object type. Attempting to encode it.\")\n",
        "    le = LabelEncoder()\n",
        "    try:\n",
        "        df[target_column] = le.fit_transform(df[target_column])\n",
        "        print(f\"Target column '{target_column}' encoded. Classes: {le.classes_}\")\n",
        "        if len(le.classes_) > 2:\n",
        "            print(\"Warning: Target variable has more than two classes. This will be a multi-class SVM.\")\n",
        "        elif len(le.classes_) <= 1:\n",
        "            print(f\"Error: Target column '{target_column}' has only one class after encoding ({le.classes_}). Cannot train a classifier.\")\n",
        "            exit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error encoding target column '{target_column}': {e}\")\n",
        "        print(\"Please ensure the target column contains appropriate values for classification.\")\n",
        "        exit()\n",
        "\n",
        "# Define feature columns\n",
        "# Identify potential keypoint columns (typically floats or integers)\n",
        "potential_feature_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Columns to exclude from features (USER UPDATED LIST)\n",
        "# This list now means other engagement labels (like focused_engagement) MIGHT become features if numeric\n",
        "columns_to_exclude_from_features = [\n",
        "    target_column, video_id_column, # video_id_column is used for splitting, not as a feature\n",
        "    'video_id', # if 'video_id' is different from video_id_column and also an identifier\n",
        "    'sec', 'seconds', 'seconds_rounded', 'sec_rounded', 'merge_key',\n",
        "    'angrily_engaged', 'playing_engaged', 'time', 'watching', 'frame', 'tracking_id','task'\n",
        "]\n",
        "# Add any other known non-feature or identifier columns if necessary.\n",
        "\n",
        "# Filter out columns from the exclusion list that might not exist in the dataframe\n",
        "columns_to_exclude_from_features = [col for col in columns_to_exclude_from_features if col in df.columns]\n",
        "\n",
        "feature_cols = [col for col in potential_feature_cols if col not in columns_to_exclude_from_features]\n",
        "\n",
        "if not feature_cols:\n",
        "    print(\"Error: No feature columns were identified. Please check the column names, types, and exclusion list.\")\n",
        "    print(f\"Potential numeric columns found: {potential_feature_cols}\")\n",
        "    print(f\"Columns excluded: {columns_to_exclude_from_features}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\nIdentified {len(feature_cols)} feature columns: {feature_cols}\")\n",
        "print(f\"Target column: {target_column}\")\n",
        "print(f\"Video ID column for splitting: {video_id_column}\")\n",
        "\n",
        "# --- 3. Split Data into Training and Testing Sets based on Video IDs ---\n",
        "unique_videos = df[video_id_column].unique()\n",
        "print(f\"\\nFound {len(unique_videos)} unique videos for splitting.\")\n",
        "\n",
        "if len(unique_videos) < 2: # Need at least one video for train and one for test\n",
        "    print(\"Error: Not enough unique videos to perform a train/test split. Need at least 2.\")\n",
        "    exit()\n",
        "# Ensure test_size is not too large for the number of videos\n",
        "test_size_videos = 0.3\n",
        "if len(unique_videos) * test_size_videos < 1:\n",
        "    print(f\"Warning: Number of unique videos ({len(unique_videos)}) is small. Adjusting test_size for videos to ensure at least 1 test video.\")\n",
        "    # Ensure at least 1 video for testing, if possible.\n",
        "    # If only 2 videos, it will be 1 train, 1 test. If 3, 2 train, 1 test.\n",
        "    test_video_count = 1\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_video_count, random_state=21, shuffle=True)\n",
        "else:\n",
        "    train_video_ids, test_video_ids = train_test_split(unique_videos, test_size=test_size_videos, random_state=21, shuffle=True)\n",
        "\n",
        "\n",
        "print(f\"Number of videos in training set: {len(train_video_ids)}\")\n",
        "print(f\"Number of videos in testing set: {len(test_video_ids)}\")\n",
        "\n",
        "if len(train_video_ids) == 0 or len(test_video_ids) == 0:\n",
        "    print(\"Error: Splitting videos resulted in an empty training or testing set of videos.\")\n",
        "    exit()\n",
        "\n",
        "# Create training and testing dataframes\n",
        "train_df = df[df[video_id_column].isin(train_video_ids)].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "test_df = df[df[video_id_column].isin(test_video_ids)].copy()\n",
        "\n",
        "if train_df.empty or test_df.empty:\n",
        "    print(\"Error: Training or testing dataframe is empty after filtering by video IDs.\")\n",
        "    exit()\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[target_column]\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "print(\"\\nData split into training and testing sets based on video IDs.\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "if X_train.empty or X_test.empty:\n",
        "    print(\"Error: X_train or X_test is empty. Check feature selection and data splitting.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Distribution of target variable in training set:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"Distribution of target variable in test set:\\n\", y_test.value_counts(normalize=True))\n",
        "\n",
        "# --- 4. Handle Missing Values in Features (Post-Split) ---\n",
        "print(f\"\\nMissing values in X_train before imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test before imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test) # Use transform only on test data\n",
        "\n",
        "# Convert imputed arrays back to DataFrames with original column names\n",
        "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns, index=X_train.index)\n",
        "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(f\"Missing values in X_train after imputation: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in X_test after imputation: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "# --- 5. Scale Numerical Features (Post-Split and Post-Imputation) ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test) # Use transform only on test data\n",
        "\n",
        "print(\"\\nFeatures scaled.\")"
      ],
      "metadata": {
        "id": "K--akXMDmXN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Train and Evaluate SVM Model ---\n",
        "print(\"\\n--- Training SVM Model ---\")\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, class_weight='balanced', probability=True) # Added class_weight and probability\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_svm = svm_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nSVM Model Evaluation:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n"
      ],
      "metadata": {
        "id": "jIKk0TzVl3Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CkLW2apHnZfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXP 9- LSTM"
      ],
      "metadata": {
        "id": "7Mmah1a2oLwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/merged_with_forward_labels_with_tasks.csv')"
      ],
      "metadata": {
        "id": "zeCQcrGLpCGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df[\"task\"]=='p']\n",
        "print(\"Data loaded successfully.\")\n",
        "print(\"Shape of the dataframe:\", df.shape)"
      ],
      "metadata": {
        "id": "f6wDciQ9pE-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdff = pd.DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(dff.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(dff.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = pd.concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "metadata": {
        "id": "l_C6WcF5ojLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baby_df=df.copy()"
      ],
      "metadata": {
        "id": "rObq13Q2o1lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# keypoint sütunları\n",
        "keypoint_cols = [col for col in df.columns if \"kp\" in col and (\"_x\" in col or \"_y\" in col)]\n",
        "target_column=\"playfully_engaged\"\n",
        "\n"
      ],
      "metadata": {
        "id": "V4e3HrHJpPa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler # Import the scaler\n",
        "import numpy as np\n",
        "# Assuming baby_df, keypoint_cols, and target_column are defined\n",
        "# and series_to_supervised is a defined function.\n",
        "\n",
        "# Your existing code:\n",
        "all_sequences_X = []\n",
        "all_sequences_y = []\n",
        "all_video_ids = []\n",
        "\n",
        "# Tüm video id'leri topla\n",
        "unique_videos = baby_df['source_video'].unique()\n",
        "print(f\"Toplam video: {len(unique_videos)}\")\n",
        "\n",
        "# Train-test video bazlı split\n",
        "train_videos, test_videos = train_test_split(unique_videos, test_size=0.3, random_state=42)\n",
        "\n",
        "X_train_list, y_train_list = [], []\n",
        "X_test_list, y_test_list = [], []\n",
        "\n",
        "for video in unique_videos:\n",
        "    video_df = baby_df[baby_df['source_video'] == video]\n",
        "    for tid in video_df['tracking_id'].unique():\n",
        "        person_df = video_df[video_df['tracking_id'] == tid].copy()\n",
        "        person_df = person_df.sort_values('sec')\n",
        "\n",
        "        # Keypoint değerleri\n",
        "        kp_data = person_df[keypoint_cols].values\n",
        "        label_data = person_df[target_column].values\n",
        "\n",
        "        # Supervised format\n",
        "        # Assuming n_in = 30, n_out = 1 for series_to_supervised\n",
        "        # and series_to_supervised handles cases with insufficient data for a full sequence\n",
        "        if len(kp_data) > 30: # Ensure there's enough data for at least one sequence\n",
        "            supervised_kp = series_to_supervised(kp_data, n_in=30, n_out=1)\n",
        "            # Ensure supervised_kp is not empty and has the expected structure\n",
        "            if not supervised_kp.empty:\n",
        "                # The last kp_data.shape[1] columns in supervised_kp are the target if n_out > 0 and target is part of kp_data\n",
        "                # Based on X_seq = supervised_kp.iloc[:, :-kp_data.shape[1]].values,\n",
        "                # it implies the supervised function creates features and targets,\n",
        "                # and you are selecting only the input features for X_seq.\n",
        "                # And y_seq = label_data[30:] implies labels are taken directly from original label_data.\n",
        "\n",
        "                X_seq_input_features = supervised_kp.iloc[:, :30*kp_data.shape[1]].values # Adjust if series_to_supervised output differs\n",
        "\n",
        "                # Ensure y_seq aligns with X_seq\n",
        "                # If series_to_supervised creates sequences of length 30 input and 1 output step,\n",
        "                # and you take y_seq from label_data[30:], this should align if each row in supervised_kp\n",
        "                # corresponds to a starting point in label_data.\n",
        "                num_sequences = X_seq_input_features.shape[0]\n",
        "\n",
        "                if num_sequences > 0 and len(label_data) >= 30 + num_sequences -1 : # Check alignment\n",
        "                    # X_seq = X_seq_input_features.reshape((num_sequences, 30, kp_data.shape[1]))\n",
        "                    # y_seq_aligned = label_data[30 : 30 + num_sequences] # Align y_seq with X_seq\n",
        "\n",
        "                    # The original code for X_seq and y_seq generation:\n",
        "                    X_seq = supervised_kp.iloc[:, :-kp_data.shape[1]].values # Assumes last columns are target features to be dropped\n",
        "                    y_seq_current = label_data[30:] # This needs to align with the number of sequences in X_seq\n",
        "\n",
        "                    # Make sure X_seq and y_seq_current have the same number of samples\n",
        "                    # The number of samples from series_to_supervised is typically len(data) - n_in - n_out + 1\n",
        "                    # For X_seq, it would be len(kp_data) - 30 - 1 + 1 = len(kp_data) - 30\n",
        "                    # So y_seq should be label_data[30 : 30 + (len(kp_data) - 30)] = label_data[30 : len(kp_data)]\n",
        "\n",
        "                    # Adjusting y_seq to match the number of sequences generated by series_to_supervised more reliably\n",
        "                    # Assuming series_to_supervised(data, n_in, n_out) generates (len(data) - n_in - n_out + 1) samples.\n",
        "                    # Here, n_out=1, so it generates (len(kp_data) - 30) samples for X.\n",
        "                    num_generated_sequences = len(kp_data) - 30\n",
        "                    if num_generated_sequences > 0:\n",
        "                        X_seq = X_seq_input_features[:num_generated_sequences] # Take the generated sequences\n",
        "                        X_seq = X_seq.reshape((num_generated_sequences, 30, kp_data.shape[1]))\n",
        "                        y_seq = label_data[30 : 30 + num_generated_sequences]\n",
        "\n",
        "\n",
        "                        if video in train_videos:\n",
        "                            X_train_list.append(X_seq)\n",
        "                            y_train_list.append(y_seq)\n",
        "                        else:\n",
        "                            X_test_list.append(X_seq)\n",
        "                            y_test_list.append(y_seq)\n",
        "\n",
        "# Final train/test arrays\n",
        "if X_train_list: # Check if lists are not empty\n",
        "    X_train = np.concatenate(X_train_list, axis=0)\n",
        "    y_train = np.concatenate(y_train_list, axis=0)\n",
        "else:\n",
        "    X_train, y_train = np.array([]), np.array([]) # Or handle as an error/warning\n",
        "\n",
        "if X_test_list:\n",
        "    X_test = np.concatenate(X_test_list, axis=0)\n",
        "    y_test = np.concatenate(y_test_list, axis=0)\n",
        "else:\n",
        "    X_test, y_test = np.array([]), np.array([])\n",
        "\n",
        "print(\"✅ Train/test verisi hazır.\")\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)\n",
        "\n",
        "# --- SCALING THE DATA ---\n",
        "# Check if X_train is not empty before proceeding with scaling\n",
        "if X_train.size > 0 and X_test.size > 0 : # Ensure X_test also has data if you intend to scale it\n",
        "    # 1. Initialize the Scaler\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # 2. Reshape X_train for scaling\n",
        "    #    The scaler expects a 2D array (n_samples, n_features).\n",
        "    #    Your X_train is 3D (n_samples, n_timesteps, n_keypoint_features).\n",
        "    #    We reshape it to (n_samples * n_timesteps, n_keypoint_features),\n",
        "    #    fit the scaler, transform, and then reshape back.\n",
        "    original_shape_X_train = X_train.shape\n",
        "    X_train_reshaped = X_train.reshape(-1, original_shape_X_train[2])\n",
        "\n",
        "    # 3. Fit the scaler on the TRAINING data\n",
        "    scaler.fit(X_train_reshaped)\n",
        "\n",
        "    # 4. Transform the TRAINING data\n",
        "    X_train_scaled_reshaped = scaler.transform(X_train_reshaped)\n",
        "    # Reshape X_train back to its original 3D shape\n",
        "    X_train_scaled = X_train_scaled_reshaped.reshape(original_shape_X_train)\n",
        "\n",
        "    # 5. Reshape and Transform the TESTING data\n",
        "    original_shape_X_test = X_test.shape\n",
        "    X_test_reshaped = X_test.reshape(-1, original_shape_X_test[2])\n",
        "    X_test_scaled_reshaped = scaler.transform(X_test_reshaped)\n",
        "    # Reshape X_test back to its original 3D shape\n",
        "    X_test_scaled = X_test_scaled_reshaped.reshape(original_shape_X_test)\n",
        "\n",
        "    print(\"✅ Veri ölçeklendirildi.\")\n",
        "    print(\"X_train_scaled:\", X_train_scaled.shape)\n",
        "    print(\"X_test_scaled:\", X_test_scaled.shape)\n",
        "\n",
        "    # Now you would use X_train_scaled, y_train, X_test_scaled, and y_test for your model\n",
        "    # For example: model.fit(X_train_scaled, y_train)\n",
        "    #            model.evaluate(X_test_scaled, y_test)\n",
        "elif X_train.size == 0:\n",
        "    print(\"⚠️ X_train is empty. Scaling cannot be performed.\")\n",
        "    # Assign empty arrays or handle as appropriate for your workflow\n",
        "    X_train_scaled, X_test_scaled = np.array([]), np.array([])\n",
        "elif X_test.size == 0 and X_train.size > 0 : # X_train has data, but X_test is empty\n",
        "    scaler = StandardScaler()\n",
        "    original_shape_X_train = X_train.shape\n",
        "    X_train_reshaped = X_train.reshape(-1, original_shape_X_train[2])\n",
        "    scaler.fit(X_train_reshaped)\n",
        "    X_train_scaled_reshaped = scaler.transform(X_train_reshaped)\n",
        "    X_train_scaled = X_train_scaled_reshaped.reshape(original_shape_X_train)\n",
        "    X_test_scaled = np.array([]) # X_test remains empty\n",
        "    print(\"✅ X_train verisi ölçeklendirildi. X_test boş.\")\n",
        "    print(\"X_train_scaled:\", X_train_scaled.shape)\n",
        "\n",
        "\n",
        "# Note: You generally do NOT scale your target variables (y_train, y_test),\n",
        "# especially if they are categorical labels for classification.\n",
        "# If it's a regression task with a wide range of output values,\n",
        "# target scaling might sometimes be considered, but it's less common."
      ],
      "metadata": {
        "id": "46__yz4poNYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# ✅ LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ✅ Erken durdurma\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# ✅ Modeli eğit\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_scaled, y_test),\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "n9vBwu6epUGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())\n",
        "\n"
      ],
      "metadata": {
        "id": "2qVfWxYerogH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- Provided series_to_supervised function ---\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    \"\"\"\n",
        "    Frame a time series as a supervised learning dataset.\n",
        "    Arguments:\n",
        "        data: Sequence of observations as a list or NumPy array.\n",
        "        n_in: Number of lag observations as input (X).\n",
        "        n_out: Number of observations as output (y).\n",
        "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
        "    Returns:\n",
        "        Pandas DataFrame of series framed for supervised learning.\n",
        "    \"\"\"\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    dff = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(dff.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(dff.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg\n",
        "\n",
        "# --- Configuration ---\n",
        "N_IN_TIMESTEPS = 20 # Number of input timesteps for the sequence\n",
        "N_OUT_TIMESTEPS = 1 # Corresponds to n_out in series_to_supervised, relevant for X_seq slicing\n",
        "\n",
        "\n",
        "\n",
        "# 1. Collect all unique video IDs\n",
        "unique_videos = baby_df['source_video'].unique()\n",
        "print(f\"Toplam video: {len(unique_videos)}\")\n",
        "\n",
        "# 2. Split videos into training and testing sets\n",
        "train_videos, test_videos = train_test_split(unique_videos, test_size=0.3, random_state=42)\n",
        "print(f\"Training videos: {len(train_videos)}, Test videos: {len(test_videos)}\")\n",
        "\n",
        "# 3. Fit the StandardScaler ONLY on the training data\n",
        "scaler = StandardScaler()\n",
        "all_train_kp_for_scaling = []\n",
        "\n",
        "print(\"Collecting data for scaler fitting (from training videos only)...\")\n",
        "for video_id in train_videos:\n",
        "    video_df = baby_df[baby_df['source_video'] == video_id]\n",
        "    for tid in video_df['tracking_id'].unique():\n",
        "        person_df = video_df[video_df['tracking_id'] == tid].copy()\n",
        "        # Ensure data is sorted by time for sequence generation\n",
        "        person_df = person_df.sort_values('sec')\n",
        "\n",
        "        # Need at least N_IN_TIMESTEPS + 1 rows to produce one sequence\n",
        "        if len(person_df) > N_IN_TIMESTEPS:\n",
        "            kp_data = person_df[keypoint_cols].values\n",
        "            all_train_kp_for_scaling.append(kp_data)\n",
        "\n",
        "if not all_train_kp_for_scaling:\n",
        "    # This can happen if training videos are too short or have no valid tracks\n",
        "    print(\"Warning: No data available from training videos to fit the scaler. Scaling will not be applied.\")\n",
        "    # Optionally, raise an error or handle as per your needs\n",
        "    # For this example, we'll proceed without a fitted scaler, which means kp_scaled will be same as kp_data\n",
        "    # A better approach might be to ensure sufficient training data or use a default scaler.\n",
        "    # For simplicity, we'll make scaler.transform do nothing if not fitted.\n",
        "    # A real `StandardScaler` would error if transform is called before fit.\n",
        "    # So, we create a dummy scaler if no data.\n",
        "    class DummyScaler:\n",
        "        def fit(self, data): pass\n",
        "        def transform(self, data): return data\n",
        "    scaler = DummyScaler()\n",
        "\n",
        "else:\n",
        "    concatenated_train_kp = np.concatenate(all_train_kp_for_scaling, axis=0)\n",
        "    if concatenated_train_kp.shape[0] > 0 : # Ensure there is data to fit\n",
        "        scaler.fit(concatenated_train_kp)\n",
        "        print(\"Scaler fitted on training data.\")\n",
        "    else: # Should be caught by all_train_kp_for_scaling check, but as a safeguard\n",
        "        print(\"Warning: Concatenated training keypoints resulted in empty data. Scaler not fitted.\")\n",
        "        class DummyScaler: # Define dummy scaler again if fitting fails\n",
        "            def fit(self, data): pass\n",
        "            def transform(self, data): return data\n",
        "        scaler = DummyScaler()\n",
        "\n",
        "\n",
        "# 4. Prepare sequences for training and testing sets\n",
        "X_train_list, y_train_list = [], []\n",
        "X_test_list, y_test_list = [], []\n",
        "\n",
        "NUM_KEYPOINT_FEATURES = len(keypoint_cols)\n",
        "\n",
        "print(\"Processing videos to create sequences...\")\n",
        "for video_id in unique_videos:\n",
        "    video_df = baby_df[baby_df['source_video'] == video_id]\n",
        "    for tid in video_df['tracking_id'].unique():\n",
        "        person_df = video_df[video_df['tracking_id'] == tid].copy()\n",
        "        person_df = person_df.sort_values('sec')\n",
        "\n",
        "        # Sequences can only be formed if there are more data points than N_IN_TIMESTEPS\n",
        "        if len(person_df) <= N_IN_TIMESTEPS:\n",
        "            # print(f\"Skipping track {tid} in video {video_id} due to insufficient data points ({len(person_df)}).\")\n",
        "            continue\n",
        "\n",
        "        kp_data = person_df[keypoint_cols].values\n",
        "        label_data = person_df[target_column].values.ravel() # .ravel() if target_column is a list of one item\n",
        "\n",
        "        # Apply the PRE-FITTED scaler\n",
        "        kp_scaled = scaler.transform(kp_data)\n",
        "\n",
        "        # Convert to supervised learning format\n",
        "        # n_out=1 means series_to_supervised will also create columns for var(t) using original data\n",
        "        supervised_kp_df = series_to_supervised(kp_scaled, n_in=N_IN_TIMESTEPS, n_out=N_OUT_TIMESTEPS)\n",
        "\n",
        "        if supervised_kp_df.empty:\n",
        "            # print(f\"Skipping track {tid} in video {video_id} as series_to_supervised resulted in empty dataframe.\")\n",
        "            continue\n",
        "\n",
        "        # The last 'NUM_KEYPOINT_FEATURES * N_OUT_TIMESTEPS' columns are the 'y' part from series_to_supervised\n",
        "        # We want only the input part (X)\n",
        "        X_seq = supervised_kp_df.iloc[:, :-(NUM_KEYPOINT_FEATURES * N_OUT_TIMESTEPS)].values\n",
        "\n",
        "        num_sequences = X_seq.shape[0]\n",
        "        if num_sequences == 0:\n",
        "            continue\n",
        "\n",
        "        # Labels correspond to the end of the input window (or start of output window)\n",
        "        # series_to_supervised drops the first N_IN_TIMESTEPS rows\n",
        "        # So, the first sequence's label corresponds to label_data[N_IN_TIMESTEPS]\n",
        "        y_seq = label_data[N_IN_TIMESTEPS : N_IN_TIMESTEPS + num_sequences]\n",
        "\n",
        "        # Ensure X_seq and y_seq have a consistent number of samples\n",
        "        if X_seq.shape[0] != len(y_seq):\n",
        "            print(f\"Warning: Mismatch in X and y sequence lengths for track {tid}, video {video_id}. Skipping.\")\n",
        "            print(f\"X_seq shape[0]: {X_seq.shape[0]}, y_seq len: {len(y_seq)}\")\n",
        "            continue\n",
        "\n",
        "        # Reshape X_seq to (samples, timesteps, features)\n",
        "        X_seq_reshaped = X_seq.reshape((num_sequences, N_IN_TIMESTEPS, NUM_KEYPOINT_FEATURES))\n",
        "\n",
        "        if video_id in train_videos:\n",
        "            X_train_list.append(X_seq_reshaped)\n",
        "            y_train_list.append(y_seq)\n",
        "        elif video_id in test_videos: # Make sure it's explicitly in test_videos\n",
        "            X_test_list.append(X_seq_reshaped)\n",
        "            y_test_list.append(y_seq)\n",
        "\n",
        "# 5. Final train/test arrays concatenation\n",
        "if X_train_list:\n",
        "    X_train = np.concatenate(X_train_list, axis=0)\n",
        "    y_train = np.concatenate(y_train_list, axis=0)\n",
        "else:\n",
        "    X_train = np.empty((0, N_IN_TIMESTEPS, NUM_KEYPOINT_FEATURES))\n",
        "    y_train = np.empty((0,))\n",
        "    print(\"Warning: Training data is empty after processing.\")\n",
        "\n",
        "if X_test_list:\n",
        "    X_test = np.concatenate(X_test_list, axis=0)\n",
        "    y_test = np.concatenate(y_test_list, axis=0)\n",
        "else:\n",
        "    X_test = np.empty((0, N_IN_TIMESTEPS, NUM_KEYPOINT_FEATURES))\n",
        "    y_test = np.empty((0,))\n",
        "    print(\"Warning: Test data is empty after processing.\")\n",
        "\n",
        "print(\"✅ Train/test verisi hazır.\")\n",
        "print(\"X_train shape:\", X_train.shape, \"| y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape, \"| y_test shape:\", y_test.shape)\n",
        "\n",
        "# Further checks\n",
        "if X_train.shape[0] == 0 and len(train_videos) > 0:\n",
        "    print(\"Note: X_train is empty. This might be due to all training video tracks being too short or other processing issues.\")\n",
        "if X_test.shape[0] == 0 and len(test_videos) > 0:\n",
        "     print(\"Note: X_test is empty. This might be due to all test video tracks being too short or other processing issues.\")"
      ],
      "metadata": {
        "id": "nf5Bk5cCrv3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# ✅ LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ✅ Erken durdurma\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# ✅ Modeli eğit\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "iz3tyCS6zL3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ALEXNET"
      ],
      "metadata": {
        "id": "0UVNe3Oo-xye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "\n",
        "n_in_steps = 30  # Sequence length (will be Height for 2D CNN input)\n",
        "\n",
        "# --- 1. Determine number of features and padding ---\n",
        "num_original_features = len(keypoint_cols)\n",
        "\n",
        "# For 2D CNN, target_H and target_W are not used to reshape each timestep's features into a small image.\n",
        "# Instead, padded_feature_size will be the width of our input image, and n_in_steps the height.\n",
        "# We still might want to pad features to a consistent size, e.g., to make it a power of 2 or a round number.\n",
        "# Let's keep the original padding logic for `padded_feature_size`.\n",
        "# This means each of the `n_in_steps` rows in our 2D input will have `padded_feature_size` columns.\n",
        "target_H_orig_padding_logic = int(np.ceil(np.sqrt(num_original_features)))\n",
        "target_W_orig_padding_logic = target_H_orig_padding_logic\n",
        "padded_feature_size = target_H_orig_padding_logic * target_W_orig_padding_logic # This will be the WIDTH of our 2D input\n",
        "padding_needed = padded_feature_size - num_original_features\n",
        "\n",
        "print(f\"Original features per time step: {num_original_features}\")\n",
        "print(f\"Each time step will be padded to: {padded_feature_size} features (this will be the input WIDTH for 2D CNN).\")\n",
        "print(f\"Padding needed per time step: {padding_needed}\")\n",
        "print(f\"Input to 2D CNN will have H={n_in_steps}, W={padded_feature_size}\")\n",
        "\n",
        "# --- 2. Split video IDs for training and testing ---\n",
        "if 'source_video' not in baby_df.columns:\n",
        "    raise ValueError(\"DataFrame must contain 'source_video' column for splitting.\")\n",
        "unique_videos = baby_df['source_video'].unique()\n",
        "\n",
        "train_videos = np.array([])\n",
        "test_videos = np.array([])\n",
        "\n",
        "if len(unique_videos) < 2:\n",
        "    print(\"Warning: Too few unique videos for video-based train/test split.\")\n",
        "    if len(unique_videos) == 1:\n",
        "        print(\"Only one unique video found. Using all data for training and creating an empty test set.\")\n",
        "        train_videos = unique_videos\n",
        "    else:\n",
        "        print(\"Error: No unique videos found. Cannot proceed.\")\n",
        "        exit()\n",
        "else:\n",
        "    train_videos, test_videos = train_test_split(unique_videos, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Total unique videos: {len(unique_videos)}\")\n",
        "print(f\"Training videos: {list(train_videos)}, Count: {len(train_videos)}\")\n",
        "print(f\"Testing videos: {list(test_videos)}, Count: {len(test_videos)}\")\n",
        "\n",
        "\n",
        "# --- 3. Fit Scaler on Training Data ---\n",
        "print(\"Fitting scaler on training data...\")\n",
        "scaler = StandardScaler()\n",
        "scaler_fitted = False\n",
        "\n",
        "if len(train_videos) > 0:\n",
        "    training_kp_data_for_scaler = []\n",
        "    for video_id in train_videos:\n",
        "        video_df = baby_df[baby_df['source_video'] == video_id]\n",
        "        for tid in video_df['tracking_id'].unique():\n",
        "            person_df = video_df[(video_df['tracking_id'] == tid) & (video_df['source_video'] == video_id)].copy().sort_values('sec')\n",
        "            # Ensure there's enough data to form at least one sequence for scaling purposes as well\n",
        "            if not person_df.empty and len(person_df[keypoint_cols]) >= n_in_steps:\n",
        "                training_kp_data_for_scaler.append(person_df[keypoint_cols].values)\n",
        "\n",
        "    if training_kp_data_for_scaler:\n",
        "        all_train_kp_flat = np.concatenate(training_kp_data_for_scaler, axis=0)\n",
        "        if all_train_kp_flat.shape[0] > 0:\n",
        "            scaler.fit(all_train_kp_flat)\n",
        "            print(\"Scaler fitted.\")\n",
        "            scaler_fitted = True\n",
        "        else:\n",
        "            print(\"Warning: Concatenated training keypoint data is empty. Scaler will not be fitted.\")\n",
        "    else:\n",
        "        print(\"Warning: No keypoint data found for training videos to fit the scaler. Scaler will not be fitted.\")\n",
        "else:\n",
        "    print(\"Warning: No training videos available to fit scaler. Scaler will not be fitted.\")\n",
        "\n",
        "\n",
        "# --- 4. Prepare Sequences for 2D CNN ---\n",
        "X_train_list, y_train_list = [], []\n",
        "X_test_list, y_test_list = [], []\n",
        "\n",
        "# Determine which videos to process for sequence generation\n",
        "videos_to_assign_to_train = train_videos\n",
        "videos_to_assign_to_test = test_videos\n",
        "\n",
        "print(\"Preparing sequences for 2D CNN...\")\n",
        "for video_id in unique_videos:\n",
        "    video_df = baby_df[baby_df['source_video'] == video_id]\n",
        "    for tid in video_df['tracking_id'].unique():\n",
        "        person_df = video_df[(video_df['tracking_id'] == tid) & (video_df['source_video'] == video_id)].copy()\n",
        "        person_df = person_df.sort_values('sec')\n",
        "\n",
        "        if len(person_df) < n_in_steps:\n",
        "            continue\n",
        "\n",
        "        kp_data_original = person_df[keypoint_cols].values\n",
        "        if scaler_fitted:\n",
        "            kp_data_processed = scaler.transform(kp_data_original)\n",
        "        else:\n",
        "            kp_data_processed = kp_data_original\n",
        "\n",
        "        label_data = person_df[target_column].values\n",
        "\n",
        "        num_sequences_possible = len(kp_data_processed) - n_in_steps + 1\n",
        "        if num_sequences_possible <= 0:\n",
        "            continue\n",
        "\n",
        "        current_X_sequences_list_for_person = [] # Store sequences for current person\n",
        "        current_y_sequences_list_for_person = []\n",
        "\n",
        "        for i in range(num_sequences_possible):\n",
        "            # Get the window of n_in_steps for keypoint data\n",
        "            raw_feature_sequence = kp_data_processed[i : i + n_in_steps] # Shape: (n_in_steps, num_original_features)\n",
        "\n",
        "            # Create the 2D \"image\" for the sequence: (n_in_steps, padded_feature_size)\n",
        "            sequence_2d_image = np.zeros((n_in_steps, padded_feature_size), dtype=np.float32)\n",
        "\n",
        "            for t_idx in range(n_in_steps):\n",
        "                features_at_t = raw_feature_sequence[t_idx, :] # Features for one time step\n",
        "                if padding_needed > 0:\n",
        "                    padded_features_at_t = np.pad(features_at_t, (0, padding_needed), 'constant', constant_values=0.0)\n",
        "                else:\n",
        "                    padded_features_at_t = features_at_t\n",
        "                sequence_2d_image[t_idx, :] = padded_features_at_t\n",
        "\n",
        "            # Add channel dimension: (1, n_in_steps, padded_feature_size)\n",
        "            # This ensures each sequence has a channel dimension.\n",
        "            current_X_sequences_list_for_person.append(sequence_2d_image[np.newaxis, :, :])\n",
        "            current_y_sequences_list_for_person.append(label_data[i + n_in_steps - 1])\n",
        "\n",
        "        if not current_X_sequences_list_for_person:\n",
        "            continue\n",
        "\n",
        "        # Concatenate all sequences from this person\n",
        "        # Each item in list is (1, n_in_steps, padded_feature_size)\n",
        "        # Resulting shape: (num_person_sequences, 1, n_in_steps, padded_feature_size)\n",
        "        X_person_sequences = np.concatenate(current_X_sequences_list_for_person, axis=0)\n",
        "        y_person_sequences = np.array(current_y_sequences_list_for_person)\n",
        "\n",
        "        if video_id in videos_to_assign_to_train:\n",
        "            X_train_list.append(X_person_sequences)\n",
        "            y_train_list.append(y_person_sequences)\n",
        "        elif video_id in videos_to_assign_to_test:\n",
        "            X_test_list.append(X_person_sequences)\n",
        "            y_test_list.append(y_person_sequences)\n",
        "\n",
        "# --- 5. Final Train/Test Arrays ---\n",
        "# Input shape for 2D CNN: (N, C, H, W) where C=1, H=n_in_steps, W=padded_feature_size\n",
        "if X_train_list:\n",
        "    X_train = np.concatenate(X_train_list, axis=0)\n",
        "    y_train = np.concatenate(y_train_list, axis=0).astype(np.int64)\n",
        "else:\n",
        "    X_train = np.empty((0, 1, n_in_steps, padded_feature_size), dtype=np.float32)\n",
        "    y_train = np.array([], dtype=np.int64)\n",
        "\n",
        "if X_test_list:\n",
        "    X_test = np.concatenate(X_test_list, axis=0)\n",
        "    y_test = np.concatenate(y_test_list, axis=0).astype(np.int64)\n",
        "else:\n",
        "    X_test = np.empty((0, 1, n_in_steps, padded_feature_size), dtype=np.float32)\n",
        "    y_test = np.array([], dtype=np.int64)\n",
        "\n",
        "print(\"✅ Train/test data prepared for 2D CNN.\")\n",
        "# This print should now reflect the channel dimension if data preparation is correct\n",
        "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)\n",
        "\n",
        "num_classes = 0\n",
        "if y_train.size > 0:\n",
        "    unique_train_labels = np.unique(y_train)\n",
        "    num_classes = len(unique_train_labels)\n",
        "    print(f\"Number of unique classes in y_train: {num_classes}\")\n",
        "    print(f\"Unique y_train labels: {unique_train_labels}\")\n",
        "elif y_test.size > 0:\n",
        "    unique_test_labels = np.unique(y_test)\n",
        "    num_classes = len(unique_test_labels)\n",
        "    print(f\"Warning: y_train is empty. Using y_test to determine num_classes: {num_classes}\")\n",
        "    print(f\"Unique y_test labels: {unique_test_labels}\")\n",
        "else:\n",
        "    print(\"Error: Both y_train and y_test are empty. Cannot determine num_classes.\")\n",
        "    exit()\n",
        "\n",
        "if num_classes <= 1 and (X_train.size > 0 or X_test.size > 0) : # Check if data exists but not enough classes\n",
        "    print(f\"Error: num_classes is {num_classes}. Need at least 2 classes for classification.\")\n",
        "    exit()\n",
        "if num_classes == 0: # Should be caught by above, but as a safeguard\n",
        "    print(\"Error: num_classes is 0. No data available.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# --- 6. Define Adapted 2D CNN Model (Inspired by AlexNet structure) ---\n",
        "class AlexNet2D_Adapted(nn.Module):\n",
        "    def __init__(self, num_classes, input_channels=1, input_h=30, input_w=36): # input_h=n_in_steps, input_w=padded_feature_size\n",
        "        super(AlexNet2D_Adapted, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Input: (N, C_in, H_in, W_in) = (N, 1, n_in_steps, padded_feature_size)\n",
        "            # Example: (N, 1, 30, 36)\n",
        "            nn.Conv2d(input_channels, 32, kernel_size=3, padding=1), # (N, 32, 30, 36)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # (N, 32, 15, 18)\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # (N, 64, 15, 18)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # (N, 64, 7, 9)\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # (N, 128, 7, 9)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(128),\n",
        "            # Optional: Another MaxPool2d if dimensions are still large enough\n",
        "            # nn.MaxPool2d(kernel_size=2, stride=2), # Example: (N, 128, 3, 4) - check if H/W > 1 after this\n",
        "        )\n",
        "\n",
        "        # Calculate the size after conv features by doing a dummy pass\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, input_channels, input_h, input_w)\n",
        "            conv_out_shape = self.features(dummy_input).shape\n",
        "\n",
        "        # Adaptive pool to get a fixed size output (1,1) for each feature map\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1)) # Output: (N, 128, 1, 1)\n",
        "\n",
        "        num_features_after_pool = conv_out_shape[1] # Number of channels from last conv layer (e.g., 128)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features_after_pool, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x should be (N, C, H, W)\n",
        "        x = self.features(x)\n",
        "        x = self.adaptive_pool(x) # (N, num_channels_after_conv, 1, 1)\n",
        "        x = torch.flatten(x, 1)    # (N, num_channels_after_conv)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# --- 7. Prepare PyTorch DataLoaders ---\n",
        "if X_train.shape[0] == 0:\n",
        "    print(\"Error: Training data (X_train) is empty. Cannot create DataLoaders or train model.\")\n",
        "    exit()\n",
        "\n",
        "# Ensure X_train has 4 dimensions (N, C, H, W) before converting to tensor\n",
        "if X_train.ndim == 3: # If X_train is (N, H, W)\n",
        "    print(\"Reshaping X_train from (N, H, W) to (N, 1, H, W) for DataLoader.\")\n",
        "    X_train = X_train[:, np.newaxis, :, :] # Add channel dimension\n",
        "\n",
        "X_train_tensor = torch.from_numpy(X_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).long()\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "print(\"Training DataLoader created.\")\n",
        "\n",
        "test_loader = None\n",
        "if X_test.shape[0] > 0:\n",
        "    if X_test.ndim == 3: # If X_test is (N, H, W)\n",
        "        print(\"Reshaping X_test from (N, H, W) to (N, 1, H, W) for DataLoader.\")\n",
        "        X_test = X_test[:, np.newaxis, :, :] # Add channel dimension\n",
        "    X_test_tensor = torch.from_numpy(X_test).float()\n",
        "    y_test_tensor = torch.from_numpy(y_test).long()\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "    print(\"Test DataLoader created.\")\n",
        "else:\n",
        "    print(\"Test data is empty. No Test DataLoader will be created.\")\n",
        "\n",
        "\n",
        "# --- 8. Initialize Model, Loss, Optimizer ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = AlexNet2D_Adapted(\n",
        "    num_classes=num_classes,\n",
        "    input_channels=1, # Data prepared with 1 channel\n",
        "    input_h=n_in_steps,          # Height of the 2D input\n",
        "    input_w=padded_feature_size  # Width of the 2D input\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"2D Model, Loss, and Optimizer initialized.\")\n",
        "print(model)\n",
        "\n",
        "# --- 9. Training Loop ---\n",
        "num_epochs = 10  # Adjust as needed\n",
        "\n",
        "print(\"Starting 2D CNN training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "        inputs, labels = batch_data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Explicitly ensure inputs have 4 dimensions (B, C, H, W)\n",
        "        # This is a safeguard. Ideally, data prep (step 4 & 5) and DataLoader prep (step 7)\n",
        "        # should ensure inputs already have the correct shape (B, 1, H, W).\n",
        "        if inputs.ndim == 3:  # If inputs tensor is (B, H, W)\n",
        "            inputs = inputs.unsqueeze(1)  # Reshape to (B, 1, H, W)\n",
        "\n",
        "        # Verify input shape just before model call for debugging\n",
        "        # if i == 0 and epoch == 0:\n",
        "        #     print(f\"Shape of 'inputs' tensor going into model: {inputs.shape}\")\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if (i + 1) % 10 == 0: # Print every 10 mini-batches\n",
        "            if len(train_loader) > 0 : # Avoid division by zero if train_loader is small\n",
        "                 print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    if len(train_loader) > 0:\n",
        "        print(f'Epoch {epoch+1} average loss: {running_loss / len(train_loader):.4f}')\n",
        "    else:\n",
        "        print(f'Epoch {epoch+1} completed (no training data in loader).')\n",
        "\n",
        "    # --- 10. (Optional) Validation Loop ---\n",
        "    if test_loader:\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs_val, labels_val in test_loader:\n",
        "                inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
        "\n",
        "                # Explicitly ensure validation inputs also have 4 dimensions\n",
        "                if inputs_val.ndim == 3:\n",
        "                    inputs_val = inputs_val.unsqueeze(1)\n",
        "\n",
        "                outputs_val = model(inputs_val)\n",
        "                _, predicted = torch.max(outputs_val.data, 1)\n",
        "                total += labels_val.size(0)\n",
        "                correct += (predicted == labels_val).sum().item()\n",
        "\n",
        "        if total > 0:\n",
        "            accuracy = 100 * correct / total\n",
        "            print(f'Accuracy on test set after epoch {epoch+1}: {accuracy:.2f}%')\n",
        "        # else: # No print needed if test_loader was None or empty\n",
        "            # print(\"No test samples to evaluate or test_loader is empty.\")\n",
        "\n",
        "print('2D CNN Training finished!')\n",
        "\n",
        "# TODO: Save the model if needed\n",
        "# torch.save(model.state_dict(), 'alexnet2d_adapted_baby_action.pth')\n"
      ],
      "metadata": {
        "id": "FhDms5II5Fpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler # StandardScaler might not be suitable for this spatial approach\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# --- User-Defined Parameters ---\n",
        "ORIGINAL_FRAME_WIDTH = 1440\n",
        "ORIGINAL_FRAME_HEIGHT = 1080\n",
        "\n",
        "\n",
        "# --- Parameters for Spatial Pose Image Representation ---\n",
        "n_in_steps = 30  # Sequence length (will be number of CHANNELS for 2D CNN input)\n",
        "GRID_H = 64      # Height of the spatial grid for each pose\n",
        "GRID_W = 64      # Width of the spatial grid for each pose\n",
        "\n",
        "print(f\"Original frame dimensions: {ORIGINAL_FRAME_WIDTH}x{ORIGINAL_FRAME_HEIGHT}\")\n",
        "print(f\"Input to 2D CNN will be (Batch, Channels={n_in_steps}, Height={GRID_H}, Width={GRID_W})\")\n",
        "\n",
        "# --- 2. Split video IDs for training and testing ---\n",
        "if 'source_video' not in baby_df.columns:\n",
        "    raise ValueError(\"DataFrame must contain 'source_video' column for splitting.\")\n",
        "unique_videos = baby_df['source_video'].unique()\n",
        "\n",
        "train_videos = np.array([])\n",
        "test_videos = np.array([])\n",
        "\n",
        "if len(unique_videos) < 2:\n",
        "    print(\"Warning: Too few unique videos for video-based train/test split.\")\n",
        "    if len(unique_videos) == 1:\n",
        "        print(\"Only one unique video found. Using all data for training, empty test set.\")\n",
        "        train_videos = unique_videos\n",
        "    else:\n",
        "        print(\"Error: No unique videos found. Cannot proceed.\")\n",
        "        exit()\n",
        "else:\n",
        "    train_videos, test_videos = train_test_split(unique_videos, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Total unique videos: {len(unique_videos)}\")\n",
        "print(f\"Training videos: {list(train_videos)}, Count: {len(train_videos)}\")\n",
        "print(f\"Testing videos: {list(test_videos)}, Count: {len(test_videos)}\")\n",
        "\n",
        "\n",
        "# --- 3. Scaler (Commented Out - Per-pose normalization is now handled in step 4) ---\n",
        "print(\"Skipping global StandardScaler. Per-pose normalization/scaling to grid is applied during sequence preparation.\")\n",
        "\n",
        "\n",
        "# --- 4. Prepare Sequences for 2D CNN (Spatial Pose Images) ---\n",
        "X_train_list, y_train_list = [], []\n",
        "X_test_list, y_test_list = [], []\n",
        "\n",
        "videos_to_assign_to_train = train_videos\n",
        "videos_to_assign_to_test = test_videos\n",
        "\n",
        "print(\"Preparing sequences as spatial pose images for 2D CNN...\")\n",
        "for video_id in unique_videos:\n",
        "    video_df = baby_df[baby_df['source_video'] == video_id]\n",
        "    for tid in video_df['tracking_id'].unique():\n",
        "        person_df = video_df[(video_df['tracking_id'] == tid) & (video_df['source_video'] == video_id)].copy()\n",
        "        person_df = person_df.sort_values('sec')\n",
        "\n",
        "        if len(person_df) < n_in_steps:\n",
        "            continue\n",
        "\n",
        "        # Keypoint data for this person: shape (num_timesteps_for_person, num_original_features)\n",
        "        kp_data_all_timesteps = person_df[keypoint_cols].values\n",
        "        label_data = person_df[target_column].values\n",
        "\n",
        "        num_sequences_possible = len(kp_data_all_timesteps) - n_in_steps + 1\n",
        "        if num_sequences_possible <= 0:\n",
        "            continue\n",
        "\n",
        "        current_X_sequences_list_for_person = []\n",
        "        current_y_sequences_list_for_person = []\n",
        "\n",
        "        for i in range(num_sequences_possible):\n",
        "            # Get the window of n_in_steps for keypoint data\n",
        "            # Shape: (n_in_steps, num_original_features), where num_original_features = 17*2 = 34\n",
        "            raw_kp_sequence = kp_data_all_timesteps[i : i + n_in_steps]\n",
        "\n",
        "            # Create the multi-channel 2D \"image\" for the sequence\n",
        "            # Shape: (n_in_steps_as_channels, GRID_H, GRID_W)\n",
        "            sequence_as_spatial_image = np.zeros((n_in_steps, GRID_H, GRID_W), dtype=np.float32)\n",
        "\n",
        "            for t_idx in range(n_in_steps): # Iterate through each time step in the sequence\n",
        "                # features_at_t has shape (num_original_features), e.g., (kp0_x, kp0_y, kp1_x, kp1_y, ...)\n",
        "                features_at_t = raw_kp_sequence[t_idx, :]\n",
        "\n",
        "                # This grid will represent the pose at the current time step t_idx\n",
        "                current_timestep_grid = np.zeros((GRID_H, GRID_W), dtype=np.float32)\n",
        "\n",
        "                for kp_i in range(int(17)): # Iterate through 17 keypoints\n",
        "                    kp_x_original = features_at_t[kp_i * 2]     # Absolute pixel coordinate X\n",
        "                    kp_y_original = features_at_t[kp_i * 2 + 1] # Absolute pixel coordinate Y\n",
        "\n",
        "                    if pd.isna(kp_x_original) or pd.isna(kp_y_original):\n",
        "                        continue # Skip NaN coordinates\n",
        "\n",
        "                    # Normalize keypoint coordinates to [0, 1] range based on original frame dimensions\n",
        "                    kp_x_normalized = kp_x_original / ORIGINAL_FRAME_WIDTH\n",
        "                    kp_y_normalized = kp_y_original / ORIGINAL_FRAME_HEIGHT\n",
        "\n",
        "                    # Scale normalized coordinates to the grid dimensions and clip\n",
        "                    grid_x = int(np.clip(kp_x_normalized * (GRID_W - 1), 0, GRID_W - 1))\n",
        "                    grid_y = int(np.clip(kp_y_normalized * (GRID_H - 1), 0, GRID_H - 1))\n",
        "\n",
        "                    current_timestep_grid[grid_y, grid_x] = 1.0 # Mark keypoint presence\n",
        "\n",
        "                sequence_as_spatial_image[t_idx, :, :] = current_timestep_grid\n",
        "\n",
        "            current_X_sequences_list_for_person.append(sequence_as_spatial_image) # Shape (n_in_steps, GRID_H, GRID_W)\n",
        "            current_y_sequences_list_for_person.append(label_data[i + n_in_steps - 1])\n",
        "\n",
        "        if not current_X_sequences_list_for_person:\n",
        "            continue\n",
        "\n",
        "        # Stack sequences for this person. Each item is (n_in_steps, GRID_H, GRID_W)\n",
        "        # Resulting X_person_sequences shape: (num_person_sequences, n_in_steps_as_channels, GRID_H, GRID_W)\n",
        "        X_person_sequences = np.stack(current_X_sequences_list_for_person, axis=0)\n",
        "        y_person_sequences = np.array(current_y_sequences_list_for_person)\n",
        "\n",
        "        if video_id in videos_to_assign_to_train:\n",
        "            X_train_list.append(X_person_sequences)\n",
        "            y_train_list.append(y_person_sequences)\n",
        "        elif video_id in videos_to_assign_to_test:\n",
        "            X_test_list.append(X_person_sequences)\n",
        "            y_test_list.append(y_person_sequences)\n",
        "\n",
        "# --- 5. Final Train/Test Arrays ---\n",
        "# Expected shape: (N_total_sequences, n_in_steps_as_channels, GRID_H, GRID_W)\n",
        "if X_train_list:\n",
        "    X_train = np.concatenate(X_train_list, axis=0)\n",
        "    y_train = np.concatenate(y_train_list, axis=0).astype(np.int64)\n",
        "else:\n",
        "    X_train = np.empty((0, n_in_steps, GRID_H, GRID_W), dtype=np.float32)\n",
        "    y_train = np.array([], dtype=np.int64)\n",
        "\n",
        "if X_test_list:\n",
        "    X_test = np.concatenate(X_test_list, axis=0)\n",
        "    y_test = np.concatenate(y_test_list, axis=0).astype(np.int64)\n",
        "else:\n",
        "    X_test = np.empty((0, n_in_steps, GRID_H, GRID_W), dtype=np.float32)\n",
        "    y_test = np.array([], dtype=np.int64)\n",
        "\n",
        "print(\"✅ Train/test data prepared for 2D CNN (spatial pose images).\")\n",
        "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape) # Should be (N, n_in_steps, GRID_H, GRID_W)\n",
        "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)\n",
        "\n",
        "num_classes = 0\n",
        "if y_train.size > 0:\n",
        "    unique_train_labels = np.unique(y_train)\n",
        "    num_classes = len(unique_train_labels)\n",
        "    print(f\"Number of unique classes in y_train: {num_classes}\")\n",
        "    print(f\"Unique y_train labels: {unique_train_labels}\")\n",
        "elif y_test.size > 0:\n",
        "    unique_test_labels = np.unique(y_test)\n",
        "    num_classes = len(unique_test_labels)\n",
        "    print(f\"Warning: y_train is empty. Using y_test to determine num_classes: {num_classes}\")\n",
        "    print(f\"Unique y_test labels: {unique_test_labels}\")\n",
        "else:\n",
        "    print(\"Error: Both y_train and y_test are empty. Cannot determine num_classes.\")\n",
        "    exit()\n",
        "\n",
        "if num_classes <= 1 and (X_train.size > 0 or X_test.size > 0) :\n",
        "    print(f\"Error: num_classes is {num_classes}. Need at least 2 classes for classification.\")\n",
        "    exit()\n",
        "if num_classes == 0:\n",
        "    print(\"Error: num_classes is 0. No data available.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# --- 6. Define Adapted 2D CNN Model for Spatial Pose Images ---\n",
        "class AlexNet2D_SpatialPose(nn.Module):\n",
        "    # input_channels will now be n_in_steps\n",
        "    def __init__(self, num_classes, input_channels, input_h, input_w):\n",
        "        super(AlexNet2D_SpatialPose, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Input: (N, C_in=n_in_steps, H_in=GRID_H, W_in=GRID_W)\n",
        "            # Example: (N, 30, 64, 64)\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=3, padding=1), # Keep H, W same\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # H, W become GRID_H/2, GRID_W/2 (e.g., 32x32)\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # H, W become GRID_H/4, GRID_W/4 (e.g., 16x16)\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(256),\n",
        "            # Optional: another conv/pool layer if GRID_H/W are large enough\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # H, W become GRID_H/8, GRID_W/8 (e.g., 8x8)\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, input_channels, input_h, input_w)\n",
        "            conv_out_shape = self.features(dummy_input).shape\n",
        "\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1)) # Output: (N, last_conv_channels, 1, 1)\n",
        "\n",
        "        num_features_after_pool = conv_out_shape[1] # Channels from last conv layer (e.g., 256)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features_after_pool, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x input shape: (N, n_in_steps_as_channels, GRID_H, GRID_W)\n",
        "        x = self.features(x)\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# --- 7. Prepare PyTorch DataLoaders ---\n",
        "if X_train.shape[0] == 0:\n",
        "    print(\"Error: Training data (X_train) is empty. Cannot create DataLoaders or train model.\")\n",
        "    exit()\n",
        "\n",
        "# X_train and X_test should already be (N, n_in_steps, GRID_H, GRID_W) from Step 5\n",
        "X_train_tensor = torch.from_numpy(X_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).long()\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "print(\"Training DataLoader created.\")\n",
        "\n",
        "test_loader = None\n",
        "if X_test.shape[0] > 0:\n",
        "    X_test_tensor = torch.from_numpy(X_test).float()\n",
        "    y_test_tensor = torch.from_numpy(y_test).long()\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "    print(\"Test DataLoader created.\")\n",
        "else:\n",
        "    print(\"Test data is empty. No Test DataLoader will be created.\")\n",
        "\n",
        "\n",
        "# --- 8. Initialize Model, Loss, Optimizer ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = AlexNet2D_SpatialPose(\n",
        "    num_classes=num_classes,\n",
        "    input_channels=n_in_steps, # Number of channels is the sequence length\n",
        "    input_h=GRID_H,\n",
        "    input_w=GRID_W\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"2D Spatial Pose Model, Loss, and Optimizer initialized.\")\n",
        "print(model)\n",
        "\n",
        "# --- 9. Training Loop ---\n",
        "num_epochs = 10  # Adjust as needed\n",
        "\n",
        "print(\"Starting 2D Spatial Pose CNN training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "        inputs, labels = batch_data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Inputs should already be (B, n_in_steps, GRID_H, GRID_W)\n",
        "        # No unsqueeze(1) needed here.\n",
        "        # if i == 0 and epoch == 0:\n",
        "        #     print(f\"Shape of 'inputs' tensor going into model: {inputs.shape}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if (i + 1) % 10 == 0:\n",
        "            if len(train_loader) > 0 :\n",
        "                 print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    if len(train_loader) > 0:\n",
        "        print(f'Epoch {epoch+1} average loss: {running_loss / len(train_loader):.4f}')\n",
        "    else:\n",
        "        print(f'Epoch {epoch+1} completed (no training data in loader).')\n",
        "\n",
        "    # --- 10. (Optional) Validation Loop ---\n",
        "    if test_loader:\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs_val, labels_val in test_loader:\n",
        "                inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
        "                # inputs_val should also be (B, n_in_steps, GRID_H, GRID_W)\n",
        "                outputs_val = model(inputs_val)\n",
        "                _, predicted = torch.max(outputs_val.data, 1)\n",
        "                total += labels_val.size(0)\n",
        "                correct += (predicted == labels_val).sum().item()\n",
        "\n",
        "        if total > 0:\n",
        "            accuracy = 100 * correct / total\n",
        "            print(f'Accuracy on test set after epoch {epoch+1}: {accuracy:.2f}%')\n",
        "\n",
        "print('2D Spatial Pose CNN Training finished!')\n",
        "\n",
        "# TODO: Save the model if needed\n",
        "# torch.save(model.state_dict(), 'alexnet2d_spatial_pose_action.pth')\n"
      ],
      "metadata": {
        "id": "YLRq1mSf8KGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler # StandardScaler might not be suitable for this spatial approach\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# --- User-Defined Parameters ---\n",
        "ORIGINAL_FRAME_WIDTH = 1440\n",
        "ORIGINAL_FRAME_HEIGHT = 1080\n",
        "\n",
        "\n",
        "# --- Parameters for Spatial Pose Image Representation ---\n",
        "n_in_steps = 30  # Sequence length (will be number of CHANNELS for 2D CNN input)\n",
        "GRID_H = 64      # Height of the spatial grid for each pose\n",
        "GRID_W = 64      # Width of the spatial grid for each pose\n",
        "\n",
        "print(f\"Original frame dimensions: {ORIGINAL_FRAME_WIDTH}x{ORIGINAL_FRAME_HEIGHT}\")\n",
        "print(f\"Input to 2D CNN will be (Batch, Channels={n_in_steps}, Height={GRID_H}, Width={GRID_W})\")\n",
        "\n",
        "# --- 2. Split video IDs for training and testing ---\n",
        "if 'source_video' not in baby_df.columns:\n",
        "    raise ValueError(\"DataFrame must contain 'source_video' column for splitting.\")\n",
        "unique_videos = baby_df['source_video'].unique()\n",
        "print(f\"Found unique video IDs: {unique_videos}\")\n",
        "\n",
        "\n",
        "train_videos = np.array([])\n",
        "test_videos = np.array([])\n",
        "\n",
        "if len(unique_videos) < 2:\n",
        "    print(\"Warning: Too few unique videos for video-based train/test split.\")\n",
        "    if len(unique_videos) == 1:\n",
        "        print(\"Only one unique video found. Using all data for training, empty test set.\")\n",
        "        train_videos = unique_videos\n",
        "    else:\n",
        "        print(\"Error: No unique videos found. Cannot proceed.\")\n",
        "        exit()\n",
        "else:\n",
        "    # Sort unique_videos to ensure consistent splitting if the order from .unique() varies\n",
        "    train_videos, test_videos = train_test_split(np.sort(unique_videos), test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Total unique videos: {len(unique_videos)}\")\n",
        "print(f\"Training videos: {list(train_videos)}, Count: {len(train_videos)}\")\n",
        "print(f\"Testing videos: {list(test_videos)}, Count: {len(test_videos)}\")\n",
        "\n",
        "\n",
        "# --- 3. Scaler (Commented Out - Per-pose normalization is now handled in step 4) ---\n",
        "print(\"Skipping global StandardScaler. Per-pose normalization/scaling to grid is applied during sequence preparation.\")\n",
        "\n",
        "\n",
        "# --- 4. Prepare Sequences for 2D CNN (Spatial Pose Images) ---\n",
        "X_train_list, y_train_list = [], []\n",
        "X_test_list, y_test_list = [], []\n",
        "\n",
        "videos_to_assign_to_train = train_videos\n",
        "videos_to_assign_to_test = test_videos\n",
        "\n",
        "print(\"Preparing sequences as spatial pose images for 2D CNN...\") # CRASH POINT\n",
        "for video_idx, video_id in enumerate(unique_videos):\n",
        "    print(f\"  Processing video {video_idx + 1}/{len(unique_videos)}: {video_id}\")\n",
        "    video_df = baby_df[baby_df['source_video'] == video_id]\n",
        "\n",
        "    unique_tracking_ids_in_video = video_df['tracking_id'].unique()\n",
        "    for tid_idx, tid in enumerate(unique_tracking_ids_in_video):\n",
        "        person_df = video_df[(video_df['tracking_id'] == tid) & (video_df['source_video'] == video_id)].copy()\n",
        "        person_df = person_df.sort_values('sec')\n",
        "\n",
        "        print(f\"    Processing person {tid_idx + 1}/{len(unique_tracking_ids_in_video)} (ID: {tid}) from video {video_id}.DataFrame length for this person: {len(person_df)}\")\n",
        "\n",
        "        if len(person_df) < n_in_steps:\n",
        "            print(f\"      Skipping person ID {tid} in video {video_id} due to insufficient data (Length: {len(person_df)}, Needed: {n_in_steps})\")\n",
        "            continue\n",
        "\n",
        "        # Keypoint data for this person: shape (num_timesteps_for_person, num_original_features)\n",
        "        kp_data_all_timesteps = person_df[keypoint_cols].values\n",
        "        label_data = person_df[target_column].values\n",
        "\n",
        "        num_sequences_possible = len(kp_data_all_timesteps) - n_in_steps + 1\n",
        "        print(f\"      Number of sequences possible for this person: {num_sequences_possible}\")\n",
        "\n",
        "        if num_sequences_possible <= 0: # Should be caught by len(person_df) < n_in_steps, but as a safeguard\n",
        "            continue\n",
        "\n",
        "        # Pre-allocate array for this person's sequences\n",
        "        # Shape: (num_sequences_possible, n_in_steps_as_channels, GRID_H, GRID_W)\n",
        "        try:\n",
        "            print(f\"      Attempting to allocate array of shape: ({num_sequences_possible}, {n_in_steps}, {GRID_H}, {GRID_W})\")\n",
        "            X_person_sequences_direct = np.zeros((num_sequences_possible, n_in_steps, GRID_H, GRID_W), dtype=np.float32)\n",
        "            y_person_sequences_direct = np.zeros(num_sequences_possible, dtype=np.int64)\n",
        "        except MemoryError:\n",
        "            print(f\"      ❌ MEMORY ERROR: Failed to allocate array for person {tid}, video {video_id}. Shape: ({num_sequences_possible}, {n_in_steps}, {GRID_H}, {GRID_W}). Skipping this person.\")\n",
        "            continue # Skip to the next person\n",
        "        except Exception as e:\n",
        "            print(f\"      ❌ ERROR during allocation for person {tid}, video {video_id}: {e}. Skipping this person.\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        sequence_idx_for_person = 0\n",
        "\n",
        "        for i in range(num_sequences_possible):\n",
        "            raw_kp_sequence = kp_data_all_timesteps[i : i + n_in_steps]\n",
        "            sequence_as_spatial_image = np.zeros((n_in_steps, GRID_H, GRID_W), dtype=np.float32)\n",
        "\n",
        "            for t_idx in range(n_in_steps):\n",
        "                features_at_t = raw_kp_sequence[t_idx, :]\n",
        "                current_timestep_grid = np.zeros((GRID_H, GRID_W), dtype=np.float32)\n",
        "\n",
        "                for kp_i in range(int(17)):\n",
        "                    kp_x_original = features_at_t[kp_i * 2]\n",
        "                    kp_y_original = features_at_t[kp_i * 2 + 1]\n",
        "\n",
        "                    if pd.isna(kp_x_original) or pd.isna(kp_y_original):\n",
        "                        continue\n",
        "\n",
        "                    kp_x_normalized = kp_x_original / ORIGINAL_FRAME_WIDTH\n",
        "                    kp_y_normalized = kp_y_original / ORIGINAL_FRAME_HEIGHT\n",
        "\n",
        "                    grid_x = int(np.clip(kp_x_normalized * (GRID_W - 1), 0, GRID_W - 1))\n",
        "                    grid_y = int(np.clip(kp_y_normalized * (GRID_H - 1), 0, GRID_H - 1))\n",
        "\n",
        "                    current_timestep_grid[grid_y, grid_x] = 1.0\n",
        "\n",
        "                sequence_as_spatial_image[t_idx, :, :] = current_timestep_grid\n",
        "\n",
        "            X_person_sequences_direct[sequence_idx_for_person] = sequence_as_spatial_image\n",
        "            y_person_sequences_direct[sequence_idx_for_person] = label_data[i + n_in_steps - 1]\n",
        "            sequence_idx_for_person += 1\n",
        "\n",
        "        if X_person_sequences_direct.shape[0] > 0:\n",
        "            if video_id in videos_to_assign_to_train:\n",
        "                X_train_list.append(X_person_sequences_direct)\n",
        "                y_train_list.append(y_person_sequences_direct)\n",
        "            elif video_id in videos_to_assign_to_test:\n",
        "                X_test_list.append(X_person_sequences_direct)\n",
        "                y_test_list.append(y_person_sequences_direct)\n",
        "\n",
        "# --- 5. Final Train/Test Arrays ---\n",
        "# Expected shape: (N_total_sequences, n_in_steps_as_channels, GRID_H, GRID_W)\n",
        "if X_train_list:\n",
        "    try:\n",
        "        print(\"Concatenating training data...\")\n",
        "        X_train = np.concatenate(X_train_list, axis=0)\n",
        "        y_train = np.concatenate(y_train_list, axis=0).astype(np.int64)\n",
        "    except MemoryError:\n",
        "        print(\"❌ MEMORY ERROR during final concatenation of X_train_list. Data might be too large.\")\n",
        "        # Handle error, e.g., by exiting or trying to use a subset\n",
        "        exit()\n",
        "else:\n",
        "    X_train = np.empty((0, n_in_steps, GRID_H, GRID_W), dtype=np.float32)\n",
        "    y_train = np.array([], dtype=np.int64)\n",
        "\n",
        "if X_test_list:\n",
        "    try:\n",
        "        print(\"Concatenating testing data...\")\n",
        "        X_test = np.concatenate(X_test_list, axis=0)\n",
        "        y_test = np.concatenate(y_test_list, axis=0).astype(np.int64)\n",
        "    except MemoryError:\n",
        "        print(\"❌ MEMORY ERROR during final concatenation of X_test_list. Data might be too large.\")\n",
        "        exit()\n",
        "else:\n",
        "    X_test = np.empty((0, n_in_steps, GRID_H, GRID_W), dtype=np.float32)\n",
        "    y_test = np.array([], dtype=np.int64)\n",
        "\n",
        "print(\"✅ Train/test data prepared for 2D CNN (spatial pose images).\")\n",
        "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)\n",
        "\n",
        "num_classes = 0\n",
        "if y_train.size > 0:\n",
        "    unique_train_labels = np.unique(y_train)\n",
        "    num_classes = len(unique_train_labels)\n",
        "    print(f\"Number of unique classes in y_train: {num_classes}\")\n",
        "    print(f\"Unique y_train labels: {unique_train_labels}\")\n",
        "elif y_test.size > 0:\n",
        "    unique_test_labels = np.unique(y_test)\n",
        "    num_classes = len(unique_test_labels)\n",
        "    print(f\"Warning: y_train is empty. Using y_test to determine num_classes: {num_classes}\")\n",
        "    print(f\"Unique y_test labels: {unique_test_labels}\")\n",
        "else:\n",
        "    print(\"Error: Both y_train and y_test are empty. Cannot determine num_classes.\")\n",
        "    exit()\n",
        "\n",
        "if num_classes <= 1 and (X_train.size > 0 or X_test.size > 0) :\n",
        "    print(f\"Error: num_classes is {num_classes}. Need at least 2 classes for classification.\")\n",
        "    exit()\n",
        "if num_classes == 0:\n",
        "    print(\"Error: num_classes is 0. No data available.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# --- 6. Define Adapted 2D CNN Model for Spatial Pose Images ---\n",
        "class AlexNet2D_SpatialPose(nn.Module):\n",
        "    # input_channels will now be n_in_steps\n",
        "    def __init__(self, num_classes, input_channels, input_h, input_w):\n",
        "        super(AlexNet2D_SpatialPose, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, input_channels, input_h, input_w)\n",
        "            conv_out_shape = self.features(dummy_input).shape\n",
        "\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        num_features_after_pool = conv_out_shape[1]\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features_after_pool, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# --- 7. Prepare PyTorch DataLoaders ---\n",
        "if X_train.shape[0] == 0:\n",
        "    print(\"Error: Training data (X_train) is empty. Cannot create DataLoaders or train model.\")\n",
        "    exit()\n",
        "\n",
        "X_train_tensor = torch.from_numpy(X_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).long()\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "print(\"Training DataLoader created.\")\n",
        "\n",
        "test_loader = None\n",
        "if X_test.shape[0] > 0:\n",
        "    X_test_tensor = torch.from_numpy(X_test).float()\n",
        "    y_test_tensor = torch.from_numpy(y_test).long()\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "    print(\"Test DataLoader created.\")\n",
        "else:\n",
        "    print(\"Test data is empty. No Test DataLoader will be created.\")\n",
        "\n",
        "\n",
        "# --- 8. Initialize Model, Loss, Optimizer ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = AlexNet2D_SpatialPose(\n",
        "    num_classes=num_classes,\n",
        "    input_channels=n_in_steps,\n",
        "    input_h=GRID_H,\n",
        "    input_w=GRID_W\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"2D Spatial Pose Model, Loss, and Optimizer initialized.\")\n",
        "print(model)\n",
        "\n",
        "# --- 9. Training Loop ---\n",
        "num_epochs = 10\n",
        "\n",
        "print(\"Starting 2D Spatial Pose CNN training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "        inputs, labels = batch_data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if (i + 1) % 10 == 0:\n",
        "            if len(train_loader) > 0 :\n",
        "                 print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    if len(train_loader) > 0:\n",
        "        print(f'Epoch {epoch+1} average loss: {running_loss / len(train_loader):.4f}')\n",
        "    else:\n",
        "        print(f'Epoch {epoch+1} completed (no training data in loader).')\n",
        "\n",
        "    # --- 10. (Optional) Validation Loop ---\n",
        "    if test_loader:\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs_val, labels_val in test_loader:\n",
        "                inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
        "                outputs_val = model(inputs_val)\n",
        "                _, predicted = torch.max(outputs_val.data, 1)\n",
        "                total += labels_val.size(0)\n",
        "                correct += (predicted == labels_val).sum().item()\n",
        "\n",
        "        if total > 0:\n",
        "            accuracy = 100 * correct / total\n",
        "            print(f'Accuracy on test set after epoch {epoch+1}: {accuracy:.2f}%')\n",
        "\n",
        "print('2D Spatial Pose CNN Training finished!')\n",
        "\n",
        "# TODO: Save the model if needed\n",
        "# torch.save(model.state_dict(), 'alexnet2d_spatial_pose_action.pth')\n"
      ],
      "metadata": {
        "id": "04-gdbTIDLvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zyDdIfAPJGU3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "19_eaplXOJMxMJ0oirOBhw-tVo7AXdvhl",
      "authorship_tag": "ABX9TyNxbcl6iViJCqHksYdtpzGF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}